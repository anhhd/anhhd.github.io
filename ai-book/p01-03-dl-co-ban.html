
<!DOCTYPE html>


<html lang="vn" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>3. Tensorflow &amp; Keras &#8212; AI with Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=0cebd926" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=b0188291"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "displayMath": [["$$", "$$"], ["\\[", "\\]"]]}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'p01-03-dl-co-ban';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4. Chuỗi thời gian" href="p01-04-dl-timeseries.html" />
    <link rel="prev" title="2. Toán cơ bản với DL" href="p01-02-toan-co-ban.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="vn"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">AI with Python</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Cơ bản về Deep Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="p01-01-gioi-thieu-deep-learning.html">1. Giới thiệu về học sâu</a></li>
<li class="toctree-l1"><a class="reference internal" href="p01-02-toan-co-ban.html">2. Toán cơ bản với DL</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">3. Tensorflow &amp; Keras</a></li>
<li class="toctree-l1"><a class="reference internal" href="p01-04-dl-timeseries.html">4. Chuỗi thời gian</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM &amp; GenAI</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="p02-01-gioi-thieu-llm.html">1. Giới thiệu về mô hình ngôn ngữ lớn</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-02-xu-ly-text.html">2. Xử lý dữ liệu text</a></li>
<li class="toctree-l1"><a class="reference internal" href="p02-03-co-che-tu-chu-y.html">3. Cơ chế tự chú ý</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">GenAI</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="p05-01-gioi-thieu-langchain.html">1. Giới thiệu langchain</a></li>
<li class="toctree-l1"><a class="reference internal" href="p05-04-phan-tich-du-lieu.html">2. Use case - truy vấn &amp; phân tích dữ liệu</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">AI Agent</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="p06-01-gioi-thieu-ai-agent.html">1. Giới thiệu về AI Agent</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Tensorflow & Keras</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Mục lục </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow">3.1. Tensorflow</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-co-ban">3.1.1. TensorFlow cơ bản</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xay-dung-mo-hinh-phan-loai-co-ban-voi-tensorflow">3.1.2. Xây dựng mô hình phân loại cơ bản với tensorflow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#keras">3.2. Keras</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cac-mo-hinh-co-ban">3.3. Các mô hình cơ bản</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#phan-loai-nhi-phan">3.3.1. Phân loại nhị phân</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mo-hinh-phan-loai-nhieu-nhom">3.3.2. Mô hình phân loại nhiều nhóm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mo-hinh-hoi-quy">3.3.3. Mô hình hồi quy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#luu-y-xay-dung-mo-hinh">3.4. Lưu ý xây dựng mô hình</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="tensorflow-keras">
<h1><span class="section-number">3. </span>Tensorflow &amp; Keras<a class="headerlink" href="#tensorflow-keras" title="Link to this heading">#</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Tensorflow</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">Keras</span></code> là framework được sử dụng rộng rãi trong deep learning - keras là tầng interface giúp cho quá trình làm việc và training model với deep learning sử dụng tensorflow được dễ dàng hơn.</p>
<p>Keras ra đời từ 3/2015 và thiết kế trên nền của <code class="docutils literal notranslate"><span class="pre">theano</span></code> trong khi <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code> đến 11/2015 mới bắt đầu ra đời. Sự phát triển nhanh chóng của <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code> dần thay thế <code class="docutils literal notranslate"><span class="pre">theano</span></code>, và dần dần, keras chỉ sử dụng <code class="docutils literal notranslate"><span class="pre">tensorlow</span></code> là backend. Thông qua <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code>, keras có thể tương tác với cả GPU/TPU hoặc CPU truyền thống trong các mô hình <code class="docutils literal notranslate"><span class="pre">deep</span> <span class="pre">learning</span></code> để tăng tốc độ xây dựng mô hình.</p>
<p><img alt="" src="_images/p03-01-keras-tf.png" /></p>
<p>Với kiến trúc như trên, <code class="docutils literal notranslate"><span class="pre">keras</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code> sẽ chia thành 2 lớp xử lý các vấn đề khác nhau.</p>
<p><strong>Low-level tensor</strong>: Xử lý thông qua tensorflow</p>
<ul class="simple">
<li><p>Tensor</p></li>
<li><p>Các phép toán với tensor như <code class="docutils literal notranslate"><span class="pre">relu</span></code>, <code class="docutils literal notranslate"><span class="pre">dot</span></code>, <code class="docutils literal notranslate"><span class="pre">matmul</span></code></p></li>
<li><p>Tối ưu &amp; tính toán đạo hàm - <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code></p></li>
</ul>
<p><strong>High level deep learning</strong>: Xử lý thông qua keras</p>
<ul class="simple">
<li><p>Xác định kiến trúc và layers trong mạng deep learning</p></li>
<li><p>Xác định <code class="docutils literal notranslate"><span class="pre">loss</span> <span class="pre">function</span></code></p></li>
<li><p>Xác định thuật toán tối ưu <code class="docutils literal notranslate"><span class="pre">optimizer</span></code></p></li>
<li><p>Xác định chỉ số để đánh giá mô hình</p></li>
<li><p>Xác định <code class="docutils literal notranslate"><span class="pre">training</span> <span class="pre">loop</span></code> để tối ưu hóa theo từng mini-batch</p></li>
</ul>
<section id="tensorflow">
<h2><span class="section-number">3.1. </span>Tensorflow<a class="headerlink" href="#tensorflow" title="Link to this heading">#</a></h2>
<section id="tensorflow-co-ban">
<h3><span class="section-number">3.1.1. </span>TensorFlow cơ bản<a class="headerlink" href="#tensorflow-co-ban" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tạo tensor 1</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(
[[1.]
 [1.]], shape=(2, 1), dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tạo tensor random</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">mean</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stddev</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(
[[1.9448011  0.59846926]
 [1.4538708  2.5709903 ]
 [2.979758   2.5642636 ]], shape=(3, 2), dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>Cấu trúc tạo tensor rất giống với numpy, khác biệt lớn nhất là trong tensor ta không thể thực hiện phép <code class="docutils literal notranslate"><span class="pre">assign</span></code>. Kết quả sau sẽ báo lỗi</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># error</span>
<span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># error</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="ne">TypeError</span>: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object does not support item assignment
</pre></div>
</div>
</div>
</div>
<p>Để thực hiện tính toán với tensor, phải sử dụng class <code class="docutils literal notranslate"><span class="pre">Variable</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">mean</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">stddev</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Variable &#39;Variable:0&#39; shape=(2, 2) dtype=float32, numpy=
array([[-0.6348591 , -0.45395944],
       [ 0.49644822, -0.13218977]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assign x(0, 0)</span>
<span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Variable &#39;Variable:0&#39; shape=(2, 2) dtype=float32, numpy=
array([[ 1.        , -0.45395944],
       [ 0.49644822, -0.13218977]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p><strong>Các phép toán trong tensorflow</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="n">c</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(
[[1. 1.]
 [1. 1.]], shape=(2, 2), dtype=float32)
tf.Tensor(
[[2. 2.]
 [2. 2.]], shape=(2, 2), dtype=float32)
tf.Tensor(
[[2. 2.]
 [2. 2.]], shape=(2, 2), dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>Sư khác biệt cơ bản giữa <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code> và <code class="docutils literal notranslate"><span class="pre">numpy</span></code> nằm ở khả năng tính toán đạo hàm với bất kỳ thông số đầu vào nào.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ví dụ 1: Hàm y = x^2</span>
<span class="n">input_var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="mf">3.</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">input_var</span><span class="p">)</span>
<span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">input_var</span><span class="p">)</span> <span class="c1"># grad_y = 2 * x </span>
<span class="nb">print</span><span class="p">(</span><span class="n">gradient</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(6.0, shape=(), dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ví dụ 2: y = 3</span>
<span class="n">input_const</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">3.</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">tape</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">input_const</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">input_const</span><span class="p">)</span>                 <span class="c1"># 9</span>
<span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">input_const</span><span class="p">)</span>   <span class="c1"># 0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gradient</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>None
</pre></div>
</div>
</div>
</div>
</section>
<section id="xay-dung-mo-hinh-phan-loai-co-ban-voi-tensorflow">
<h3><span class="section-number">3.1.2. </span>Xây dựng mô hình phân loại cơ bản với tensorflow<a class="headerlink" href="#xay-dung-mo-hinh-phan-loai-co-ban-voi-tensorflow" title="Link to this heading">#</a></h3>
<p>Trong phần này, ta sẽ xây dựng một mô hình đơn giản phân loại 2 nhóm sử dụng neural netwwork với mục tiêu tìm hàm <span class="math notranslate nohighlight">\(w_1 x_1 + x_2 x_2 + b\)</span> cho phép phân nhóm mô hình đơn giản</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lets_plot</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="n">LetsPlot</span><span class="o">.</span><span class="n">setup_html</span><span class="p">()</span>
<span class="n">num_samples_per_class</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">negative_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">cov</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
    <span class="n">size</span><span class="o">=</span><span class="n">num_samples_per_class</span><span class="p">)</span>
<span class="n">positive_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">cov</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
    <span class="n">size</span><span class="o">=</span><span class="n">num_samples_per_class</span><span class="p">)</span>

<span class="c1"># Tạo biến input &amp; target</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">negative_samples</span><span class="p">,</span> <span class="n">positive_samples</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_samples_per_class</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_samples_per_class</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
            <div id="JkXVFM"></div>
            <script type="text/javascript" data-lets-plot-script="library">
                if(!window.letsPlotCallQueue) {
                    window.letsPlotCallQueue = [];
                }; 
                window.letsPlotCall = function(f) {
                    window.letsPlotCallQueue.push(f);
                };
                (function() {
                    var script = document.createElement("script");
                    script.type = "text/javascript";
                    script.src = "https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.7.0/js-package/distr/lets-plot.min.js";
                    script.onload = function() {
                        window.letsPlotCall = function(f) {f();};
                        window.letsPlotCallQueue.forEach(function(f) {f();});
                        window.letsPlotCallQueue = [];
                        
                    };
                    script.onerror = function(event) {
                        window.letsPlotCall = function(f) {};    // noop
                        window.letsPlotCallQueue = [];
                        var div = document.createElement("div");
                        div.style.color = 'darkred';
                        div.textContent = 'Error loading Lets-Plot JS';
                        document.getElementById("JkXVFM").appendChild(div);
                    };
                    var e = document.getElementById("JkXVFM");
                    e.appendChild(script);
                })()
            </script>
            </div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">polars</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;x1&#39;</span><span class="p">:</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="s1">&#39;x2&#39;</span><span class="p">:</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">targets</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (5, 3)</small><table border="1" class="dataframe"><thead><tr><th>x1</th><th>x2</th><th>y</th></tr><tr><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>2.896133</td><td>3.857033</td><td>0.0</td></tr><tr><td>-0.404993</td><td>1.654341</td><td>0.0</td></tr><tr><td>-0.104036</td><td>2.584361</td><td>0.0</td></tr><tr><td>-0.036517</td><td>2.520259</td><td>0.0</td></tr><tr><td>-0.158406</td><td>1.512122</td><td>0.0</td></tr></tbody></table></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span>
    <span class="n">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">))</span> 
        <span class="o">+</span> <span class="n">geom_point</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;y&#39;</span><span class="p">))</span>
        <span class="o">+</span> <span class="n">labs</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Simple classification&#39;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">   <div id="YnC465"></div>
   <script type="text/javascript" data-lets-plot-script="plot">
   
   (function() {
   // ----------
   
   const forceImmediateRender = false;
   const responsive = false;
   
   let sizing = {
       width_mode: "MIN",
       height_mode: "SCALED",
       width: null, 
       height: null 
   };
   
   const preferredWidth = document.body.dataset.letsPlotPreferredWidth;
   if (preferredWidth !== undefined) {
       sizing = {
           width_mode: 'FIXED',
           height_mode: 'SCALED',
           width: parseFloat(preferredWidth)
       };
   }
   
   const containerDiv = document.getElementById("YnC465");
   let fig = null;
   
   function renderPlot() {
       if (fig === null) {
           const plotSpec = {
"data":{
"x1":[2.896132707595825,-0.4049931764602661,-0.10403605550527573,-0.03651680797338486,-0.15840646624565125,-0.03452053293585777,0.9125211834907532,-1.7197636365890503,-0.5430731177330017,0.07387895882129669,-0.45392584800720215,-1.4814804792404175,0.8554124236106873,-0.17697231471538544,0.4963032305240631,-0.9843814969062805,1.7282357215881348,-1.4323581457138062,1.0178567171096802,-0.21229441463947296,-0.378709614276886,-0.3670024871826172,0.6360698938369751,1.315200686454773,-1.0101865530014038,-0.7166284918785095,-1.967427134513855,-1.1521739959716797,-1.566593885421753,1.6671839952468872,1.0480530261993408,-1.1914067268371582,-1.308578610420227,0.6923750042915344,-0.9436194896697998,0.47960662841796875,1.4566105604171753,-0.6083104014396667,-0.9183673858642578,0.5346103310585022,-0.5896413326263428,0.1560591757297516,-0.5357654690742493,-1.400414228439331,2.404715061187744,-1.0977566242218018,0.7428321838378906,0.2578831911087036,-0.04446953907608986,-1.6113553047180176,0.498897910118103,-0.6409952044487,-1.0938477516174316,0.9735395312309265,-0.3863881230354309,0.7992422580718994,-0.40363451838493347,0.1736667901277542,1.053960919380188,-0.7712641358375549,0.7841466665267944,-0.10831412672996521,-0.1079375222325325,-1.6676911115646362,0.6832919120788574,0.48237672448158264,-0.7773799896240234,-0.8295691013336182,1.2179536819458008,2.6351778507232666,-1.5840882062911987,1.4244402647018433,-0.5132889747619629,0.22876591980457306,-0.48711639642715454,-0.5095149278640747,-0.872138500213623,-1.4516632556915283,0.6183382272720337,-0.11813328415155411,0.8511158227920532,-0.3583776354789734,-1.895805835723877,-0.37436649203300476,-0.5444298982620239,0.22358833253383636,-0.17188329994678497,-1.3545390367507935,-1.0815670490264893,-0.4361903667449951,-0.7943606972694397,-0.48574578762054443,0.27143436670303345,-0.6332336068153381,0.5040258169174194,-0.8673935532569885,-0.782768964767456,0.0837223008275032,-0.06441543251276016,-0.4207046627998352,-1.279826045036316,-0.2151685506105423,0.8389050960540771,0.9670289158821106,1.1671738624572754,1.2607091665267944,-2.4294748306274414,1.2757033109664917,0.3213679790496826,-0.060833465307950974,-1.1241252422332764,0.4342974126338959,0.8097804188728333,1.8798108100891113,-0.2672198712825775,-0.565549910068512,0.0017372582806274295,-0.07544030994176865,-1.258367657661438,-0.7409382462501526,-0.9438763856887817,-1.2807257175445557,0.9518284201622009,-1.1337953805923462,-2.120432138442993,0.22559557855129242,-0.14279818534851074,0.4222782552242279,0.048315610736608505,0.40649911761283875,0.6134406328201294,1.805229663848877,-1.0851274728775024,-1.3814337253570557,-0.038089364767074585,0.15053367614746094,0.04321828484535217,1.3480595350265503,0.19411438703536987,0.44410383701324463,0.03028208203613758,-0.712836742401123,-1.0939446687698364,-1.6355870962142944,1.0215243101119995,0.7696039080619812,-1.2482547760009766,-0.9806637763977051,-0.788546085357666,1.8341364860534668,1.907107949256897,0.18882590532302856,0.7263250350952148,-0.21403352916240692,-0.9371282458305359,0.9477192163467407,1.0076669454574585,-0.8952284455299377,0.9432642459869385,-0.4794021546840668,0.5589162111282349,-0.04162276163697243,1.7935649156570435,-0.006890385411679745,1.148590326309204,1.0434856414794922,-0.8877953886985779,-1.8026396036148071,-0.19675306975841522,-0.6882877945899963,-0.7584359049797058,1.62308931350708,-2.354295253753662,-1.4621002674102783,-0.6632240414619446,0.10384256392717361,-0.7868239879608154,-0.22924071550369263,0.06699883937835693,-0.17130252718925476,1.072660207748413,1.7924308776855469,-0.0996035784482956,1.090024709701538,-1.2652931213378906,0.9644789099693298,-0.6493825912475586,1.2838587760925293,-0.15362434089183807,0.24499846994876862,-0.12468533217906952,0.29081225395202637,2.4390785694122314,-1.4257619380950928,-1.2125762701034546,-0.5887723565101624,-0.7350972294807434,0.4335310161113739,-1.0649335384368896,-2.125962972640991,-0.9323625564575195,-0.369053453207016,-0.6305669546127319,-0.4279921352863312,-0.5036119818687439,-1.1157686710357666,-1.1644643545150757,-0.5620168447494507,0.688994288444519,0.5114549994468689,0.5085908770561218,-1.076230525970459,0.6696653962135315,1.0948599576950073,-1.1837676763534546,-0.4693828523159027,-0.7210924029350281,0.020037101581692696,1.2265892028808594,1.2858589887619019,1.2953801155090332,0.8919408321380615,0.7823854088783264,2.861551523208618,-0.42966315150260925,0.8916652798652649,0.16478639841079712,-0.9723158478736877,-3.055049180984497,-0.03700416907668114,1.7574011087417603,0.09559080749750137,-0.48895859718322754,-0.09970489889383316,1.1878681182861328,-0.45315679907798767,-2.1884162425994873,-0.1816391497850418,-0.7643837332725525,-0.7442188262939453,1.5554324388504028,0.40390709042549133,0.42264148592948914,0.8213062286376953,0.6424447298049927,-1.300278663635254,0.14977732300758362,-0.5604838728904724,-0.4918968677520752,0.25533193349838257,0.22918178141117096,-0.48342248797416687,0.634239673614502,-0.3578004837036133,1.7186771631240845,0.7135469317436218,0.5867979526519775,1.4317699670791626,-0.3165729343891144,0.967680037021637,0.17861980199813843,0.7245291471481323,-0.6775828003883362,1.0917028188705444,0.5580805540084839,-1.1289323568344116,0.27531588077545166,-1.2181146144866943,-0.8440837860107422,-1.0175031423568726,0.17767733335494995,0.09634938836097717,0.9276694059371948,0.45222532749176025,-0.5199549198150635,0.6813242435455322,2.487549304962158,0.2648726999759674,0.7139749526977539,0.9456314444541931,1.419528603553772,0.9858567714691162,0.521551787853241,0.7043746113777161,-1.540038824081421,1.5323295593261719,-0.4766887426376343,-2.0362298488616943,0.6309844851493835,0.8091143369674683,-0.4481329023838043,0.9341397881507874,0.08003150671720505,0.1405455619096756,1.3826779127120972,-1.2317745685577393,-1.952722191810608,0.0665636882185936,-0.1806505173444748,-0.4914838969707489,-0.3448430597782135,-0.1857564002275467,-1.3638097047805786,-0.1455204337835312,-2.5453991889953613,-0.23581786453723907,0.1470029205083847,0.9784034490585327,2.1403958797454834,1.189591884613037,-0.19259482622146606,0.82123863697052,0.49346867203712463,-0.9701637625694275,1.1464807987213135,-0.5616987347602844,-0.2934991717338562,0.4584985673427582,0.018212242051959038,0.4293675422668457,-0.5291013121604919,-1.0139071941375732,0.43862679600715637,0.9331457018852234,-0.23814241588115692,-0.4440808594226837,0.14116038382053375,-0.9102709293365479,0.2706383168697357,0.3173407018184662,0.2959335148334503,-0.6345216035842896,1.2341433763504028,0.8953606486320496,-0.5100492835044861,0.3322486877441406,-1.0987502336502075,0.30753523111343384,-0.7608320116996765,1.3928879499435425,2.2050089836120605,-1.3442294597625732,-0.3675779402256012,1.3634060621261597,-0.19115671515464783,1.1351404190063477,0.615919291973114,0.24512536823749542,0.37226518988609314,-0.8782981038093567,0.7208860516548157,-0.2958499789237976,-1.0247026681900024,0.9189699292182922,0.2460792511701584,-2.601365804672241,-0.610709547996521,0.8143560290336609,1.593591570854187,0.9609361290931702,0.8815212845802307,-1.1785478591918945,-0.34141483902931213,0.05110472813248634,1.0810257196426392,-0.2555701434612274,0.19997471570968628,0.9604914784431458,-0.48794233798980713,-1.6684616804122925,-0.33914366364479065,0.9296088218688965,-0.7393581867218018,1.075576901435852,-0.009230880998075008,-1.416421890258789,-0.268746018409729,0.5896756052970886,0.5296149253845215,0.27936869859695435,-0.0013912023277953267,1.455498456954956,0.09754890948534012,1.6063786745071411,-0.8762602806091309,0.8840200901031494,-1.1527800559997559,-1.1892056465148926,-0.3596508800983429,1.718279242515564,-0.8344611525535583,0.2812378704547882,-0.5484965443611145,-1.070860743522644,-0.3080458641052246,0.9389718770980835,1.7616952657699585,-0.7392895221710205,-0.8809601068496704,2.142106294631958,-0.8801842927932739,-0.09615471959114075,-0.45897525548934937,-1.0298004150390625,1.1865971088409424,-0.9831240177154541,0.7642303109169006,-0.18287508189678192,1.6882953643798828,0.9267066121101379,-0.6027300357818604,1.7536238431930542,-0.286888986825943,0.6890559196472168,0.7278988361358643,-1.165966510772705,-0.369354784488678,-0.3890979290008545,-0.06480760872364044,0.8311846852302551,0.8246085047721863,0.4486006796360016,-1.3020507097244263,-0.49218297004699707,-0.019234219565987587,1.9440780878067017,1.047216534614563,-1.5658515691757202,-0.2041017860174179,0.99940425157547,1.9722086191177368,-0.03215055167675018,-0.20497646927833557,2.6904313564300537,-0.3441726565361023,-1.619884967803955,-0.5933698415756226,-0.46350252628326416,1.2143539190292358,0.3520180583000183,-0.24010562896728516,0.6561002731323242,-1.4992058277130127,0.21859784424304962,-0.3124667704105377,0.8894205689430237,0.614348828792572,-0.2208486944437027,0.9000154733657837,1.7359709739685059,-1.1884249448776245,-0.5221073627471924,-0.8343912959098816,-0.20240536332130432,0.09036838263273239,-1.7267787456512451,-0.8635154366493225,-0.5716888308525085,1.262321949005127,1.0245281457901,0.050209347158670425,0.38479307293891907,-0.5593268275260925,0.26455289125442505,-0.8563717007637024,1.1262149810791016,-1.9909895658493042,-1.1614435911178589,-1.0272080898284912,1.1234911680221558,1.1376994848251343,0.9516069889068604,-0.8812536001205444,0.06751696020364761,-0.15029172599315643,0.3282582759857178,-1.0451524257659912,-1.2928811311721802,0.14327001571655273,1.2885992527008057,-1.7011215686798096,1.6836134195327759,0.13131220638751984,0.5892865061759949,1.3567622900009155,-0.8896348476409912,0.684361457824707,-0.24011117219924927,-0.9198178648948669,-0.906449019908905,0.3425145447254181,-1.094793677330017,0.5834999084472656,2.048222780227661,-0.3449050188064575,0.11191421747207642,0.567796528339386,0.3563207983970642,-1.024098515510559,-0.39983728528022766,-0.8649330139160156,0.8911039233207703,1.2331770658493042,0.14851558208465576,0.3556870222091675,-1.5537296533584595,-0.1455947905778885,0.31029170751571655,-0.0844433605670929,0.3752773702144623,-0.2685976028442383,0.13754554092884064,-0.8652359247207642,-0.0279137771576643,0.9766574501991272,-1.106077790260315,0.4454904794692993,-0.6353890895843506,0.21774879097938538,-0.38087329268455505,0.7777339816093445,0.22725701332092285,0.6652620434761047,-0.33570432662963867,0.45171037316322327,-0.35455161333084106,0.35992181301116943,-0.4550999104976654,-1.7496058940887451,0.45688897371292114,-0.8787955045700073,0.48352450132369995,0.600136935710907,0.14609801769256592,0.9484230875968933,3.258664131164551,0.3331044018268585,-0.44811564683914185,0.06444717943668365,0.588725745677948,1.5985959768295288,-0.7217572927474976,0.34135758876800537,-0.37181225419044495,0.1620744913816452,0.5157443284988403,0.08648719638586044,-1.2869378328323364,0.4400234818458557,-2.328477144241333,0.18326936662197113,-0.007269293535500765,0.2325630486011505,0.8044710755348206,1.036828637123108,0.9862289428710938,0.35332000255584717,0.14585822820663452,2.183134078979492,-0.9749444127082825,-1.007943868637085,-0.44973140954971313,0.5541793704032898,-0.11138615757226944,0.30754154920578003,-1.0129928588867188,-0.29534533619880676,0.19789183139801025,-1.587045669555664,-0.9810284376144409,0.1750038117170334,0.5782603621482849,0.6658238768577576,-0.5149280428886414,2.312203884124756,-1.2637290954589844,-0.8092479109764099,-0.4232670068740845,-3.9326257705688477,1.3584476709365845,0.05242326855659485,-1.3718470335006714,-0.4599733054637909,-1.3168866634368896,-0.8427114486694336,-0.3553282916545868,-0.8264727592468262,0.7977186441421509,0.4151539206504822,-0.5220804810523987,0.8154639601707458,0.9670087695121765,-0.8436779975891113,-1.2945972681045532,1.4480400085449219,-0.016500717028975487,0.32550981640815735,-0.1214812844991684,-1.4515891075134277,0.05614598095417023,-1.3036339282989502,-1.434733510017395,-1.2606483697891235,1.6379328966140747,-0.4586813747882843,-1.201501488685608,1.0959253311157227,-0.3327762186527252,0.939836323261261,-0.1143532246351242,0.46848946809768677,-0.5609045624732971,-2.029806137084961,0.45517411828041077,-0.6958673000335693,-0.4768214523792267,-1.7725056409835815,-1.0451281070709229,0.9178222417831421,-0.9007502794265747,-1.2202953100204468,-0.5580161213874817,-0.17198462784290314,0.675487756729126,0.8234268426895142,0.3043506145477295,1.5273746252059937,0.042774803936481476,1.9956154823303223,-0.8029810190200806,-0.9712661504745483,-0.9773228168487549,-0.230597123503685,1.2115318775177002,0.7541894912719727,0.4241723418235779,-0.517724335193634,0.24952952563762665,-0.7404027581214905,1.880211591720581,0.3279389441013336,-1.2249423265457153,-0.8708312511444092,0.5035038590431213,0.4240838289260864,-0.3389408588409424,1.0124239921569824,-1.4958503246307373,-0.19865472614765167,-0.45872586965560913,-0.18912871181964874,0.12798330187797546,0.5838045477867126,-0.04108976200222969,-0.8265421986579895,0.5491076707839966,0.7785388231277466,-0.23896314203739166,-1.7470680475234985,1.9246134757995605,1.8876159191131592,-0.043862950056791306,0.05084230378270149,0.7536593675613403,0.6128837466239929,-2.5916097164154053,-1.5902103185653687,0.7479740381240845,-0.23154987394809723,0.9455417394638062,1.5279871225357056,1.4841021299362183,-0.9892389178276062,1.3055787086486816,-0.1581670045852661,1.103980541229248,0.7627637386322021,-0.1908012181520462,0.16319112479686737,1.0247563123703003,-0.18584465980529785,1.096408486366272,2.2589352130889893,-0.30765005946159363,-0.3860307037830353,-0.6452747583389282,0.02506181225180626,0.46991342306137085,0.2639999985694885,-1.0828553438186646,-0.9128066301345825,1.7066881656646729,-1.684204339981079,-1.680160641670227,1.3570417165756226,0.932377278804779,-0.03425971791148186,1.832110047340393,-0.6244497299194336,0.4949139356613159,0.10305698215961456,0.7789767384529114,-0.02901068888604641,0.2125302255153656,0.0847293809056282,0.966867983341217,0.06085152179002762,0.26142436265945435,-0.6532987952232361,-0.1074138730764389,-0.9731550216674805,0.6062299013137817,0.1768290400505066,1.3109592199325562,-0.4054761528968811,1.6266372203826904,1.3401678800582886,0.6768265962600708,0.6311299800872803,1.0143779516220093,0.37516388297080994,-0.13749723136425018,0.31464049220085144,-0.8871234655380249,1.1748511791229248,-0.5464971661567688,-0.8145356178283691,-0.34177955985069275,0.7689564228057861,-2.058103084564209,-1.6184173822402954,-1.0478357076644897,-0.6193167567253113,1.3625394105911255,0.09503928571939468,-0.30497682094573975,0.37941667437553406,-0.3064177632331848,1.2547938823699951,-0.32890692353248596,2.087536334991455,0.0589144267141819,0.1687210202217102,-1.3101807832717896,-0.5246078968048096,1.833280324935913,0.18233315646648407,-1.6849504709243774,0.19691890478134155,-0.37825271487236023,2.399840831756592,0.24025005102157593,0.7588315010070801,1.253440499305725,-0.17345161736011505,-0.060011010617017746,0.6788840889930725,-2.3555831909179688,-0.17055542767047882,-1.4756416082382202,0.9242185950279236,2.0863420963287354,-1.2209877967834473,-1.167168140411377,2.1289002895355225,1.5617632865905762,0.8673626780509949,-0.706194281578064,1.2466418743133545,-0.9724881052970886,-1.0372732877731323,-0.34267377853393555,-0.22721490263938904,-1.2373826503753662,-0.046932924538850784,0.0367266982793808,-0.19307729601860046,-0.4052365720272064,-0.1476174145936966,1.1811376810073853,2.1668052673339844,0.3747285306453705,0.6706169247627258,0.03230452165007591,-0.979926586151123,1.0902875661849976,1.3046088218688965,1.7756688594818115,1.719758152961731,-0.011150963604450226,-1.0663342475891113,0.9450064301490784,-0.6179295778274536,-0.355049729347229,-0.8930883407592773,-1.8432408571243286,1.0146691799163818,-0.5011445879936218,0.0024333917535841465,-0.5695241689682007,0.4047439396381378,1.4094252586364746,0.9176272749900818,0.8012017607688904,0.5902681946754456,-0.2219998687505722,-0.37130358815193176,-0.24309249222278595,-1.2406543493270874,0.6427062153816223,-1.9668201208114624,0.2230401486158371,-0.3904520869255066,-1.754978060722351,-2.3995635509490967,0.3934878408908844,1.2823855876922607,-0.8602621555328369,-0.3268820643424988,0.3482748568058014,-0.3834855854511261,-1.5732015371322632,-1.2275981903076172,1.79826021194458,1.4268254041671753,1.6538254022598267,0.7730237245559692,-0.7621216773986816,-0.09160813689231873,0.10076021403074265,1.231501817703247,-0.66490238904953,0.6697072386741638,0.0346355214715004,0.8716473579406738,1.5620043277740479,0.7574729919433594,-0.6408457159996033,-1.5931470394134521,-1.2119759321212769,-1.6980317831039429,-0.0071118720807135105,-0.35631319880485535,-1.1210148334503174,-0.20447249710559845,0.10011620819568634,0.3776211738586426,1.7397336959838867,-0.5571206212043762,1.0795592069625854,-0.7920135855674744,1.6924015283584595,-1.4271975755691528,0.24707649648189545,-0.6302551031112671,-0.6302765607833862,-0.9873727560043335,0.7651556730270386,-0.03381114453077316,0.49338170886039734,0.186649888753891,0.07221152633428574,-1.7276065349578857,2.305467367172241,-0.4183981120586395,-0.34530407190322876,0.3887172341346741,0.7804575562477112,-1.075669765472412,-0.5384531021118164,-1.4323238134384155,0.3719768226146698,-0.21050572395324707,0.24652676284313202,1.112273097038269,0.5081735849380493,1.2277096509933472,0.3019731342792511,-0.1358436942100525,-0.360694020986557,-0.6130911111831665,-1.2416750192642212,-0.5013210773468018,-0.013067888095974922,-0.686678946018219,-0.21686622500419617,0.522579550743103,0.2991766333580017,0.3902420103549957,0.8128700852394104,0.13631387054920197,-0.5283836126327515,-2.0887744426727295,-0.110906220972538,-1.0425103902816772,-0.8478606343269348,-0.328167587518692,-0.6507190465927124,0.4566301703453064,-1.0231379270553589,-1.0296120643615723,1.2297284603118896,1.8012077808380127,0.5154747366905212,0.7861674427986145,-0.8765179514884949,-1.9641969203948975,-0.7871938347816467,1.1206295490264893,-1.2102726697921753,-0.48723194003105164,2.098956346511841,-0.07263810187578201,1.0289407968521118,1.216869831085205,-1.0793781280517578,-1.1702510118484497,1.0014169216156006,-0.23529331386089325,-0.24744606018066406,-1.1678129434585571,1.9536190032958984,-0.27737757563591003,-0.7284582257270813,-0.7563788890838623,0.031724963337183,-0.11042562872171402,-0.9399581551551819,1.0023375749588013,0.16226014494895935,0.25492531061172485,0.42337170243263245,-0.6170139908790588,0.3670026957988739,-0.24736200273036957,0.9069309830665588,0.8911151885986328,-0.8548593521118164,-0.1855776011943817,0.4065902829170227,-1.1741054058074951,0.60195392370224,0.6575469970703125,-0.36854758858680725,-1.041934609413147,1.4803757667541504,0.8429512977600098,-0.6556506156921387,-1.967287540435791,1.9865339994430542,0.12760891020298004,0.10171312838792801,-0.06339491903781891,-0.9439318776130676,-0.8380681276321411,-0.5799927115440369,0.046512506902217865,-2.099957227706909,1.4876675605773926,0.020091835409402847,-0.2365083247423172,-0.8493126034736633,-0.48320120573043823,-0.20826226472854614,0.8164370059967041,-0.690855860710144,-1.0399806499481201,-1.9607512950897217,-0.7468166351318359,-0.06803552061319351,-1.6283742189407349,-1.6279016733169556,0.0631699413061142,0.7684991955757141,1.7521353960037231,0.13783331215381622,0.3346886932849884,-0.6481059789657593,-0.31690162420272827,1.989593744277954,0.294742614030838,1.0891424417495728,1.7021054029464722,0.5908800363540649,0.4106661379337311,1.4412399530410767,-0.9052124619483948,-1.8276585340499878,0.14867541193962097,0.781156599521637,-1.6877323389053345,0.3942992687225342,1.0398613214492798,0.3049815595149994,-2.728494582697749E-4,-1.188860297203064,-1.1879905462265015,1.7138018608093262,-0.773181140422821,-0.2905845046043396,3.9520764350891113,3.246614456176758,2.5061469078063965,3.992677927017212,3.7789394855499268,3.894073486328125,2.812879800796509,2.379326105117798,3.977337121963501,4.058145999908447,3.386380910873413,2.628903388977051,1.751974105834961,2.73441481590271,2.7122223377227783,3.675868272781372,2.4869680404663086,2.5647079944610596,2.143075466156006,3.076833963394165,1.4589929580688477,1.808692455291748,3.905909299850464,0.6700875163078308,2.6895880699157715,3.411977767944336,3.6922521591186523,2.0165271759033203,3.1341354846954346,3.299776315689087,3.744814872741699,2.699812650680542,3.4665911197662354,0.7018830180168152,3.1287729740142822,3.166890859603882,3.1626553535461426,2.466391086578369,2.852440118789673,3.3261189460754395,1.6438781023025513,3.1452438831329346,2.4858250617980957,1.5149259567260742,1.9167203903198242,2.2408883571624756,3.7011382579803467,4.277706146240234,2.1342697143554688,2.58743953704834,2.4645392894744873,2.1913177967071533,2.8252384662628174,2.703472137451172,4.261240005493164,3.495603561401367,1.4381437301635742,3.1930136680603027,2.1447150707244873,3.4943490028381348,1.9603978395462036,3.87611722946167,4.024895668029785,3.0674197673797607,3.2333240509033203,2.2900655269622803,2.2397964000701904,3.605006456375122,2.0471887588500977,4.303483486175537,3.430485725402832,3.873502254486084,3.7407984733581543,3.8119518756866455,2.9606199264526367,4.105782985687256,3.8534772396087646,3.1267828941345215,3.922062635421753,2.3410325050354004,4.223661422729492,3.162757396697998,3.332383632659912,2.531632423400879,3.7312071323394775,2.476775646209717,2.5596923828125,3.398717164993286,0.3524409234523773,2.2307276725769043,3.983579397201538,3.50542950630188,3.269033670425415,2.4030494689941406,4.114306926727295,3.461909294128418,2.734152317047119,2.4976532459259033,0.5369756817817688,3.6959071159362793,1.885603427886963,2.7555551528930664,3.113645076751709,2.60461688041687,4.363943099975586,0.8596226572990417,2.5198185443878174,3.6249849796295166,3.522526264190674,3.8304038047790527,2.548133134841919,2.95654296875,3.3592538833618164,3.980621099472046,2.776930809020996,3.0641632080078125,4.08727502822876,3.5932810306549072,2.357357978820801,2.780871868133545,1.4484128952026367,2.7688727378845215,2.582939624786377,2.670274496078491,3.0202183723449707,3.594996213912964,1.3216636180877686,4.2361016273498535,3.7240114212036133,3.5279204845428467,2.716207981109619,3.42842960357666,2.9293429851531982,3.120366334915161,2.6305761337280273,3.1600241661071777,3.3270351886749268,0.9818256497383118,2.3790876865386963,4.143046855926514,3.004422426223755,2.6072847843170166,3.854947805404663,3.710942506790161,2.0722084045410156,2.212334632873535,2.3900251388549805,2.9873504638671875,1.1268694400787354,2.841914653778076,2.1418967247009277,3.524028778076172,2.6388421058654785,1.2504031658172607,3.727360963821411,2.930455207824707,2.0515053272247314,1.5698058605194092,2.983530282974243,4.633949279785156,1.4547383785247803,3.4330005645751953,1.3041410446166992,3.5762693881988525,3.4256093502044678,3.166243553161621,2.2813451290130615,4.516783237457275,2.275200366973877,2.123757839202881,3.918210029602051,3.4059855937957764,3.750673532485962,3.1224570274353027,2.7886526584625244,1.196284532546997,4.310931205749512,1.3619041442871094,1.59965980052948,2.5068936347961426,2.5982542037963867,3.1573543548583984,3.056696891784668,2.6477181911468506,2.1884121894836426,3.3771414756774902,2.661741256713867,1.2659449577331543,3.1405839920043945,3.8369712829589844,2.3759851455688477,2.195888042449951,2.8473267555236816,3.5184640884399414,3.289790153503418,3.4744935035705566,2.918236255645752,4.448429107666016,2.860592842102051,2.6417384147644043,2.8114113807678223,3.343815326690674,3.4754037857055664,3.5394372940063477,1.8996762037277222,2.998969078063965,1.2366958856582642,4.005898475646973,3.672126054763794,2.859553337097168,1.8008843660354614,1.9357696771621704,2.522526264190674,4.347029209136963,3.6064538955688477,2.860629081726074,3.5346219539642334,4.907870292663574,3.5132029056549072,1.7584846019744873,4.48007345199585,1.8522671461105347,1.552081823348999,3.6334664821624756,3.0038087368011475,2.750109910964966,4.077807426452637,2.017129898071289,4.19398832321167,2.62703537940979,2.637939691543579,2.7782039642333984,2.564610004425049,3.447099447250366,3.6200852394104004,2.851830244064331,1.619717001914978,0.7903326153755188,2.7465412616729736,3.1824917793273926,4.743942737579346,2.3998358249664307,2.821364402770996,3.799166202545166,4.120172023773193,2.7466623783111572,4.192564010620117,2.6778316497802734,3.1545376777648926,3.3941543102264404,3.001513957977295,2.7899203300476074,4.344555377960205,3.7806577682495117,2.052316665649414,4.250418663024902,2.6965882778167725,2.562805652618408,1.0590317249298096,3.182384729385376,4.429769039154053,2.7735402584075928,3.1753389835357666,2.075317859649658,3.358910083770752,5.473575115203857,2.2294421195983887,4.666920185089111,2.6262457370758057,3.473499298095703,3.818359136581421,3.1140389442443848,2.96056866645813,3.150970697402954,1.6586672067642212,3.7507498264312744,4.936799049377441,3.3079559803009033,2.9413604736328125,3.1084775924682617,2.9588985443115234,2.656175374984741,2.561569929122925,3.525507926940918,4.398028373718262,2.3747732639312744,2.0176615715026855,3.1754348278045654,3.1253268718719482,2.5112061500549316,2.39339017868042,3.724684238433838,3.001023292541504,3.31254506111145,4.015503406524658,2.0155296325683594,2.388037919998169,2.8050625324249268,2.3517262935638428,2.2058675289154053,3.1642954349517822,3.1620380878448486,4.103822708129883,3.4566636085510254,2.169046401977539,1.7352298498153687,3.4866831302642822,4.203951835632324,3.0588631629943848,2.8928706645965576,1.5957789421081543,2.7941482067108154,4.566840171813965,4.190375804901123,3.75508451461792,2.971684217453003,2.2074637413024902,2.0251805782318115,3.00666880607605,3.879976749420166,2.1123485565185547,2.77744722366333,3.2429120540618896,3.41723370552063,3.020564079284668,4.796547889709473,3.669983148574829,5.143591403961182,2.934999465942383,3.1522791385650635,3.4926645755767822,3.0687010288238525,3.4126975536346436,1.243034839630127,1.6434811353683472,2.702115535736084,3.7885899543762207,2.788602590560913,1.598261833190918,4.393098831176758,3.375309467315674,2.452284336090088,3.4541983604431152,3.543792486190796,2.9912779331207275,2.193885326385498,3.2433626651763916,2.909243106842041,4.84724760055542,3.724203586578369,2.2284011840820313,3.409651756286621,1.977085828781128,1.1201822757720947,4.068655014038086,2.618490695953369,4.232666492462158,4.303360462188721,4.001112937927246,3.749323606491089,3.9344396591186523,2.4852888584136963,4.764927864074707,2.195610523223877,3.229982852935791,2.4874489307403564,3.8773157596588135,1.3072606325149536,3.479444980621338,2.0621445178985596,3.7895214557647705,2.485112428665161,4.026322841644287,2.9550418853759766,3.416376829147339,3.682560920715332,3.369717597961426,2.7771401405334473,3.0510666370391846,2.2775871753692627,5.087810039520264,2.824078321456909,2.370069980621338,2.7469418048858643,2.6981313228607178,3.010453462600708,2.296992540359497,2.4669861793518066,1.890311598777771,2.6484923362731934,2.516233205795288,2.5093131065368652,3.0914604663848877,1.592976689338684,4.0356974601745605,4.263253688812256,2.376410722732544,2.747340202331543,1.5382922887802124,1.7913726568222046,1.9875847101211548,3.368131399154663,1.3094056844711304,3.277754068374634,2.5993189811706543,2.8375377655029297,4.226121425628662,3.187324047088623,2.312406301498413,4.8273773193359375,4.501324653625488,3.825407028198242,2.789017915725708,3.3864641189575195,3.6010003089904785,3.0141096115112305,3.795377731323242,2.34801983833313,2.9305481910705566,0.9194846153259277,2.25030255317688,3.2986397743225098,3.641552686691284,2.019449234008789,4.4486002922058105,1.3314896821975708,1.412123441696167,2.4554073810577393,3.307068347930908,4.870386600494385,5.80687952041626,2.0560829639434814,2.9063360691070557,4.791542053222656,2.540999174118042,2.4239509105682373,1.7216367721557617,4.097425937652588,3.452291250228882,3.1746740341186523,3.0913443565368652,3.464517116546631,4.020097255706787,2.5231881141662598,3.417785406112671,2.5241363048553467,1.939703345298767,2.2004997730255127,0.38078218698501587,1.9297051429748535,2.98443603515625,3.7331087589263916,4.044098377227783,3.2925446033477783,4.840418338775635,2.2187013626098633,2.744936466217041,3.401353120803833,3.101571559906006,1.762679100036621,3.0445942878723145,3.89758038520813,4.503952980041504,3.7353038787841797,4.222720623016357,2.966670036315918,5.219785690307617,3.7724428176879883,2.7382638454437256,2.1960442066192627,4.779440879821777,3.0139501094818115,3.1514198780059814,2.5561342239379883,4.300631999969482,1.05093514919281,4.257420539855957,2.9052534103393555,2.2519829273223877,4.428501605987549,2.9448604583740234,2.1346194744110107,3.6019551753997803,1.5556389093399048,2.4880282878875732,3.001720905303955,2.29919695854187,2.9204752445220947,2.9721128940582275,4.091440200805664,3.2915470600128174,3.3432767391204834,2.255859851837158,1.2455973625183105,3.416440963745117,3.5310041904449463,2.9943690299987793,2.4745869636535645,4.48627233505249,2.342526912689209,2.9031569957733154,2.8282470703125,3.5349183082580566,2.2061946392059326,2.7904624938964844,2.036944627761841,2.2250313758850098,5.572340488433838,2.7682816982269287,3.746875762939453,2.414822578430176,3.5892090797424316,2.781641721725464,3.65567684173584,3.1891961097717285,3.8609819412231445,2.1640682220458984,3.2672431468963623,2.381955146789551,1.318842887878418,4.434728622436523,2.9794328212738037,2.020012617111206,4.176459789276123,2.5943994522094727,3.4490339756011963,4.448251247406006,4.079261302947998,2.490584135055542,1.9248656034469604,3.6735639572143555,3.024110794067383,2.8351762294769287,2.6069438457489014,3.2616288661956787,3.031010866165161,1.8361443281173706,2.3576557636260986,0.5408183336257935,3.2644526958465576,3.279116630554199,2.845316171646118,2.135061740875244,3.6710073947906494,4.333500385284424,2.345364570617676,3.1645138263702393,1.8081914186477661,4.114206314086914,3.627800703048706,1.9428001642227173,2.2125155925750732,2.648205518722534,2.974522352218628,3.401559829711914,2.6764488220214844,3.4146244525909424,1.5092442035675049,2.827483654022217,5.149423122406006,3.6384594440460205,2.442296028137207,1.9185912609100342,1.5466139316558838,2.412538766860962,5.2291669845581055,2.3755509853363037,1.4032306671142578,2.8023195266723633,2.702798366546631,2.0522375106811523,2.640488386154175,3.223280429840088,3.5020432472229004,4.896598815917969,4.242785930633545,4.146297454833984,4.849832534790039,4.081705570220947,4.02158260345459,2.949970245361328,2.5863430500030518,4.030029773712158,2.47550630569458,1.6596800088882446,3.548621892929077,3.5885589122772217,4.421915531158447,1.4350019693374634,2.010826349258423,2.5044350624084473,3.8366332054138184,1.7126977443695068,4.507673740386963,2.2060093879699707,3.055232286453247,2.9622297286987305,2.454824924468994,2.649010419845581,4.629854202270508,3.719251871109009,3.5086565017700195,1.2571711540222168,3.144953966140747,1.4897209405899048,3.6447932720184326,1.2054603099822998,1.8118586540222168,3.9393856525421143,2.2758700847625732,3.0866260528564453,4.09039831161499,2.5924901962280273,2.669728994369507,3.3095710277557373,4.580240249633789,3.9804227352142334,3.872849464416504,4.678703308105469,4.043974876403809,6.097987174987793,3.3278799057006836,2.3776845932006836,3.5820248126983643,3.276190996170044,3.0483622550964355,3.339522123336792,3.3354358673095703,4.590428352355957,3.212695837020874,4.359605312347412,2.213639497756958,2.246551513671875,4.507180690765381,2.2245423793792725,2.313242197036743,2.6678245067596436,3.3134572505950928,2.2751123905181885,4.417294979095459,1.877381443977356,3.3310582637786865,2.773988723754883,2.1698248386383057,1.8274662494659424,3.775878429412842,3.195338487625122,3.304123878479004,1.9546496868133545,1.1844074726104736,2.9010608196258545,2.10974383354187,5.653990745544434,3.9788296222686768,2.2577736377716064,2.7747554779052734,0.8052440285682678,1.236739158630371,4.065108299255371,1.879448652267456,2.672370672225952,2.035083770751953,3.6354048252105713,2.8868606090545654,2.15203857421875,5.2102155685424805,2.244706392288208,3.9865849018096924,2.0527706146240234,3.1127309799194336,3.0601818561553955,1.598866581916809,2.865431785583496,4.998013496398926,1.678626298904419,3.2007126808166504,4.694725513458252,2.627426862716675,2.533816337585449,1.6461973190307617,4.387279987335205,2.952833652496338,2.616429328918457,3.8036792278289795,2.750939130783081,2.700143575668335,1.4259952306747437,3.13374400138855,2.896871566772461,2.865694761276245,4.39956521987915,1.290634274482727,3.3978071212768555,2.9275262355804443,2.976666212081909,4.708298683166504,2.003399610519409,3.204592227935791,4.607931137084961,3.387279748916626,1.6701220273971558,1.8146240711212158,2.2455248832702637,3.4893176555633545,4.026567459106445,1.9956899881362915,2.6140480041503906,5.188666343688965,2.332689046859741,2.4967257976531982,4.336693286895752,2.8651838302612305,1.8611011505126953,4.113992214202881,3.053131341934204,2.8743672370910645,1.8944615125656128,3.4567339420318604,3.7992794513702393,3.085155963897705,1.0776989459991455,2.736734628677368,3.487224578857422,2.130448579788208,3.3502399921417236,2.5232629776000977,4.778636455535889,3.4901106357574463,1.8163477182388306,3.62044358253479,2.74615740776062,3.7319703102111816,3.3205246925354004,2.1706631183624268,1.571088194847107,4.233532905578613,6.397271156311035,2.7039899826049805,2.3112893104553223,3.7027692794799805,4.881030082702637,4.295983791351318,2.956892251968384,3.1146955490112305,1.335890769958496,1.6316219568252563,1.6322636604309082,2.4931960105895996,2.2273178100585938,2.53637957572937,4.873298645019531,1.7229723930358887,3.0366055965423584,3.0662119388580322,3.552825927734375,4.848605632781982,3.115900993347168,3.699211597442627,2.6294877529144287,3.1904921531677246,2.0984771251678467,3.390523672103882,2.546651601791382,2.507624626159668,3.235994338989258,3.752060651779175,2.6780900955200195,3.9711852073669434,3.8873343467712402,3.389155149459839,3.460087776184082,2.507988214492798,2.290994882583618,2.324578046798706,3.1512813568115234,2.7522823810577393,3.2656641006469727,2.6263582706451416,2.528214693069458,3.3946871757507324,4.0073161125183105,3.6065070629119873,2.6776349544525146,3.32277250289917,3.0144295692443848,3.436884880065918,2.8482470512390137,4.17399787902832,2.545776605606079,3.927626848220825,3.1950299739837646,1.9624896049499512,2.9623141288757324,3.996786594390869,4.345454692840576,4.119755744934082,3.933288812637329,3.7909352779388428,3.304953098297119,3.51115345954895,2.55117130279541,1.3287441730499268,4.470535755157471,4.827737808227539,3.3772544860839844,2.6479978561401367,2.997072458267212,4.925848960876465,3.570741653442383,1.1102880239486694,2.1926534175872803,3.0265204906463623,2.1091129779815674,1.1838855743408203,2.574615240097046,4.017999172210693,2.519702672958374,4.02420711517334,1.5874531269073486,5.105405807495117,2.8445324897766113,4.531733512878418,3.567498207092285,3.7995195388793945,2.522902250289917,2.3785722255706787,2.808868408203125,1.9532686471939087,4.017481803894043,4.4584245681762695,2.5172317028045654,2.1459031105041504,4.222134113311768,3.429906129837036,2.132598400115967,2.094919204711914,4.010986328125,2.6109225749969482,4.298761367797852,3.602799892425537,2.4262218475341797,2.463988780975342,4.311343669891357,1.8228644132614136,1.51584792137146,3.8168554306030273,2.1626875400543213,2.0433714389801025,2.4818711280822754,3.432962656021118,3.175443649291992,3.202789068222046,3.099766254425049,2.8804380893707275,2.417646884918213,3.98441743850708,2.3781495094299316,1.6940655708312988,1.4512465000152588,2.3580126762390137,2.4231088161468506,1.8438334465026855,3.7369632720947266,1.1513798236846924,2.7208921909332275,2.773207902908325,2.4186933040618896,2.7796638011932373,2.6460421085357666,4.164993762969971,2.275136709213257,4.077488422393799,3.555159330368042,1.8373254537582397,4.082587242126465,4.096841812133789,3.123729705810547,3.4884026050567627,2.9726037979125977,3.04986572265625,3.3761374950408936,4.734872341156006,3.0911290645599365,1.118104100227356,3.2824196815490723,2.8898427486419678,3.2277841567993164,4.27578592300415,3.9291563034057617,3.0751688480377197,2.044224500656128,3.7894153594970703,4.681305408477783,3.328730821609497,-0.029939087107777596,2.743520975112915,2.4095146656036377,2.6592588424682617,3.176705837249756,5.125969409942627,3.1460189819335938,3.8112287521362305,2.3771209716796875,2.2211227416992188,2.9214024543762207,4.341482162475586,3.0099146366119385,3.6465210914611816,2.8358426094055176,2.941848039627075,3.3335986137390137,3.2070937156677246,3.486420154571533,1.3312933444976807,2.803797483444214,3.3650951385498047,2.5261592864990234,2.860736846923828,3.186230182647705,2.7192039489746094,2.088981866836548,3.6001217365264893,2.8950388431549072,3.1533050537109375,3.655193567276001,1.1003670692443848,3.9331107139587402,4.017577648162842,4.1073760986328125,5.456650733947754,2.5240838527679443,2.732869863510132,2.773934841156006,5.671379566192627,1.7973078489303589,3.7477951049804688,3.2552995681762695,3.15480375289917,2.9979560375213623,1.4352409839630127,4.418618679046631,3.4216468334198,2.5091118812561035,3.661181926727295,2.6585729122161865,2.556609630584717,1.746436357498169,1.6952197551727295,3.9452619552612305,2.800912380218506,5.040439605712891,3.4456629753112793,2.65177321434021,2.392677068710327,3.156064748764038,4.07753324508667,3.6205055713653564,1.4493521451950073,2.2841274738311768,3.684865951538086,0.6256298422813416,3.6251208782196045,5.121704578399658,3.77467679977417,2.5323238372802734,2.366018056869507,4.371649742126465,2.0281155109405518,2.158552408218384,2.5707921981811523,2.441312313079834,3.1821885108947754,3.2766268253326416,2.732682466506958,3.270935535430908,3.5440685749053955,2.509350299835205,2.6198413372039795,3.056870937347412,1.6250587701797485,2.0868592262268066,3.8127729892730713,1.4363282918930054,2.851004123687744,2.7854766845703125,5.317850112915039,3.2975096702575684,1.8001198768615723,2.66096568107605,2.6975436210632324,1.0781493186950684,2.2154269218444824,3.148726463317871,3.688735246658325,2.7351999282836914,1.8717581033706665,4.792626857757568,3.589496612548828,2.0903170108795166,4.361390113830566],
"x2":[3.8570334911346436,1.6543406248092651,2.5843610763549805,2.520259380340576,1.5121219158172607,2.3542463779449463,3.7438812255859375,3.2497732639312744,3.7567107677459717,3.5469157695770264,3.2582905292510986,2.5878829956054688,3.1016101837158203,2.3883392810821533,1.7080203294754028,2.8165650367736816,4.303731918334961,1.0137966871261597,3.202138900756836,3.3294878005981445,3.0201570987701416,3.9479284286499023,4.4933881759643555,2.4714627265930176,2.8679592609405518,2.7527520656585693,-0.20466749370098114,3.2107269763946533,3.1532509326934814,3.4441025257110596,3.9925713539123535,3.383486747741699,0.971818208694458,4.189121246337891,3.7693393230438232,2.0253102779388428,3.1030631065368652,2.7497079372406006,1.0052539110183716,3.4640755653381348,3.6577885150909424,2.5753893852233887,1.5726385116577148,2.4087300300598145,2.962695598602295,3.334679126739502,3.9601659774780273,3.475641965866089,3.6587042808532715,2.5284931659698486,2.416768789291382,3.4912307262420654,2.4913113117218018,3.8342955112457275,4.0214009284973145,1.8555583953857422,2.8630127906799316,4.723758220672607,4.237068176269531,3.0609846115112305,2.92810320854187,3.9321129322052,3.7643651962280273,1.6757704019546509,3.9313910007476807,3.3430886268615723,2.66074275970459,2.9326658248901367,2.1916067600250244,3.8100130558013916,1.4945194721221924,2.6976213455200195,2.1646108627319336,1.7902276515960693,1.4541313648223877,2.9698245525360107,1.9981133937835693,3.4315433502197266,1.820580005645752,3.206744432449341,2.7780895233154297,2.7108089923858643,1.963028907775879,2.225715398788452,4.493465423583984,3.343794584274292,3.828131675720215,2.1356735229492188,2.410186290740967,2.2988345623016357,1.799324870109558,2.068448305130005,3.9234204292297363,2.564579486846924,2.0873544216156006,3.463968276977539,2.3974099159240723,2.9611713886260986,4.727166652679443,2.4200942516326904,1.7726112604141235,2.413668394088745,2.990604877471924,3.891291856765747,4.783810138702393,2.4983479976654053,2.2953081130981445,5.214728355407715,3.6512627601623535,3.196753740310669,2.625091075897217,4.013086795806885,4.371811389923096,5.68624210357666,2.073103666305542,3.4294676780700684,2.3975305557250977,1.504709243774414,0.8865615129470825,1.2953672409057617,3.98795747756958,2.7635295391082764,2.104776382446289,3.2830007076263428,1.7975267171859741,2.424950361251831,1.8329652547836304,4.410603046417236,2.792957305908203,2.801135301589966,2.674374580383301,3.0186173915863037,2.6424665451049805,3.069584608078003,4.18179178237915,3.571349620819092,3.1070621013641357,4.803287982940674,3.5455923080444336,2.91481351852417,1.5079513788223267,1.2330232858657837,2.8391056060791016,1.1985136270523071,2.694242477416992,2.8120405673980713,1.0752520561218262,2.2062087059020996,2.3737998008728027,2.458479166030884,5.167341232299805,4.159895896911621,3.310225009918213,1.8029694557189941,0.6262744069099426,4.682618141174316,2.107085704803467,2.0918619632720947,3.2901041507720947,2.5098683834075928,2.808464527130127,3.197221279144287,3.635375499725342,3.627779483795166,5.947085380554199,4.30323600769043,2.8188986778259277,3.156723976135254,3.188030958175659,1.2436662912368774,2.7428977489471436,3.1435399055480957,2.67907452583313,2.619516134262085,3.0321762561798096,1.2900437116622925,3.911311626434326,1.6783710718154907,3.852987289428711,3.384831428527832,4.101130962371826,3.7353293895721436,3.104576587677002,2.1424994468688965,2.4168827533721924,4.576992988586426,2.9411823749542236,3.160104751586914,3.3725132942199707,3.2639403343200684,3.765738010406494,1.2115460634231567,2.674791097640991,3.017406463623047,2.0663418769836426,1.3939309120178223,2.201589345932007,1.6338657140731812,3.4044833183288574,1.5645263195037842,2.915761709213257,3.2694480419158936,2.4809298515319824,3.881305694580078,4.7221503257751465,1.0534076690673828,4.037050724029541,2.2534449100494385,4.14849853515625,6.3441081047058105,1.6295431852340698,0.7253368496894836,3.391857862472534,3.0774662494659424,2.8323216438293457,3.7893311977386475,2.3454031944274902,2.863006591796875,3.6359658241271973,5.234925746917725,3.5757222175598145,2.886766195297241,4.440325736999512,4.544586181640625,1.5399482250213623,3.0125670433044434,4.481309413909912,1.6784303188323975,2.325030565261841,2.4907870292663574,4.957118511199951,3.7315564155578613,3.621798038482666,2.7558090686798096,3.1384334564208984,3.0930700302124023,2.926079273223877,1.7765007019042969,3.566499710083008,4.374671459197998,3.75372314453125,2.8507676124572754,0.6930493712425232,2.931060791015625,4.015624523162842,4.294278621673584,3.7405388355255127,2.958751916885376,1.8449516296386719,3.128889799118042,2.782782554626465,2.806422233581543,3.8726186752319336,2.867443799972534,3.4390807151794434,3.0844593048095703,3.790560722351074,3.1543776988983154,1.9666045904159546,1.7162532806396484,3.3448538780212402,2.279644012451172,2.844104290008545,3.135809898376465,4.5067901611328125,1.8419480323791504,3.801074504852295,2.8779289722442627,1.2783255577087402,3.3562564849853516,3.0462453365325928,3.134044647216797,0.7229530215263367,4.682688236236572,4.35476016998291,2.8464698791503906,3.7466042041778564,4.396055221557617,3.6889636516571045,3.297755002975464,3.147977113723755,2.6695821285247803,3.623678684234619,3.467594861984253,2.486529588699341,3.438779592514038,2.919379711151123,2.326939582824707,3.9956531524658203,5.514367580413818,4.276966571807861,2.977518320083618,3.111180543899536,1.4433577060699463,2.9683098793029785,1.3809993267059326,1.1219850778579712,2.9825246334075928,1.3797637224197388,1.853416085243225,2.203033924102783,3.7985243797302246,2.6641483306884766,3.123793840408325,1.356631875038147,2.679584264755249,4.210578918457031,2.0837814807891846,2.2638585567474365,4.1314377784729,3.073894500732422,4.472830295562744,3.5503458976745605,0.34437504410743713,3.3691859245300293,1.0222853422164917,2.1624958515167236,4.875255584716797,2.435323476791382,2.769998073577881,3.769604444503784,3.7352817058563232,4.27740478515625,4.240924835205078,1.8622692823410034,3.0984160900115967,3.571838855743408,3.1163065433502197,4.3779802322387695,2.7077150344848633,3.2909913063049316,3.2127842903137207,2.5832741260528564,5.0626654624938965,3.5178234577178955,1.5610942840576172,0.9723593592643738,4.015294551849365,2.7993037700653076,4.386816501617432,4.403507709503174,2.6077382564544678,2.607907772064209,2.0947227478027344,2.5380537509918213,3.204376459121704,4.129551410675049,2.9013240337371826,2.097257375717163,2.5466508865356445,4.492615222930908,2.688035726547241,3.0717861652374268,2.6207568645477295,2.9619386196136475,1.9722325801849365,1.569375991821289,3.336406946182251,3.205739974975586,4.2680745124816895,4.53850793838501,0.7966138124465942,3.7353880405426025,2.6140127182006836,3.947096109390259,2.460444450378418,2.829287052154541,3.1316471099853516,1.0697184801101685,2.3923163414001465,2.7369823455810547,3.2364587783813477,1.969239354133606,3.8257710933685303,3.070561647415161,2.5240468978881836,4.078213691711426,3.0520925521850586,3.2836358547210693,2.493818759918213,2.2593283653259277,4.69883394241333,3.561516761779785,3.5959365367889404,1.3157447576522827,2.744318723678589,1.9230796098709106,2.2396347522735596,4.3619561195373535,3.2369813919067383,2.800325393676758,2.917876720428467,3.0355000495910645,2.9680936336517334,4.963994979858398,4.386032581329346,4.239298343658447,3.2377545833587646,1.1913565397262573,4.095261573791504,3.0301849842071533,2.2127268314361572,1.741025447845459,1.8713328838348389,3.99863862991333,4.030068874359131,3.2913739681243896,3.7139523029327393,4.933935165405273,3.861487865447998,3.997694969177246,4.09545373916626,3.1536686420440674,2.9982755184173584,3.194906234741211,1.3605276346206665,5.143671035766602,3.1470677852630615,1.8967504501342773,3.9156298637390137,4.078049659729004,2.4254884719848633,2.233624219894409,2.484168767929077,3.485383987426758,4.586268901824951,3.8496744632720947,2.1590898036956787,2.5942232608795166,2.1913187503814697,3.5324466228485107,2.9634666442871094,2.9247586727142334,3.2314019203186035,3.892772674560547,1.0880533456802368,3.193571090698242,2.8532564640045166,3.592212200164795,1.6561778783798218,2.604896306991577,2.960500717163086,2.376669406890869,1.6725397109985352,2.2670695781707764,3.1057138442993164,1.300963044166565,2.1934943199157715,4.373931884765625,3.9120934009552,1.5756440162658691,2.051370620727539,0.49967479705810547,2.553270101547241,2.674326181411743,2.052626132965088,2.4323160648345947,1.5899919271469116,4.890424728393555,2.7218918800354004,1.9881688356399536,4.295139789581299,3.1140942573547363,1.9971270561218262,3.086470127105713,5.3087286949157715,1.9703360795974731,1.7477033138275146,2.2682440280914307,3.4483792781829834,2.0238330364227295,2.79634428024292,3.642136812210083,3.3377633094787598,3.882091522216797,2.9427266120910645,2.8354413509368896,1.9280188083648682,3.62805438041687,2.7574386596679688,3.1635069847106934,4.504781246185303,2.3283960819244385,3.0483498573303223,2.8353466987609863,2.00201153755188,2.9253273010253906,3.7084286212921143,1.8461726903915405,2.273404598236084,3.38350772857666,2.4996440410614014,3.369077205657959,3.5914323329925537,2.412290334701538,2.981792688369751,2.1618731021881104,4.588166236877441,3.348904848098755,4.029584884643555,3.5921378135681152,3.113502025604248,3.8982951641082764,4.203975677490234,3.4097607135772705,2.506650924682617,3.3729171752929688,2.6031839847564697,3.0328876972198486,1.903125286102295,2.2288296222686768,2.901949882507324,2.6612720489501953,1.9876071214675903,4.982420444488525,1.5004682540893555,4.369040489196777,2.5752124786376953,3.824235200881958,2.475196123123169,3.9369516372680664,4.462250232696533,3.1857404708862305,4.462700843811035,3.8698630332946777,3.1462273597717285,4.320540428161621,2.4492974281311035,1.8352899551391602,2.7202389240264893,2.8295178413391113,2.9568095207214355,4.940061569213867,3.452993869781494,3.682368278503418,4.16237211227417,3.959351062774658,1.9004799127578735,2.4539859294891357,3.655451536178589,2.4110021591186523,3.298802614212036,2.663576602935791,3.1236014366149902,2.9837591648101807,5.3267412185668945,2.902259588241577,2.0929529666900635,3.5517160892486572,0.728499710559845,2.8880367279052734,5.516584873199463,3.6535961627960205,5.16596794128418,3.224318504333496,2.822890281677246,2.5717830657958984,2.465029239654541,4.528956890106201,4.8684282302856445,1.320165991783142,2.792501926422119,3.4942893981933594,4.372369766235352,2.695266008377075,4.081139087677002,4.28006649017334,2.3543546199798584,-1.0884298086166382,3.2044262886047363,3.421600341796875,4.595246315002441,3.9529576301574707,2.688023805618286,5.39459228515625,1.929527759552002,2.7380411624908447,2.3059308528900146,-1.3301268815994263,4.023591041564941,3.430438280105591,2.3480782508850098,3.029404640197754,2.800428867340088,1.6451631784439087,3.095423698425293,3.0316784381866455,3.719447135925293,4.144376277923584,2.8986833095550537,3.1746203899383545,2.4970316886901855,3.3101751804351807,2.542219638824463,2.3822317123413086,3.439295530319214,3.0953025817871094,3.5230138301849365,0.43577927350997925,2.500546455383301,1.3683608770370483,2.5985050201416016,2.1004621982574463,4.299131393432617,3.0471441745758057,1.6576640605926514,3.5799782276153564,3.243837833404541,3.726957321166992,2.1064000129699707,1.8614214658737183,2.8310768604278564,3.526204824447632,2.6381003856658936,3.750488042831421,3.726578712463379,3.0699563026428223,3.0788958072662354,2.460991382598877,0.9893436431884766,3.183295249938965,2.558553457260132,3.0671494007110596,3.1480400562286377,4.564493179321289,3.1950840950012207,4.266171932220459,2.6083121299743652,4.784953594207764,2.171600580215454,1.566754937171936,1.477523922920227,2.4281957149505615,3.406674861907959,3.260666608810425,4.564538955688477,1.3410085439682007,3.63974666595459,1.67630136013031,3.3072075843811035,2.3933026790618896,2.0567071437835693,1.8014429807662964,1.8017734289169312,4.58919620513916,2.458040952682495,4.511693477630615,2.038475513458252,3.0689542293548584,2.108859062194824,1.6038084030151367,4.025747776031494,4.083582401275635,1.6896476745605469,3.4351840019226074,3.070986032485962,5.013962268829346,2.431694269180298,1.6962494850158691,3.514256715774536,3.5909502506256104,2.880838632583618,4.057580471038818,2.8245034217834473,3.1558949947357178,2.404717445373535,1.984616756439209,3.8932180404663086,3.3542559146881104,2.600830554962158,4.731863021850586,4.238036155700684,4.216812610626221,2.5976831912994385,2.356013536453247,3.455702781677246,0.5287573337554932,2.7713916301727295,3.629669189453125,3.7780463695526123,1.530753254890442,3.006103992462158,3.711042642593384,2.8251659870147705,2.729187250137329,2.8675453662872314,2.554661750793457,3.424027919769287,3.312174081802368,3.2351574897766113,2.647411584854126,4.739905834197998,4.322379112243652,1.7664201259613037,3.806457757949829,3.9873390197753906,2.320312976837158,3.542173147201538,3.2249367237091064,3.2425270080566406,3.090998411178589,4.142181396484375,1.9484269618988037,2.9907596111297607,2.8373100757598877,2.8420004844665527,2.1452829837799072,3.187014579772949,3.734239101409912,3.7827093601226807,2.1175262928009033,4.045808792114258,2.955700635910034,5.301162242889404,2.5552685260772705,4.981704235076904,3.97644305229187,2.4090824127197266,4.842584609985352,3.237633228302002,2.7476344108581543,3.3904502391815186,1.8408827781677246,2.3854598999023438,3.915489673614502,3.4667418003082275,2.885742425918579,3.1746182441711426,3.7291815280914307,1.56629478931427,1.5961496829986572,3.086703062057495,3.511688709259033,3.1332552433013916,3.5089352130889893,1.7345963716506958,4.961456775665283,2.5525283813476563,3.4386680126190186,2.9591994285583496,3.8120806217193604,2.9990556240081787,2.572571277618408,2.3382740020751953,3.0990238189697266,3.863698959350586,3.699704885482788,1.5707228183746338,3.5055253505706787,4.338313102722168,5.87608003616333,2.763725757598877,2.4018032550811768,4.212672710418701,3.525972366333008,2.991215467453003,2.9373250007629395,0.15447714924812317,2.866938591003418,1.7717466354370117,1.4734855890274048,5.951627254486084,2.3823142051696777,3.932537794113159,4.744864463806152,2.648314952850342,3.3710997104644775,3.824507474899292,2.9160523414611816,1.859179973602295,2.169015645980835,4.607776641845703,3.6152963638305664,3.055617570877075,2.4572091102600098,2.1199862957000732,2.9338924884796143,2.1630914211273193,1.998415470123291,2.5609655380249023,5.212905406951904,4.2794013023376465,3.077106237411499,4.008563995361328,3.846137523651123,4.461185932159424,4.187876224517822,4.712913513183594,5.131117343902588,2.325894832611084,1.720170021057129,5.08766508102417,2.0998382568359375,3.385446071624756,2.4903769493103027,0.27318987250328064,4.920876502990723,2.169095277786255,2.059755325317383,2.9433295726776123,3.304802656173706,3.0710349082946777,2.080927848815918,3.5767204761505127,2.3069615364074707,2.6745126247406006,3.0491535663604736,4.0418701171875,3.1848292350769043,2.4069085121154785,2.0351388454437256,4.786187171936035,1.77632474899292,2.89982533454895,0.19915664196014404,3.165982961654663,4.446408748626709,3.3245458602905273,3.779136896133423,3.358722448348999,2.021343469619751,3.400569200515747,2.492833137512207,2.900653123855591,3.295015335083008,4.4260478019714355,1.814439058303833,4.413247108459473,3.3218886852264404,2.4700770378112793,3.2603330612182617,1.388763427734375,3.0343892574310303,3.823073148727417,2.105438232421875,4.85984992980957,3.625061511993408,2.11757230758667,2.027841567993164,2.786816358566284,1.9364038705825806,3.915564775466919,4.606001853942871,2.3566949367523193,5.373746871948242,3.198479175567627,2.4473307132720947,4.39258337020874,3.3674943447113037,2.9529314041137695,2.6360130310058594,2.3887650966644287,3.0586955547332764,3.00365948677063,1.807788372039795,3.363206148147583,2.7844786643981934,3.77836537361145,4.395745277404785,3.1980340480804443,2.4138295650482178,3.2011520862579346,2.520155191421509,6.965792179107666,3.344303607940674,1.798572301864624,2.1026723384857178,3.676543712615967,2.8030426502227783,2.6136298179626465,2.2678756713867188,4.808078765869141,4.693331718444824,4.719127655029297,2.9482998847961426,1.6423542499542236,3.6193630695343018,3.8104710578918457,2.2723171710968018,2.2149133682250977,3.540113925933838,1.332095980644226,3.5550832748413086,2.431690216064453,1.9063893556594849,2.7348246574401855,5.071722030639648,3.4580962657928467,2.1842470169067383,1.6407387256622314,3.427595615386963,2.181568145751953,2.0495998859405518,3.0144052505493164,2.859165668487549,3.063966751098633,2.202540874481201,2.692249059677124,4.320533275604248,3.0040700435638428,2.9171595573425293,2.5114705562591553,4.503451347351074,2.665433406829834,3.983812093734741,2.324104070663452,2.966794013977051,1.9347050189971924,3.7458159923553467,2.647036552429199,2.2834885120391846,4.566812515258789,2.170351982116699,3.5086944103240967,4.091621398925781,2.116001605987549,0.9498555660247803,3.725630044937134,2.853670835494995,1.7352585792541504,1.3943055868148804,4.4519362449646,0.8824111223220825,2.308427333831787,2.2713301181793213,4.189438819885254,2.914746046066284,2.1580965518951416,2.8581321239471436,3.067275047302246,2.759683609008789,3.5016138553619385,3.8918991088867188,3.045652389526367,0.5671831369400024,3.1908297538757324,1.8601962327957153,3.5330536365509033,3.7488343715667725,5.200248718261719,4.291525840759277,3.8773081302642822,5.307101249694824,3.54782772064209,3.64426326751709,3.382220983505249,3.5277841091156006,3.3203463554382324,2.7226953506469727,4.627040863037109,2.208421230316162,2.2941808700561523,1.2931029796600342,3.075134754180908,2.290013074874878,2.4479305744171143,4.0402069091796875,0.673145055770874,3.5587596893310547,2.3056368827819824,1.654518485069275,2.1266841888427734,3.855585813522339,1.557507872581482,2.7257566452026367,2.042847156524658,2.024923801422119,0.5377447009086609,2.597890615463257,2.534329414367676,1.5732163190841675,1.690268874168396,4.20892858505249,4.7142462730407715,4.040938377380371,3.5265111923217773,3.9130029678344727,2.9030208587646484,2.780310869216919,2.3318700790405273,2.330514669418335,3.47231388092041,3.7103512287139893,3.7668960094451904,4.155908584594727,4.946787357330322,1.600740909576416,1.4614977836608887,3.130422592163086,3.952298402786255,3.337360382080078,4.010567665100098,3.1699812412261963,3.508474588394165,1.761148452758789,2.0214085578918457,1.7279599905014038,4.134666919708252,1.8820462226867676,3.5855488777160645,2.0514678955078125,-0.08545580506324768,-1.1926758289337158,0.26521584391593933,-0.7384129166603088,0.7927412986755371,0.6359629034996033,-0.04725376516580582,-1.407912254333496,-0.012108405120670795,-0.6122774481773376,-0.09914355725049973,-1.574663519859314,-0.1718381941318512,-0.3425194323062897,0.5177461504936218,-1.3727946281433105,-0.5571788549423218,1.4671655893325806,-0.561892032623291,-0.4252714216709137,0.20647461712360382,0.11478224396705627,-1.2751870155334473,-0.8471226096153259,2.1414997577667236,1.0159388780593872,0.0756177306175232,0.6228001713752747,-0.03045712411403656,0.12353243678808212,-0.04791736602783203,1.0760518312454224,-0.2418856918811798,-0.5083152055740356,-1.1663291454315186,1.5113606452941895,-0.3268275856971741,-1.5433417558670044,0.9240440130233765,-0.8046121001243591,-0.5254243612289429,-1.2493188381195068,-0.22700442373752594,0.19011445343494415,-0.22431275248527527,0.6991003155708313,1.0306882858276367,0.34975627064704895,0.5675706267356873,0.38011738657951355,0.029338011518120766,-0.05853493884205818,-0.004729903303086758,0.25630027055740356,0.02603861317038536,-0.06235220283269882,0.7212473154067993,0.3664666414260864,-0.8436872959136963,-0.5419794321060181,-0.4983026683330536,0.6148308515548706,-0.9286247491836548,1.5742746591567993,-1.339072346687317,-0.2671947777271271,-0.41990458965301514,0.2400423139333725,1.555648684501648,-0.06328871101140976,0.9928983449935913,0.8449562788009644,-0.5318355560302734,-0.08520260453224182,-0.002369205467402935,-0.47947123646736145,-0.6803123354911804,0.5646637678146362,-0.21900200843811035,-1.5101916790008545,0.19372518360614777,-0.6202924251556396,-1.4768314361572266,-0.6663893461227417,0.41647300124168396,-0.38221439719200134,-0.9164053201675415,-0.7340173721313477,-1.3663357496261597,1.1264480352401733,-0.914483904838562,-0.051172465085983276,0.6484916806221008,0.6101882457733154,0.5097144246101379,-0.9689371585845947,0.15537163615226746,-1.109167218208313,0.8268188238143921,-0.00132747704628855,1.0395222902297974,-0.31087830662727356,-0.12542128562927246,-0.23473668098449707,-0.4575972557067871,0.29458513855934143,0.2746661305427551,0.5472018122673035,-0.7181753516197205,-1.8321844339370728,0.06718897074460983,-0.15688063204288483,0.5156074166297913,0.5901730060577393,0.2921977937221527,0.16516076028347015,2.321864128112793,-1.6981537342071533,-0.014843386597931385,-1.5746409893035889,-0.9587807655334473,1.4591970443725586,0.31679970026016235,0.11680923402309418,-0.6328563690185547,-0.08588546514511108,1.2805958986282349,-1.2361353635787964,0.6030963063240051,0.05825971066951752,2.2238495349884033,1.0396944284439087,0.3202701210975647,-0.2572293281555176,-0.9287672638893127,-1.2212409973144531,-1.213287591934204,-1.730360507965088,0.5953270196914673,0.3105812966823578,-0.25939396023750305,2.8134450912475586,-0.35032474994659424,-2.0591049194335938,-0.3961779773235321,-1.3853187561035156,-0.6098855137825012,-0.3380914628505707,-0.49656832218170166,-0.7785590291023254,0.6935672163963318,0.4921693205833435,-1.3659018278121948,-0.18299086391925812,0.25289732217788696,0.17123419046401978,-0.09372442960739136,-1.2015302181243896,0.8877270817756653,-1.3226072788238525,-0.8818552494049072,-1.270123839378357,0.8098527193069458,-0.7088393568992615,0.8722018003463745,-0.22325225174427032,0.18457424640655518,0.3924563229084015,-0.6042542457580566,1.9182727336883545,0.631024956703186,-0.7048450708389282,0.7897425889968872,1.0825062990188599,0.13463404774665833,0.94434654712677,1.5755398273468018,-0.5892183184623718,0.6853048205375671,-0.00702343974262476,0.08161935210227966,0.36330538988113403,-0.513948380947113,-0.4207517206668854,-0.26075899600982666,-1.1907752752304077,-2.227198362350464,0.570196807384491,0.7666574120521545,-1.4440592527389526,-0.6215006709098816,1.2675451040267944,1.356628656387329,-1.7537689208984375,0.9817643761634827,0.3371114432811737,-0.8421207070350647,-0.41425687074661255,1.1411259174346924,1.1670145988464355,-0.35135412216186523,-0.5039371848106384,0.3265813887119293,-0.795998752117157,0.6321581602096558,-0.19819852709770203,0.36497849225997925,-0.91245436668396,0.8452534675598145,-1.4326344728469849,-2.5037755966186523,-0.49949392676353455,-1.1219053268432617,0.26805418729782104,-3.218547821044922,-0.07133237272500992,0.9954077005386353,-0.7098891139030457,-0.6571522951126099,-0.22461359202861786,-1.2015717029571533,0.3989655077457428,0.8365307450294495,1.0938315391540527,-1.2138526439666748,0.19393165409564972,-1.1831562519073486,0.6708363890647888,-0.16230402886867523,0.04366728290915489,-0.7534789443016052,-0.673504650592804,0.3601832389831543,1.4937602281570435,1.7191869020462036,-1.5500378608703613,-1.2127951383590698,0.20117199420928955,-0.48031482100486755,1.1085442304611206,-1.2399563789367676,-0.8467703461647034,-0.8097932934761047,0.2450380027294159,0.9259259700775146,0.45192641019821167,-0.4871562421321869,-0.444311261177063,0.48238417506217957,-1.4259461164474487,-1.3896188735961914,0.31808629631996155,-0.37262827157974243,0.9924236536026001,0.9072556495666504,0.2088770717382431,0.033587176352739334,-1.6765533685684204,-0.07787705212831497,2.670973300933838,-1.4728624820709229,-1.0212095975875854,-1.187982439994812,-1.7324025630950928,1.8424314260482788,-0.915148913860321,1.445087194442749,0.06626108288764954,0.7612696290016174,0.052037324756383896,0.7966544032096863,0.9638930559158325,-0.3626859188079834,-0.9502875208854675,2.377676248550415,1.7139424085617065,0.26293811202049255,-1.4432073831558228,-1.4582678079605103,1.081685185432434,0.6213810443878174,1.4738596677780151,0.8411464691162109,-0.34974831342697144,0.06565731763839722,-1.8811187744140625,1.4474025964736938,0.5877506136894226,0.31483206152915955,0.6922881603240967,0.5491594076156616,-0.3188512623310089,0.26813775300979614,0.9711475372314453,-0.8191515803337097,-0.43805211782455444,-1.8875199556350708,0.196003258228302,-0.6417611837387085,-0.8916857242584229,-1.1159683465957642,0.8079923391342163,0.31158021092414856,-1.3190455436706543,-1.661688208580017,1.9695971012115479,1.5804301500320435,0.8149339556694031,2.299811363220215,-0.5909916162490845,0.15284033119678497,0.638212263584137,2.43475079536438,0.3983244001865387,1.7051398754119873,-1.8574635982513428,-1.4087315797805786,-1.200310230255127,1.2221877574920654,0.609413206577301,-1.2235877513885498,-0.6218560934066772,-0.28396037220954895,-0.004757335875183344,0.7356649041175842,0.1767355054616928,2.0660998821258545,-0.30285340547561646,0.6801725625991821,2.391446828842163,0.578346848487854,0.8990810513496399,-1.2949215173721313,-0.19296899437904358,0.2499198615550995,-0.1461257040500641,-0.3063325583934784,-1.2054589986801147,0.5854931473731995,0.558823823928833,-0.7896909117698669,-0.8639279007911682,0.6532861590385437,0.5218204259872437,-0.3715149164199829,-0.6173445582389832,-0.16219578683376312,0.7013289332389832,0.2045058012008667,-1.0879054069519043,1.4970239400863647,0.3350023031234741,-1.2650758028030396,0.5626611709594727,-0.9701648354530334,0.6120547652244568,-0.17449253797531128,0.5608741044998169,1.647987723350525,0.9191885590553284,-0.5332318544387817,1.1044989824295044,0.7682303190231323,-0.6442939639091492,1.0425652265548706,0.0031904755160212517,0.1967899203300476,-0.39001575112342834,-1.4882375001907349,0.8885956406593323,-1.218247413635254,-0.5732594132423401,0.5871074199676514,-0.4636715352535248,-0.007559279445558786,1.5729362964630127,-0.01603900082409382,0.22566074132919312,-1.0490639209747314,1.7727051973342896,0.5244286060333252,0.11573567241430283,-1.5747101306915283,-1.0928821563720703,0.962978720664978,0.5881419777870178,-0.46689245104789734,-1.7320476770401,0.17866858839988708,0.5156224966049194,-0.4715624451637268,1.4448133707046509,-0.35169029235839844,0.4296124577522278,0.18705333769321442,-0.37619858980178833,0.3055337369441986,-1.6901845932006836,-1.4033763408660889,-1.359286904335022,-0.2571013867855072,-0.6879646182060242,-1.2210339307785034,1.2515681982040405,0.8075273633003235,0.3732031583786011,1.0321154594421387,0.36371859908103943,0.940157949924469,-0.4806303381919861,-0.7179593443870544,0.4659819006919861,0.08651161193847656,0.7359203696250916,0.30692291259765625,0.4789141118526459,-2.0385890007019043,-1.6475718021392822,-1.0185481309890747,0.23606601357460022,0.028454801067709923,-0.3263612687587738,0.3082301914691925,1.2282522916793823,-0.4843985140323639,0.25624769926071167,0.12521587312221527,-0.6616498231887817,1.1346609592437744,1.4712642431259155,-1.4580048322677612,-0.4359961748123169,0.494758665561676,-0.2569067180156708,0.1703563630580902,-1.9644315242767334,-0.5838404893875122,-0.7323164343833923,-0.8209165930747986,1.800676941871643,1.2649515867233276,0.23114559054374695,-2.187290668487549,0.7225469946861267,0.16616541147232056,-1.5855815410614014,-0.8232100009918213,-3.0554239749908447,-1.0086218118667603,-0.4920421838760376,0.2379276007413864,1.7704068422317505,0.8982294201850891,1.7606275081634521,-1.6608202457427979,-0.14365729689598083,-0.1346794217824936,-0.5733902454376221,-1.840008020401001,-0.007971903309226036,0.9884566068649292,0.4079354405403137,-0.1947249472141266,-0.07677683234214783,-0.019489232450723648,3.1644163131713867,0.4494398534297943,-0.8283478021621704,-0.546057403087616,0.10368603467941284,0.3922342360019684,1.098776936531067,-0.6701880693435669,0.8417726159095764,0.10081544518470764,-0.01944917067885399,-1.6696237325668335,-0.062468212097883224,0.49369147419929504,0.2350408136844635,0.042575668543577194,-0.35660600662231445,-1.5010303258895874,0.30416339635849,0.21672426164150238,-0.31025931239128113,0.22849465906620026,-0.7908174991607666,0.36701059341430664,1.6843607425689697,1.2975528240203857,0.9552384614944458,-0.34725382924079895,-0.9421253800392151,-0.19206400215625763,0.6538951396942139,0.04562540352344513,0.7737326622009277,-0.041317299008369446,-0.06121211498975754,-0.136214479804039,0.8727788925170898,-0.6322447061538696,-0.4786492586135864,0.008574913255870342,-4.2545198812149465E-4,-0.6599252820014954,-0.32946261763572693,1.1245707273483276,-0.2526380121707916,-1.2642416954040527,0.13994422554969788,1.535131812095642,0.2752872407436371,0.7574411630630493,-0.38953667879104614,0.5857853293418884,0.35452786087989807,-0.6925329566001892,0.7606529593467712,-2.8738820552825928,-0.19539284706115723,0.3458051085472107,-0.3730754256248474,1.0481327772140503,0.9575722217559814,-0.4084472358226776,-0.8089836239814758,-1.4502493143081665,-0.5910508036613464,-0.4912594258785248,-0.3478221893310547,-0.47100111842155457,0.9333525896072388,1.4869095087051392,-0.5424892902374268,0.39683616161346436,-1.3586806058883667,-1.5920162200927734,-0.8458778262138367,-1.1188733577728271,-1.2557488679885864,0.7705324292182922,0.3154239356517792,-0.14708289504051208,-0.27511003613471985,-0.8757314085960388,-0.544298529624939,1.0733102560043335,-1.5446187257766724,0.786339521408081,1.2215750217437744,1.2499439716339111,1.2302418947219849,0.40755724906921387,-0.4612060487270355,-1.5722737312316895,1.9157981872558594,1.5787999629974365,0.5370714068412781,0.060667484998703,-1.0941814184188843,-1.3240435123443604,-1.9829649925231934,1.7915208339691162,-0.8147138357162476,-0.010319333523511887,-0.4921071529388428,-9.431330254301429E-4,-1.2095519304275513,-0.32415083050727844,-0.39346396923065186,0.6547550559043884,1.6132067441940308,-0.6452137231826782,1.9107742309570313,2.139324903488159,-0.6478385925292969,-0.3011048436164856,-0.5106630325317383,-1.0206109285354614,0.6109795570373535,-1.6992771625518799,-1.357394814491272,0.6117322444915771,1.3549376726150513,0.3641355335712433,-0.05235317349433899,-1.4218614101409912,-0.7776530385017395,-0.2432011514902115,-0.6394270658493042,0.12175775319337845,0.6867203116416931,-0.18452367186546326,-0.030041271820664406,-0.01603223942220211,-1.3976339101791382,-0.470214307308197,0.3680737316608429,-0.34149256348609924,-1.122313380241394,1.2119508981704712,-0.06238536909222603,-0.7234809398651123,-2.0471251010894775,1.0764555931091309,0.4294329583644867,-0.11818201094865799,-0.2683691084384918,-0.35657426714897156,-0.5353030562400818,-0.6657766103744507,1.1990717649459839,0.6507694721221924,0.2028064727783203,-0.6229743957519531,1.7068371772766113,1.7503446340560913,1.6825692653656006,0.8675619959831238,-0.2539367079734802,0.6222042441368103,-0.7892710566520691,0.08841843903064728,0.34690776467323303,-0.9689706563949585,1.8709219694137573,-0.08179420977830887,1.1334223747253418,-0.7030295133590698,-1.6759341955184937,0.37154150009155273,0.7343598008155823,0.2392721027135849,-0.8347210884094238,0.6787567734718323,0.47738534212112427,-0.3620759844779968,1.1182043552398682,-0.8760577440261841,-0.3896371126174927,-0.27410218119621277,0.3978703022003174,-0.4495004415512085,-0.1924191117286682,1.9751869440078735,-0.622786819934845,0.13898809254169464,-0.08562490344047546,1.9238920211791992,1.762653112411499,0.7386592626571655,-0.7455516457557678,-1.532865285873413,-1.0455217361450195,0.8970580697059631,1.1475179195404053,0.04478730261325836,-0.2151380181312561,0.8893122673034668,-0.11367407441139221,-1.8472216129302979,-0.09705086052417755,1.8531492948532104,-0.015780916437506676,0.06525558233261108,-0.5167363286018372,-0.09277915954589844,-0.8626594543457031,-1.0087276697158813,0.11710243672132492,1.2825512886047363,0.5148549675941467,0.19602839648723602,-0.2231840044260025,1.8135743141174316,-1.4032278060913086,-1.1142388582229614,0.3909541666507721,1.029523491859436,-0.12434069812297821,0.4201233685016632,0.7592350840568542,-0.6579023599624634,-0.8126258850097656,0.6072516441345215,0.08801160752773285,0.3542254865169525,0.3730340898036957,-0.8352180123329163,0.22633086144924164,0.09631694853305817,-0.05054718628525734,1.559363603591919,0.7689530253410339,0.16597917675971985,-3.717817016877234E-4,1.7483247518539429,-1.6373491287231445,-1.08229398727417,-0.9290284514427185,-1.2822656631469727,-0.39091092348098755,-0.9950461387634277,-1.291046380996704,1.502013921737671,-0.6488966941833496,-0.6463115215301514,0.21776777505874634,0.9152680039405823,-0.7718943953514099,1.4639911651611328,-1.445828914642334,-0.4307684898376465,-0.8570674061775208,0.6994082927703857,1.0223480463027954,0.6874001026153564,-2.0760867595672607,-0.8010730743408203,0.5480829477310181,-0.3394046723842621,-0.2949818968772888,-0.5173495411872864,1.9359766244888306,0.10776964575052261,-2.2876882553100586,0.2966564893722534,-0.9394838213920593,-0.2863037586212158,1.749254822731018,-0.666589081287384,-1.6656670570373535,0.18740853667259216,1.1311213970184326,-0.736253559589386,1.2252447605133057,0.1939673125743866,-0.16266398131847382,0.469574511051178,0.7570271492004395,-0.7846665382385254,-2.0130231380462646,-0.3256312608718872,0.020939795300364494,-1.0013524293899536,-1.3979673385620117,-1.6569613218307495,0.23531267046928406,-0.25482964515686035,0.2018527090549469,0.08121330291032791,-1.1660957336425781,1.8278342485427856,-0.6236312389373779,0.5577665567398071,0.6085942983627319,-0.004574151244014502,-0.35056743025779724,-1.0066406726837158,-0.521900475025177,0.32662904262542725,0.3511882722377777,0.696223795413971,-1.1840156316757202,-0.07677369564771652,0.06986066699028015,-1.4848673343658447,0.1493542492389679,-0.3261411488056183,-1.3632140159606934,-0.19272591173648834,-0.4973558187484741,-0.26975712180137634,0.1763463318347931,0.4840264320373535,2.1628060340881348,-0.4994015693664551,-1.2585766315460205,0.482049822807312,-0.3725050091743469,2.418846607208252,-0.8024225831031799,-0.24413199722766876,-0.39070814847946167,1.345114827156067,-0.25936853885650635,0.902184247970581,0.3671664297580719,0.5599637627601624,0.420940101146698,1.0958867073059082,1.0769654512405396,-0.5857429504394531,1.6897379159927368,-0.36726322770118713,2.0912678241729736,1.0834695100784302,0.20726874470710754,-0.7485381364822388,1.252637267112732,0.12477488070726395,0.38371190428733826,0.309408575296402,-0.35478273034095764,0.27156588435173035,1.387637734413147,-2.478724956512451,-1.9653476476669312,1.2605173587799072,-1.5927088260650635,-0.8273798227310181,-0.21195586025714874,-0.9659258723258972,-1.435915470123291,0.27769333124160767,-1.042248249053955,0.3814418911933899,-0.1093127429485321,2.3846752643585205,0.9933419227600098,-0.10727241635322571,-0.34133556485176086,-1.2846715450286865,-0.4385146200656891,1.3015655279159546,-0.4385322332382202,-0.11655391752719879,-0.23701484501361847,0.14638511836528778,0.334328293800354,-0.5775845646858215,-0.5627710223197937,-1.285060167312622,0.1532440334558487,0.617462694644928,-1.0270651578903198,0.367620587348938,0.17455482482910156,1.1035205125808716,1.2802271842956543,-1.834947109222412,-0.4742105305194855,-0.05535416305065155,-0.7062293887138367,-0.43817853927612305,1.2337195873260498,0.5378564596176147,0.009785452857613564,-0.7551069259643555,0.6566060781478882,-0.49640339612960815,-1.073408842086792,1.0740246772766113,0.8186410665512085,-0.5823942422866821,0.4653928577899933,-1.5762747526168823,-0.8645889163017273,0.48957791924476624,0.6925786733627319,-1.4973958730697632,-0.7059435248374939,0.5531742572784424,-1.186244010925293,0.13065126538276672,-1.0137277841567993,1.1567261219024658,0.291582852602005,0.8205046057701111,0.16415461897850037,-0.9632552862167358,1.8784325122833252,-0.14337362349033356,0.26050320267677307,0.7730212807655334,0.08142487704753876,0.8388962745666504,-0.5335803031921387,1.1927974224090576,-0.019675159826874733,1.4849356412887573,0.6545780301094055,-0.2847564220428467,1.2688586711883545,-0.12783488631248474,0.740027129650116,0.6013073325157166,-1.3927781581878662,-0.5367950797080994,0.3796462118625641,0.454927533864975,-0.24265024065971375,0.24370220303535461,-0.4777284860610962,-0.22414657473564148,2.053403377532959,0.6203303337097168,-1.635001540184021,0.3298565447330475,-1.0661064386367798,-0.9372004270553589,-0.6745266914367676,2.7649452686309814,-1.2447930574417114,0.49591347575187683,-1.136352777481079,0.9271945953369141,-0.2435997724533081,-0.624226987361908,-1.007156252861023,-0.2785196006298065,0.5777828693389893,-0.3551282286643982,0.17812283337116241,0.20882821083068848,0.8874526023864746,-0.4246787428855896,-0.7873634696006775,1.1542912721633911,0.5130065083503723,-1.0441244840621948,0.7262082099914551,-1.0893287658691406,0.5920225381851196,-0.527995228767395,-0.3935878276824951,1.0783268213272095,-0.24982163310050964,-0.42680707573890686,0.030504176393151283,1.754546046257019,-0.9442402124404907,0.9160794615745544,0.04022545367479324,-0.6429544687271118,0.33445873856544495,-0.5820097327232361,1.024698257446289,0.975399374961853,-2.1987826824188232,0.42177677154541016,0.36236119270324707,-1.337457299232483,-2.1401236057281494,-0.5599429607391357,0.8130292296409607,0.039657652378082275,0.39324307441711426,0.10475415736436844,0.948593020439148,0.6881227493286133,-1.5435947179794312,-0.5968326926231384,-2.2582223415374756,0.6305264830589294,0.5250352621078491,2.25484037399292,1.8180392980575562,0.5679706335067749,1.5515410900115967,0.2709519565105438,0.1269623339176178,0.38646987080574036,-0.24532346427440643,-0.04744432121515274,-0.3223728835582733,-0.8761098384857178,0.5930487513542175,0.24766159057617188,-0.2112414836883545,0.042604781687259674,0.17950735986232758,1.9303016662597656,-0.3347169756889343,-0.9040852189064026,-0.6546522378921509,-1.3917938470840454,-0.46527090668678284,1.7612299919128418,-1.3584181070327759,1.1849474906921387,0.8288730978965759,1.8639034032821655,1.5236101150512695,0.2594415843486786,-0.6527221202850342,-1.3395134210586548,-0.92900151014328,-2.642366409301758,-1.2915579080581665,0.032763343304395676,0.2657555043697357,-0.34736549854278564,0.9348350763320923,-0.06059419363737106,-1.68440842628479,1.4033628702163696],
"y":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]
},
"mapping":{
"x":"x1",
"y":"x2"
},
"data_meta":{
"series_annotations":[{
"type":"float",
"column":"x1"
},{
"type":"float",
"column":"x2"
},{
"type":"float",
"column":"y"
}]
},
"ggtitle":{
"text":"Simple classification"
},
"kind":"plot",
"scales":[],
"layers":[{
"geom":"point",
"mapping":{
"color":"y"
},
"data_meta":{
},
"data":{
}
}],
"metainfo_list":[],
"spec_id":"3"
};
           window.letsPlotCall(function() { fig = LetsPlot.buildPlotFromProcessedSpecs(plotSpec, containerDiv, sizing); });
       } else {
           fig.updateView({});
       }
   }
   
   const renderImmediately = 
       forceImmediateRender || (
           sizing.width_mode === 'FIXED' && 
           (sizing.height_mode === 'FIXED' || sizing.height_mode === 'SCALED')
       );
   
   if (renderImmediately) {
       renderPlot();
   }
   
   if (!renderImmediately || responsive) {
       // Set up observer for initial sizing or continuous monitoring
       var observer = new ResizeObserver(function(entries) {
           for (let entry of entries) {
               if (entry.contentBoxSize && 
                   entry.contentBoxSize[0].inlineSize > 0) {
                   if (!responsive && observer) {
                       observer.disconnect();
                       observer = null;
                   }
                   renderPlot();
                   if (!responsive) {
                       break;
                   }
               }
           }
       });
       
       observer.observe(containerDiv);
   }
   
   // ----------
   })();
   
   </script></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bước 1: Khai báo các tham số </span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">2</span>       <span class="c1"># Số lượng biến - dim(x1, x2) = 2       </span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">1</span>      <span class="c1"># Số lượng output đầu ra - dim(y) = 1</span>
<span class="c1"># Khai báo weights ban đầu</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)))</span>
<span class="c1"># Khai báo trọng số b ban đầu - default = 0</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,)))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hàm tính kết quả dự báo prediction</span>
<span class="k">def</span><span class="w"> </span><span class="nf">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Trả ra kết quả tính loss function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">square_loss</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
    <span class="n">per_sample_losses</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">targets</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="c1"># Trả ra kết quả average của per_sample_losses</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">per_sample_losses</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tốc độ máy học</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="c1"># Tính loss function với từng giá trị của W &amp; b</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">square_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="c1"># Tính đạo hàm với W &amp; b tại giá trị của X</span>
    <span class="n">grad_loss_wrt_W</span><span class="p">,</span> <span class="n">grad_loss_wrt_b</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
    <span class="c1"># Update W,b theo giá trị mới</span>
    <span class="n">W</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">grad_loss_wrt_W</span> <span class="o">*</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">grad_loss_wrt_b</span> <span class="o">*</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="c1"># Trả ra giá trị loss mới</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training với 40 step</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss at step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loss at step 0: 3.7049
Loss at step 1: 0.3988
Loss at step 2: 0.1537
Loss at step 3: 0.1163
Loss at step 4: 0.1052
Loss at step 5: 0.0981
Loss at step 6: 0.0918
Loss at step 7: 0.0862
Loss at step 8: 0.0810
Loss at step 9: 0.0763
Loss at step 10: 0.0720
Loss at step 11: 0.0680
Loss at step 12: 0.0644
Loss at step 13: 0.0610
Loss at step 14: 0.0580
Loss at step 15: 0.0552
Loss at step 16: 0.0526
Loss at step 17: 0.0503
Loss at step 18: 0.0482
Loss at step 19: 0.0462
Loss at step 20: 0.0444
Loss at step 21: 0.0427
Loss at step 22: 0.0412
Loss at step 23: 0.0399
Loss at step 24: 0.0386
Loss at step 25: 0.0374
Loss at step 26: 0.0364
Loss at step 27: 0.0354
Loss at step 28: 0.0345
Loss at step 29: 0.0337
Loss at step 30: 0.0330
Loss at step 31: 0.0323
Loss at step 32: 0.0317
Loss at step 33: 0.0311
Loss at step 34: 0.0306
Loss at step 35: 0.0301
Loss at step 36: 0.0296
Loss at step 37: 0.0292
Loss at step 38: 0.0289
Loss at step 39: 0.0285
</pre></div>
</div>
</div>
</div>
<p>Như vậy, ta đã hoàn thành việc xây dựng mô hình đơn giản neural network.</p>
</section>
</section>
<section id="keras">
<h2><span class="section-number">3.2. </span>Keras<a class="headerlink" href="#keras" title="Link to this heading">#</a></h2>
<p>Keras cho phép xây dựng mô hình DL nhanh chóng, thành phần của keras có các bước chính sau</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Layers</span></code>: Khai báo kiến trúc của mạng neural. Bao gồm:</p>
<ul>
<li><p>Dữ liệu đầu vào</p></li>
<li><p>Dữ liệu đầu ra</p></li>
<li><p>Hàm activation</p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">NaiveSequential</span><span class="p">([</span>
    <span class="n">NaiveDense</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">NaiveDense</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">NaiveDense</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">NaiveDense</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    <span class="p">])</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Compile</span></code>: Bước khai báo các tham số phục vụ việc tính toán các tham số tối ưu cho mô hình:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Loss</span> <span class="pre">functions</span></code>: Hàm mất mát - là giá trị sẽ được tối ưu trong quá trình training - ví dụ: <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">square</span> <span class="pre">error</span></code>, <code class="docutils literal notranslate"><span class="pre">CategoricalCrossentropy</span></code>,...</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Optimizer</span></code>: Thuật toán cho phép tối ưu, là các biến thể khác nhau của Stochastic Gradient Descent (SGD) như <code class="docutils literal notranslate"><span class="pre">Adam</span></code>, <code class="docutils literal notranslate"><span class="pre">SGD</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Metrics</span></code>: Chỉ số dùng để đo lường sự thành công của mô hình. Không giống như <code class="docutils literal notranslate"><span class="pre">loss</span> <span class="pre">function</span></code>, chỉ số này không được đo lường trực tiếp thông qua quá trình xây dựng mô hình như <code class="docutils literal notranslate"><span class="pre">AUC</span></code>, <code class="docutils literal notranslate"><span class="pre">CategoricalAccuracy</span></code></p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mean_squared_error&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>Lưu ý</strong>: Metrics là chỉ số ta muốn sử dụng để đo lường sự thành công của mô hình - đặc tính của chỉ số này thường là càng cao càng tốt. Tuy nhiên, chỉ số này không dễ dàng để có thể tối ưu mà phải sử dụng thông qua một chỉ số khác là <code class="docutils literal notranslate"><span class="pre">loss</span> <span class="pre">function</span></code></p>
<p>Ví dụ: Mục tiêu cần tối ưu là mục tiêu trừu tượng <em>gia tăng sự giàu có cho mỗi người dân</em> - nếu không có loss function, rất có thể sẽ đưa ra phương án tiêu diệt một số lượng lớn người dân!</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fit</span></code>: Bước trực tiếp xây dựng và tối ưu hóa mô hình</p>
<ul>
<li><p>data: input &amp; output</p></li>
<li><p>epoch: là số lần toàn bộ dữ liệu được huấn luyện (theo chiều dọc) - epoch lớn sẽ cho mô hình học đi học lại dữ liệu nhiều lần, dễ bị overfitting</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batchsize</span></code>: Batch size là số lượng mẫu dữ liệu được đưa vào mô hình để huấn luyện trong một lần truyền tiến (forward pass) và truyền ngược (backward pass). Một batch là một tập hợp con của tập dữ liệu huấn luyện.</p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span>
<span class="p">)</span>
</pre></div>
</div>
<p><img alt="" src="_images/p03-01-batch-epoch.ppm" /></p>
</section>
<section id="cac-mo-hinh-co-ban">
<h2><span class="section-number">3.3. </span>Các mô hình cơ bản<a class="headerlink" href="#cac-mo-hinh-co-ban" title="Link to this heading">#</a></h2>
<p>Trong nội dung tiếp theo, ta sẽ thực hiện 3 mô hình cơ bản của học máy:</p>
<ul class="simple">
<li><p>Phân loại nhị phân - binary classification</p></li>
<li><p>Phân loại nhiều nhóm</p></li>
<li><p>Bài toán hồi quy - regression</p></li>
</ul>
<section id="phan-loai-nhi-phan">
<h3><span class="section-number">3.3.1. </span>Phân loại nhị phân<a class="headerlink" href="#phan-loai-nhi-phan" title="Link to this heading">#</a></h3>
<p>Trong ví dụ này, ta sử dụng dữ liệu <code class="docutils literal notranslate"><span class="pre">IMDB</span></code> review, chứa các nội dung đánh giá phim với 50% <code class="docutils literal notranslate"><span class="pre">positive</span></code> &amp; 50% <code class="docutils literal notranslate"><span class="pre">negative</span></code>. Dữ liệu review đã được chuyển đổi thành dạng số với mỗi số đại diện cho 1 từ trong từ điển.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">imdb</span>
<span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz
<span class=" -Color -Color-Bold">17464789/17464789</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 0us/step
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(25000,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Review đầu tiên</span>
<span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1,
 14,
 22,
 16,
 43,
 530,
 973,
 1622,
 1385,
 65,
 458,
 4468,
 66,
 3941,
 4,
 173,
 36,
 256,
 5,
 25,
 100,
 43,
 838,
 112,
 50,
 670,
 2,
 9,
 35,
 480,
 284,
 5,
 150,
 4,
 172,
 112,
 167,
 2,
 336,
 385,
 39,
 4,
 172,
 4536,
 1111,
 17,
 546,
 38,
 13,
 447,
 4,
 192,
 50,
 16,
 6,
 147,
 2025,
 19,
 14,
 22,
 4,
 1920,
 4613,
 469,
 4,
 22,
 71,
 87,
 12,
 16,
 43,
 530,
 38,
 76,
 15,
 13,
 1247,
 4,
 22,
 17,
 515,
 17,
 12,
 16,
 626,
 18,
 2,
 5,
 62,
 386,
 12,
 8,
 316,
 8,
 106,
 5,
 4,
 2223,
 5244,
 16,
 480,
 66,
 3785,
 33,
 4,
 130,
 12,
 16,
 38,
 619,
 5,
 25,
 124,
 51,
 36,
 135,
 48,
 25,
 1415,
 33,
 6,
 22,
 12,
 215,
 28,
 77,
 52,
 5,
 14,
 407,
 16,
 82,
 2,
 8,
 4,
 107,
 117,
 5952,
 15,
 256,
 4,
 2,
 7,
 3766,
 5,
 723,
 36,
 71,
 43,
 530,
 476,
 26,
 400,
 317,
 46,
 7,
 4,
 2,
 1029,
 13,
 104,
 88,
 4,
 381,
 15,
 297,
 98,
 32,
 2071,
 56,
 26,
 141,
 6,
 194,
 7486,
 18,
 4,
 226,
 22,
 21,
 134,
 476,
 26,
 480,
 5,
 144,
 30,
 5535,
 18,
 51,
 36,
 28,
 224,
 92,
 25,
 104,
 4,
 226,
 65,
 16,
 38,
 1334,
 88,
 12,
 16,
 283,
 5,
 16,
 4472,
 113,
 103,
 32,
 15,
 16,
 5345,
 19,
 178,
 32]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">word_index</span> <span class="o">=</span> <span class="n">imdb</span><span class="o">.</span><span class="n">get_word_index</span><span class="p">()</span>
<span class="n">reverse_word_index</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="p">[(</span><span class="n">value</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
<span class="c1"># Review đầu tiên</span>
<span class="n">decoded_review</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="p">[</span><span class="n">reverse_word_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;?&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Nội dung review</span>
<span class="n">decoded_review</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&quot;? this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy&#39;s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&#39;t you think the whole story was so lovely because it was true and was someone&#39;s life after all that was shared with us all&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Review thứ 2</span>
<span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="p">[</span><span class="n">reverse_word_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;?&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&quot;? big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i&#39;ve seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it&#39;s just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn&#39;t close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80&#39;s and have a good old laugh at how bad everything was back then&quot;
</pre></div>
</div>
</div>
</div>
<p>Ta chưa thể xây dựng mô hình trực tiếp mà phải chuyển đổi đổi thành định dạng dữ liệu có cùng kích thước dưới dạng ma trận 0-1 có kích thước 25000 x 10000 (25000 lượt review x 10000 các từ có trong 25000 lượt review này)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="k">def</span><span class="w"> </span><span class="nf">vectorize_sequences</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    <span class="c1"># Tạo ma trận 0</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">),</span> <span class="n">dimension</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sequences</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">sequence</span><span class="p">:</span>
            <span class="c1"># Xác định vị trí tồn tại word để đặt bằng 1</span>
            <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">results</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">vectorize_sequences</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">vectorize_sequences</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0., 1., 1., ..., 0., 0., 0.],
       [0., 1., 1., ..., 0., 0., 0.],
       [0., 1., 1., ..., 0., 0., 0.],
       ...,
       [0., 1., 1., ..., 0., 0., 0.],
       [0., 1., 1., ..., 0., 0., 0.],
       [0., 1., 1., ..., 0., 0., 0.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="n">y_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1., 0., 0., ..., 0., 1., 0.], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>Ta có thể xây dựng mô hình đơn giản với kiến trúc như sau:</p>
<p><img alt="" src="_images/p01-03-binary-classification.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">layers</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="c1"># Output định dạng xác suất với hàn sigmoid</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_val</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
<span class="n">partial_x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:]</span>
<span class="n">y_val</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
<span class="n">partial_y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Xây dựng mô hình</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">partial_x_train</span><span class="p">,</span>
                    <span class="n">partial_y_train</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 27ms/step - accuracy: 0.6946 - loss: 0.6043 - val_accuracy: 0.8548 - val_loss: 0.4212
Epoch 2/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 7ms/step - accuracy: 0.8906 - loss: 0.3597 - val_accuracy: 0.8463 - val_loss: 0.3722
Epoch 3/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 7ms/step - accuracy: 0.9147 - loss: 0.2671 - val_accuracy: 0.8767 - val_loss: 0.3146
Epoch 4/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9309 - loss: 0.2142 - val_accuracy: 0.8779 - val_loss: 0.2996
Epoch 5/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9431 - loss: 0.1779 - val_accuracy: 0.8876 - val_loss: 0.2767
Epoch 6/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9484 - loss: 0.1570 - val_accuracy: 0.8854 - val_loss: 0.2884
Epoch 7/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9604 - loss: 0.1280 - val_accuracy: 0.8783 - val_loss: 0.3057
Epoch 8/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 7ms/step - accuracy: 0.9659 - loss: 0.1158 - val_accuracy: 0.8842 - val_loss: 0.2976
Epoch 9/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9721 - loss: 0.0977 - val_accuracy: 0.8777 - val_loss: 0.3225
Epoch 10/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9771 - loss: 0.0870 - val_accuracy: 0.8800 - val_loss: 0.3276
Epoch 11/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9820 - loss: 0.0718 - val_accuracy: 0.8789 - val_loss: 0.3409
Epoch 12/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9881 - loss: 0.0597 - val_accuracy: 0.8796 - val_loss: 0.3657
Epoch 13/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9890 - loss: 0.0546 - val_accuracy: 0.8771 - val_loss: 0.3784
Epoch 14/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 8ms/step - accuracy: 0.9917 - loss: 0.0441 - val_accuracy: 0.8754 - val_loss: 0.4116
Epoch 15/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9935 - loss: 0.0379 - val_accuracy: 0.8754 - val_loss: 0.4204
Epoch 16/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9927 - loss: 0.0355 - val_accuracy: 0.8731 - val_loss: 0.4404
Epoch 17/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9966 - loss: 0.0272 - val_accuracy: 0.8723 - val_loss: 0.4671
Epoch 18/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 7ms/step - accuracy: 0.9960 - loss: 0.0267 - val_accuracy: 0.8646 - val_loss: 0.5104
Epoch 19/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9979 - loss: 0.0202 - val_accuracy: 0.8721 - val_loss: 0.5155
Epoch 20/20
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - accuracy: 0.9992 - loss: 0.0148 - val_accuracy: 0.8646 - val_loss: 0.5809
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="n">history_dict</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span>
<span class="n">loss_values</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span>
<span class="n">val_loss_values</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_values</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss_values</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss_values</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training and validation loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/0181b579facb3afde0b9e1d9c287a9cad71dba8d73037422dc2bd0979461f1e7.png"><img alt="_images/0181b579facb3afde0b9e1d9c287a9cad71dba8d73037422dc2bd0979461f1e7.png" src="_images/0181b579facb3afde0b9e1d9c287a9cad71dba8d73037422dc2bd0979461f1e7.png" style="width: 640px; height: 480px;" />
</a>
</div>
</div>
<p>Với kết quả như trên, ta có thể thấy hàm <code class="docutils literal notranslate"><span class="pre">loss</span> <span class="pre">function</span></code> giảm liên tục trên tập train nhưng tăng dần ở validation với mức epoch = 5. Ta có thể xây dựng lại mô hình như sau</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
            <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/4
<span class=" -Color -Color-Bold">49/49</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 4ms/step - accuracy: 0.7274 - loss: 0.5762
Epoch 2/4
<span class=" -Color -Color-Bold">49/49</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.8986 - loss: 0.3038
Epoch 3/4
<span class=" -Color -Color-Bold">49/49</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9175 - loss: 0.2295
Epoch 4/4
<span class=" -Color -Color-Bold">49/49</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - accuracy: 0.9315 - loss: 0.1900
<span class=" -Color -Color-Bold">782/782</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 1ms/step - accuracy: 0.8840 - loss: 0.2837
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.28319352865219116, 0.8858399987220764]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential_4"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ dense_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">16</span>)             │       <span style="color: #00af00; text-decoration-color: #00af00">160,016</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">16</span>)             │           <span style="color: #00af00; text-decoration-color: #00af00">272</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)              │            <span style="color: #00af00; text-decoration-color: #00af00">17</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">320,612</span> (1.22 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">160,305</span> (626.19 KB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Optimizer params: </span><span style="color: #00af00; text-decoration-color: #00af00">160,307</span> (626.20 KB)
</pre>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dự báo trên tập dữ liệu mới</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">782/782</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 1ms/step
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.25915012],
       [0.9997451 ],
       [0.8726964 ],
       ...,
       [0.13297063],
       [0.07732651],
       [0.64449096]], dtype=float32)
</pre></div>
</div>
</div>
</div>
</section>
<section id="mo-hinh-phan-loai-nhieu-nhom">
<h3><span class="section-number">3.3.2. </span>Mô hình phân loại nhiều nhóm<a class="headerlink" href="#mo-hinh-phan-loai-nhieu-nhom" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">reuters</span>
<span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">reuters</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span>
<span class="n">num_words</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3 dòng đầu tiên</span>
<span class="n">train_data</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]),
       list([1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]),
       list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12])],
      dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([3, 4, 3], dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Giá trị của labels</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">unique_value</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_labels</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">value</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique_value</span><span class="p">,</span> <span class="n">counts</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">, Count: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Value: 0, Count: 55
Value: 1, Count: 432
Value: 2, Count: 74
Value: 3, Count: 3159
Value: 4, Count: 1949
Value: 5, Count: 17
Value: 6, Count: 48
Value: 7, Count: 16
Value: 8, Count: 139
Value: 9, Count: 101
Value: 10, Count: 124
Value: 11, Count: 390
Value: 12, Count: 49
Value: 13, Count: 172
Value: 14, Count: 26
Value: 15, Count: 20
Value: 16, Count: 444
Value: 17, Count: 39
Value: 18, Count: 66
Value: 19, Count: 549
Value: 20, Count: 269
Value: 21, Count: 100
Value: 22, Count: 15
Value: 23, Count: 41
Value: 24, Count: 62
Value: 25, Count: 92
Value: 26, Count: 24
Value: 27, Count: 15
Value: 28, Count: 48
Value: 29, Count: 19
Value: 30, Count: 45
Value: 31, Count: 39
Value: 32, Count: 32
Value: 33, Count: 11
Value: 34, Count: 50
Value: 35, Count: 10
Value: 36, Count: 49
Value: 37, Count: 19
Value: 38, Count: 19
Value: 39, Count: 24
Value: 40, Count: 36
Value: 41, Count: 30
Value: 42, Count: 13
Value: 43, Count: 21
Value: 44, Count: 12
Value: 45, Count: 18
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Map lại nội dung đánh giá</span>
<span class="n">word_index</span> <span class="o">=</span> <span class="n">reuters</span><span class="o">.</span><span class="n">get_word_index</span><span class="p">()</span>
<span class="n">reverse_word_index</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">value</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
<span class="n">decoded_newswire</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">reverse_word_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;?&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json
<span class=" -Color -Color-Bold">550378/550378</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">22s</span> 40us/step
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]),
       list([1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]),
       list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12]),
       ...,
       list([1, 141, 3890, 387, 81, 8, 16, 1629, 10, 340, 1241, 850, 31, 56, 3890, 691, 9, 1241, 71, 9, 5985, 2, 2, 699, 2, 2, 2, 699, 244, 5945, 4, 49, 8, 4, 656, 850, 33, 2993, 9, 2139, 340, 3371, 1493, 9, 2, 22, 2, 1094, 687, 83, 35, 15, 257, 6, 57, 9190, 7, 4, 5956, 654, 5, 2, 6191, 1371, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12]),
       list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 3614, 18, 14, 74, 134, 5131, 18, 88, 2321, 72, 11, 14, 1842, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 3237, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 1325, 6, 1532, 142, 971, 6463, 43, 359, 5, 4, 326, 753, 364, 17, 12]),
       list([1, 227, 2406, 91, 2, 125, 2855, 21, 4, 3976, 76, 7, 4, 757, 481, 3976, 790, 5259, 5654, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 6917, 1688, 340, 7, 194, 9411, 6, 1894, 21, 127, 2151, 2394, 1456, 6, 3034, 4, 329, 433, 7, 65, 87, 1127, 10, 8219, 1475, 290, 9, 21, 567, 16, 1926, 24, 4, 76, 209, 30, 4033, 6655, 5654, 8, 4, 60, 8, 4, 966, 308, 40, 2575, 129, 2, 295, 277, 1071, 9, 24, 286, 2114, 234, 222, 9, 4, 906, 3994, 8519, 114, 5758, 1752, 7, 4, 113, 17, 12])],
      dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train</span> <span class="o">=</span> <span class="n">vectorize_sequences</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">vectorize_sequences</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">to_categorical</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Shape y_train</span>
<span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8982, 46)
</pre></div>
</div>
</div>
</div>
<p>Khác với các mô hình họ cây thông thường, nhóm neural network sẽ convert định dạng <code class="docutils literal notranslate"><span class="pre">train_labels</span></code> (n, 1) thành định dạng bảng (n, 46) với mỗi cột là một labels mới định dạng 0-1</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Kết quả sau khi vectorize</span>
<span class="n">x_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0., 1., 1., ..., 0., 0., 0.],
       [0., 1., 1., ..., 0., 0., 0.],
       [0., 1., 1., ..., 0., 0., 0.],
       ...,
       [0., 1., 1., ..., 0., 0., 0.],
       [0., 1., 1., ..., 0., 0., 0.],
       [0., 1., 1., ..., 0., 0., 0.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8982, 10000)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])
</pre></div>
</div>
</div>
</div>
<p>Khi xây dựng mô hình <code class="docutils literal notranslate"><span class="pre">multi-classification</span></code>, kiến trúc tương tự như mô hình binary classification. Tuy nhiên, với việc gia tăng số lượng nhãn (<code class="docutils literal notranslate"><span class="pre">labels</span></code>), ở layer cuối, ta có thể dùng softmax với 46 neural</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">layers</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">46</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    <span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Xây dựng mô hình</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ dense (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                   │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │       <span style="color: #00af00; text-decoration-color: #00af00">640,064</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">4,160</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">46</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">2,990</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">647,214</span> (2.47 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">647,214</span> (2.47 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 27ms/step - accuracy: 0.8248 - loss: 0.0256 - val_accuracy: 0.7533 - val_loss: 0.0344
Epoch 2/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8300 - loss: 0.0246 - val_accuracy: 0.7538 - val_loss: 0.0344
Epoch 3/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 11ms/step - accuracy: 0.8211 - loss: 0.0259 - val_accuracy: 0.7565 - val_loss: 0.0340
Epoch 4/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8297 - loss: 0.0247 - val_accuracy: 0.7578 - val_loss: 0.0338
Epoch 5/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.8337 - loss: 0.0243 - val_accuracy: 0.7569 - val_loss: 0.0337
Epoch 6/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.8323 - loss: 0.0241 - val_accuracy: 0.7578 - val_loss: 0.0337
Epoch 7/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.8439 - loss: 0.0231 - val_accuracy: 0.7622 - val_loss: 0.0336
Epoch 8/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 11ms/step - accuracy: 0.8412 - loss: 0.0234 - val_accuracy: 0.7609 - val_loss: 0.0333
Epoch 9/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.8445 - loss: 0.0227 - val_accuracy: 0.7618 - val_loss: 0.0335
Epoch 10/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8421 - loss: 0.0231 - val_accuracy: 0.7609 - val_loss: 0.0331
Epoch 11/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8463 - loss: 0.0223 - val_accuracy: 0.7640 - val_loss: 0.0331
Epoch 12/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - accuracy: 0.8534 - loss: 0.0215 - val_accuracy: 0.7609 - val_loss: 0.0331
Epoch 13/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 11ms/step - accuracy: 0.8529 - loss: 0.0215 - val_accuracy: 0.7636 - val_loss: 0.0330
Epoch 14/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8596 - loss: 0.0207 - val_accuracy: 0.7631 - val_loss: 0.0331
Epoch 15/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8660 - loss: 0.0206 - val_accuracy: 0.7622 - val_loss: 0.0329
Epoch 16/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 18ms/step - accuracy: 0.8643 - loss: 0.0203 - val_accuracy: 0.7640 - val_loss: 0.0328
Epoch 17/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 17ms/step - accuracy: 0.8670 - loss: 0.0201 - val_accuracy: 0.7671 - val_loss: 0.0328
Epoch 18/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 16ms/step - accuracy: 0.8716 - loss: 0.0196 - val_accuracy: 0.7689 - val_loss: 0.0328
Epoch 19/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 19ms/step - accuracy: 0.8692 - loss: 0.0195 - val_accuracy: 0.7694 - val_loss: 0.0326
Epoch 20/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 19ms/step - accuracy: 0.8761 - loss: 0.0189 - val_accuracy: 0.7671 - val_loss: 0.0327
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dự báo tập mới</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">71/71</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 2ms/step - accuracy: 0.7709 - loss: 0.0322
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.032673172652721405, 0.767141580581665]
</pre></div>
</div>
</div>
</div>
<p>Như vậy, với mô hình trên, ta chỉ đạt được độ chính xác 77% khi dự báo trên tập mới</p>
<hr class="docutils" />
<p>Ta có thể tăng thêm 1 layers cho mô hình và đánh giá độ chính xác</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_2</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">46</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    <span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_2</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential_6"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ dense_22 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ ?                      │   <span style="color: #00af00; text-decoration-color: #00af00">0</span> (unbuilt) │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_23 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ ?                      │   <span style="color: #00af00; text-decoration-color: #00af00">0</span> (unbuilt) │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_24 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ ?                      │   <span style="color: #00af00; text-decoration-color: #00af00">0</span> (unbuilt) │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_25 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ ?                      │   <span style="color: #00af00; text-decoration-color: #00af00">0</span> (unbuilt) │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Xây dựng mô hình</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 24ms/step - accuracy: 0.0442 - loss: 0.5814 - val_accuracy: 0.0467 - val_loss: 0.1905
Epoch 2/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0995 - loss: 0.1484 - val_accuracy: 0.4550 - val_loss: 0.0926
Epoch 3/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.3901 - loss: 0.0876 - val_accuracy: 0.5013 - val_loss: 0.0770
Epoch 4/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.4745 - loss: 0.0731 - val_accuracy: 0.5147 - val_loss: 0.0665
Epoch 5/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.5184 - loss: 0.0637 - val_accuracy: 0.5258 - val_loss: 0.0608
Epoch 6/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.5314 - loss: 0.0586 - val_accuracy: 0.5632 - val_loss: 0.0569
Epoch 7/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 11ms/step - accuracy: 0.5504 - loss: 0.0558 - val_accuracy: 0.5579 - val_loss: 0.0546
Epoch 8/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.5735 - loss: 0.0526 - val_accuracy: 0.5904 - val_loss: 0.0521
Epoch 9/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.5969 - loss: 0.0506 - val_accuracy: 0.6282 - val_loss: 0.0504
Epoch 10/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6261 - loss: 0.0486 - val_accuracy: 0.6416 - val_loss: 0.0491
Epoch 11/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6434 - loss: 0.0476 - val_accuracy: 0.6483 - val_loss: 0.0484
Epoch 12/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - accuracy: 0.6685 - loss: 0.0451 - val_accuracy: 0.6652 - val_loss: 0.0471
Epoch 13/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.6786 - loss: 0.0448 - val_accuracy: 0.6674 - val_loss: 0.0462
Epoch 14/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6823 - loss: 0.0432 - val_accuracy: 0.6772 - val_loss: 0.0453
Epoch 15/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6915 - loss: 0.0425 - val_accuracy: 0.6803 - val_loss: 0.0443
Epoch 16/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.6972 - loss: 0.0415 - val_accuracy: 0.6852 - val_loss: 0.0434
Epoch 17/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.7024 - loss: 0.0404 - val_accuracy: 0.6817 - val_loss: 0.0429
Epoch 18/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.7029 - loss: 0.0393 - val_accuracy: 0.6870 - val_loss: 0.0421
Epoch 19/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7113 - loss: 0.0385 - val_accuracy: 0.6923 - val_loss: 0.0416
Epoch 20/20
<span class=" -Color -Color-Bold">18/18</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.7202 - loss: 0.0371 - val_accuracy: 0.6901 - val_loss: 0.0408
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">71/71</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - accuracy: 0.7042 - loss: 0.0401
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.04083269461989403, 0.690115749835968]
</pre></div>
</div>
</div>
</div>
<p>Như vậy, khi gia tăng thêm một layers nữa trong kiến trúc mạng neural, chưa chắc đã làm gia tăng chất lượng mô hình</p>
</section>
<section id="mo-hinh-hoi-quy">
<h3><span class="section-number">3.3.3. </span>Mô hình hồi quy<a class="headerlink" href="#mo-hinh-hoi-quy" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">boston_housing</span>
<span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">),</span> <span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_targets</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">boston_housing</span><span class="o">.</span><span class="n">load_data</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz
<span class=" -Color -Color-Bold">57026/57026</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 2us/step
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(404, 13)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_targets</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,
       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,
       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,
       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,
       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,
       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,
       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,
       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,
       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,
       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,
       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,
       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,
       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,
       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,
       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,
       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,
        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,
       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,
       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,
       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,
       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,
       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,
       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,
       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,
       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,
       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,
        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,
        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,
       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,
       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,
       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,
       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,
       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,
       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,
       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,
       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,
       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">polars</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (5, 13)</small><table border="1" class="dataframe"><thead><tr><th>column_0</th><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th><th>column_11</th><th>column_12</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.23247</td><td>0.0</td><td>8.14</td><td>0.0</td><td>0.538</td><td>6.142</td><td>91.7</td><td>3.9769</td><td>4.0</td><td>307.0</td><td>21.0</td><td>396.9</td><td>18.72</td></tr><tr><td>0.02177</td><td>82.5</td><td>2.03</td><td>0.0</td><td>0.415</td><td>7.61</td><td>15.7</td><td>6.27</td><td>2.0</td><td>348.0</td><td>14.7</td><td>395.38</td><td>3.11</td></tr><tr><td>4.89822</td><td>0.0</td><td>18.1</td><td>0.0</td><td>0.631</td><td>4.97</td><td>100.0</td><td>1.3325</td><td>24.0</td><td>666.0</td><td>20.2</td><td>375.52</td><td>3.26</td></tr><tr><td>0.03961</td><td>0.0</td><td>5.19</td><td>0.0</td><td>0.515</td><td>6.037</td><td>34.5</td><td>5.9853</td><td>5.0</td><td>224.0</td><td>20.2</td><td>396.9</td><td>8.01</td></tr><tr><td>3.69311</td><td>0.0</td><td>18.1</td><td>0.0</td><td>0.713</td><td>6.376</td><td>88.4</td><td>2.5671</td><td>24.0</td><td>666.0</td><td>20.2</td><td>391.43</td><td>14.65</td></tr></tbody></table></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (9, 14)</small><table border="1" class="dataframe"><thead><tr><th>statistic</th><th>column_0</th><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th><th>column_11</th><th>column_12</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>3.745111</td><td>11.480198</td><td>11.104431</td><td>0.061881</td><td>0.557356</td><td>6.267082</td><td>69.010644</td><td>3.740271</td><td>9.440594</td><td>405.898515</td><td>18.47599</td><td>354.783168</td><td>12.740817</td></tr><tr><td>&quot;std&quot;</td><td>9.240734</td><td>23.767711</td><td>6.811308</td><td>0.241238</td><td>0.117293</td><td>0.709788</td><td>27.940665</td><td>2.030215</td><td>8.69836</td><td>166.374543</td><td>2.200382</td><td>94.111148</td><td>7.254545</td></tr><tr><td>&quot;min&quot;</td><td>0.00632</td><td>0.0</td><td>0.46</td><td>0.0</td><td>0.385</td><td>3.561</td><td>2.9</td><td>1.1296</td><td>1.0</td><td>188.0</td><td>12.6</td><td>0.32</td><td>1.73</td></tr><tr><td>&quot;25%&quot;</td><td>0.08187</td><td>0.0</td><td>5.13</td><td>0.0</td><td>0.453</td><td>5.875</td><td>45.6</td><td>2.0788</td><td>4.0</td><td>279.0</td><td>17.3</td><td>374.71</td><td>6.9</td></tr><tr><td>&quot;50%&quot;</td><td>0.26938</td><td>0.0</td><td>9.69</td><td>0.0</td><td>0.538</td><td>6.202</td><td>78.7</td><td>3.1523</td><td>5.0</td><td>330.0</td><td>19.1</td><td>391.27</td><td>11.45</td></tr><tr><td>&quot;75%&quot;</td><td>3.67367</td><td>12.5</td><td>18.1</td><td>0.0</td><td>0.631</td><td>6.606</td><td>94.1</td><td>5.118</td><td>24.0</td><td>666.0</td><td>20.2</td><td>396.14</td><td>17.09</td></tr><tr><td>&quot;max&quot;</td><td>88.9762</td><td>100.0</td><td>27.74</td><td>1.0</td><td>0.871</td><td>8.725</td><td>100.0</td><td>10.7103</td><td>24.0</td><td>711.0</td><td>22.0</td><td>396.9</td><td>37.97</td></tr></tbody></table></div></div></div>
</div>
<p>Khi xây dựng mô hình <code class="docutils literal notranslate"><span class="pre">deep</span> <span class="pre">learning</span></code>, ta cần đưa các biến về cùng một khoảng giá trị. Cách làm cơ bản nhất là chuẩn hóa dữ liệu về cùng scale.</p>
<div class="math notranslate nohighlight">
\[y = \frac{y - \mu}{\sigma}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">mean</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([3.74511057e+00, 1.14801980e+01, 1.11044307e+01, 6.18811881e-02,
       5.57355941e-01, 6.26708168e+00, 6.90106436e+01, 3.74027079e+00,
       9.44059406e+00, 4.05898515e+02, 1.84759901e+01, 3.54783168e+02,
       1.27408168e+01])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">-=</span> <span class="n">mean</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">/=</span> <span class="n">std</span>
<span class="n">test_data</span> <span class="o">-=</span> <span class="n">mean</span>
<span class="n">test_data</span> <span class="o">/=</span> <span class="n">std</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (9, 14)</small><table border="1" class="dataframe"><thead><tr><th>statistic</th><th>column_0</th><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th><th>column_11</th><th>column_12</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td><td>404.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>-1.0553e-16</td><td>-7.4748e-17</td><td>1.8291e-15</td><td>-6.8152e-17</td><td>-5.1796e-15</td><td>6.3667e-15</td><td>2.4623e-16</td><td>5.1884e-16</td><td>-5.2763e-17</td><td>-6.1557e-17</td><td>2.3603e-14</td><td>6.0502e-15</td><td>6.3316e-16</td></tr><tr><td>&quot;std&quot;</td><td>1.00124</td><td>1.00124</td><td>1.00124</td><td>1.00124</td><td>1.00124</td><td>1.00124</td><td>1.00124</td><td>1.00124</td><td>1.00124</td><td>1.00124</td><td>1.00124</td><td>1.00124</td><td>1.00124</td></tr><tr><td>&quot;min&quot;</td><td>-0.405101</td><td>-0.483615</td><td>-1.564696</td><td>-0.256833</td><td>-1.471269</td><td>-3.81725</td><td>-2.369042</td><td>-1.287503</td><td>-0.971569</td><td>-1.311311</td><td>-2.673752</td><td>-3.771101</td><td>-1.519664</td></tr><tr><td>&quot;25%&quot;</td><td>-0.396915</td><td>-0.483615</td><td>-0.878222</td><td>-0.256833</td><td>-0.890805</td><td>-0.553078</td><td>-0.838909</td><td>-0.819387</td><td>-0.626249</td><td>-0.763674</td><td>-0.535111</td><td>0.212</td><td>-0.806123</td></tr><tr><td>&quot;50%&quot;</td><td>-0.376598</td><td>-0.483615</td><td>-0.207917</td><td>-0.256833</td><td>-0.165227</td><td>-0.091805</td><td>0.347213</td><td>-0.289969</td><td>-0.511142</td><td>-0.456756</td><td>0.283943</td><td>0.38818</td><td>-0.178153</td></tr><tr><td>&quot;75%&quot;</td><td>-0.007741</td><td>0.04296</td><td>1.028326</td><td>-0.256833</td><td>0.628642</td><td>0.478085</td><td>0.899065</td><td>0.679454</td><td>1.675886</td><td>1.565287</td><td>0.784476</td><td>0.439992</td><td>0.600255</td></tr><tr><td>&quot;max&quot;</td><td>9.234847</td><td>3.72899</td><td>2.445374</td><td>3.893584</td><td>2.677335</td><td>3.467186</td><td>1.110488</td><td>3.437406</td><td>1.675886</td><td>1.836097</td><td>1.603531</td><td>0.448077</td><td>3.482019</td></tr></tbody></table></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">build_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mae&quot;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<p>Với các mô hình hồi quy thường, layers thông thường các node đều để activation với <code class="docutils literal notranslate"><span class="pre">relu</span></code> và layer cuối sẽ để dạng <code class="docutils literal notranslate"><span class="pre">Dense</span></code> thường</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_targets</span><span class="p">),</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 17ms/step - loss: 549.4073 - mae: 21.6143 - val_loss: 455.6754 - val_mae: 19.4348
Epoch 2/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 369.8725 - mae: 17.1327 - val_loss: 265.4864 - val_mae: 14.1890
Epoch 3/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 2ms/step - loss: 182.3016 - mae: 11.3490 - val_loss: 110.8033 - val_mae: 8.6260
Epoch 4/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 2ms/step - loss: 94.0896 - mae: 7.1955 - val_loss: 55.2951 - val_mae: 5.7615
Epoch 5/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 2ms/step - loss: 41.4643 - mae: 4.8586 - val_loss: 34.2481 - val_mae: 4.6553
Epoch 6/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 26.4465 - mae: 3.7233 - val_loss: 28.2051 - val_mae: 4.0434
Epoch 7/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 19.0946 - mae: 3.0245 - val_loss: 25.2276 - val_mae: 3.9039
Epoch 8/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 19.4162 - mae: 3.0383 - val_loss: 23.5146 - val_mae: 3.7701
Epoch 9/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 18.7952 - mae: 3.0400 - val_loss: 23.7454 - val_mae: 3.5233
Epoch 10/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 15.6425 - mae: 2.7457 - val_loss: 23.4933 - val_mae: 3.7467
Epoch 11/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 13.3399 - mae: 2.6416 - val_loss: 22.9354 - val_mae: 3.4043
Epoch 12/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 2ms/step - loss: 17.8934 - mae: 2.8449 - val_loss: 21.8035 - val_mae: 3.4046
Epoch 13/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 12.0992 - mae: 2.5918 - val_loss: 22.0687 - val_mae: 3.3906
Epoch 14/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 12.1251 - mae: 2.4147 - val_loss: 20.4666 - val_mae: 3.2531
Epoch 15/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 11.5550 - mae: 2.4326 - val_loss: 21.0517 - val_mae: 3.2044
Epoch 16/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 9.5704 - mae: 2.3619 - val_loss: 21.7144 - val_mae: 3.2810
Epoch 17/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 4ms/step - loss: 9.7338 - mae: 2.2827 - val_loss: 22.7866 - val_mae: 3.3011
Epoch 18/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 10.9459 - mae: 2.3327 - val_loss: 20.7104 - val_mae: 3.2569
Epoch 19/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 10.8424 - mae: 2.3016 - val_loss: 22.1775 - val_mae: 3.2962
Epoch 20/20
<span class=" -Color -Color-Bold">26/26</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 2ms/step - loss: 10.6309 - mae: 2.3402 - val_loss: 20.6627 - val_mae: 3.1362
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_targets</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">4/4</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 3ms/step - loss: 16.3894 - mae: 2.9383 
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[20.662721633911133, 3.1361870765686035]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="luu-y-xay-dung-mo-hinh">
<h2><span class="section-number">3.4. </span>Lưu ý xây dựng mô hình<a class="headerlink" href="#luu-y-xay-dung-mo-hinh" title="Link to this heading">#</a></h2>
<p>Tương tự như các mô hình học máy khác, nhóm thuật toán học sâu cũng gặp các vấn đề như overfitting hay chất lượng mô hình và cũng có các yêu cầu về dữ liệu.</p>
<ul class="simple">
<li><p>Yêu cầu dữ liệu</p>
<ul>
<li><p>Giá trị nhỏ (thường trong khoảng 0-1)</p></li>
<li><p>Có giá trị trong cùng khỏng (homogenous)</p></li>
<li><p>Xử lý missing value</p></li>
</ul>
</li>
</ul>
<p>Với yêu cầu về mặt dữ liệu trên, thông thường sẽ scale và chuẩn hóa dữ liệu</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">-=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">/=</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Các kỹ thuật xử lý <code class="docutils literal notranslate"><span class="pre">overfitting</span></code>:</p>
<ul class="simple">
<li><p>Thay đổi kiến trúc - loại bỏ bớt các lớp</p></li>
<li><p>Giảm số lượng neural trong một layer</p></li>
<li><p>Thêm dropout - để các neural trong mỗi lớp không hoàn toàn liên kết với nhau</p></li>
<li><p>Thêm regularization - <span class="math notranslate nohighlight">\(L_1\)</span> &amp; <span class="math notranslate nohighlight">\(L_2\)</span>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(L_1\)</span>: Thêm <span class="math notranslate nohighlight">\(\sum |\alpha|\)</span> vào penalty</p></li>
<li><p><span class="math notranslate nohighlight">\(L_2\)</span>: Thêm <span class="math notranslate nohighlight">\(\sum \alpha^2\)</span> vào penalty</p></li>
</ul>
</li>
</ul>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="p01-02-toan-co-ban.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Toán cơ bản với DL</p>
      </div>
    </a>
    <a class="right-next"
       href="p01-04-dl-timeseries.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Chuỗi thời gian</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Mục lục
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow">3.1. Tensorflow</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-co-ban">3.1.1. TensorFlow cơ bản</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xay-dung-mo-hinh-phan-loai-co-ban-voi-tensorflow">3.1.2. Xây dựng mô hình phân loại cơ bản với tensorflow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#keras">3.2. Keras</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cac-mo-hinh-co-ban">3.3. Các mô hình cơ bản</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#phan-loai-nhi-phan">3.3.1. Phân loại nhị phân</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mo-hinh-phan-loai-nhieu-nhom">3.3.2. Mô hình phân loại nhiều nhóm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mo-hinh-hoi-quy">3.3.3. Mô hình hồi quy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#luu-y-xay-dung-mo-hinh">3.4. Lưu ý xây dựng mô hình</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Anh Hoang Duc
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Anh Hoang Duc.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>