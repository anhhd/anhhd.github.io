{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "412e3f15-696f-469a-8af8-16620a9b2be9",
   "metadata": {},
   "source": [
    "# Xử lý dữ liệu text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf2605-8b38-4a61-be1d-553a16294b72",
   "metadata": {},
   "source": [
    "Trước khi xây dựng mô hình ngôn ngữ lớn LLM, việc chuyển đổi dữ liệu text sang dữ liệu định dạng số để máy tính có thể xử lý là bước rất quan trọng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14749a-ce56-4811-9c81-f9ac68801741",
   "metadata": {},
   "source": [
    "![](image/p02-02-data-preparation.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3942b2-155f-4897-bfb2-21b9a919a5ac",
   "metadata": {},
   "source": [
    "## Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d2c96-8959-431d-b419-0525b24cbb8c",
   "metadata": {},
   "source": [
    "Dữ liệu phi cấu trúc sẽ không thể sử dụng trực tiếp trong các mô hình mà cần phải chuyển sang dạng vector có giá trị liên tục. Quá trình chuyển đổi từ text sang vector gọi là nhúng (`embedding`). Khi thực hiện các phép nhúng, mỗi đoạn text sẽ được phân rã thành các vector nhiều chiều, như GPT-2 có 768 chiều, trong khi GPT3 có đến 12288 chiều."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dafbb85-8093-41cb-ab37-f4e2505928d3",
   "metadata": {},
   "source": [
    "![](image/p02-02-text-embedding.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e812290-f2f7-455c-873d-9e1523034b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T10:44:10.620700Z",
     "iopub.status.busy": "2025-01-03T10:44:10.620329Z",
     "iopub.status.idle": "2025-01-03T10:44:10.825626Z",
     "shell.execute_reply": "2025-01-03T10:44:10.824531Z",
     "shell.execute_reply.started": "2025-01-03T10:44:10.620665Z"
    }
   },
   "source": [
    "![](image/p02-02-03-dimensional-embedding.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccad296-7647-440d-b9de-669f96d4c897",
   "metadata": {},
   "source": [
    "## Tokenization text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9016125-289c-4939-aff6-c47455395393",
   "metadata": {},
   "source": [
    "Trong quá trình chuyển đổi (embedding) từ text sang word, các từ hoặc cụm từ sẽ được chia thành các từ hoặc cụm từ được gọi là `tokens`. Trường hợp đơn giản nhất, mỗi từ, ký tự đứng riêng sẽ được chia thành tokens như ở dưới đây"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee70a0-7afb-4e99-b79b-c6dcc59a2d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:33:32.537385Z",
     "iopub.status.busy": "2025-01-03T20:33:32.537051Z",
     "iopub.status.idle": "2025-01-03T20:33:33.232274Z",
     "shell.execute_reply": "2025-01-03T20:33:33.231537Z",
     "shell.execute_reply.started": "2025-01-03T20:33:32.537361Z"
    }
   },
   "source": [
    "![](image/p02-02-03-text-embedding-02.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c487115c-223d-4179-ba77-a966d24150bc",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97873328-999c-4f41-9268-7d66a29a2cda",
   "metadata": {},
   "source": [
    "### Ví dụ với Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de2807-cc07-4a7c-9d34-ddd5659f8bd5",
   "metadata": {},
   "source": [
    "Trong ví dụ dưới đây, ta sẽ đọc toàn bộ dữ liệu text từ một truện ngắn và xử lý token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f90119-32f9-43f9-9ad7-2dbfe9957780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:42:51.933610Z",
     "iopub.status.busy": "2025-01-03T20:42:51.933275Z",
     "iopub.status.idle": "2025-01-03T20:42:51.937655Z",
     "shell.execute_reply": "2025-01-03T20:42:51.936859Z",
     "shell.execute_reply.started": "2025-01-03T20:42:51.933585Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Download file nếu dữ liệu chưa tồn tại\n",
    "if not os.path.exists(\"data/the-verdict.txt\"):\n",
    "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "           \"the-verdict.txt\")\n",
    "    file_path = \"./data/the-verdict.txt\"\n",
    "    urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f165c318-f50f-48bc-be09-f54f905a0438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:42:28.593888Z",
     "iopub.status.busy": "2025-01-03T20:42:28.593577Z",
     "iopub.status.idle": "2025-01-03T20:42:28.598203Z",
     "shell.execute_reply": "2025-01-03T20:42:28.597364Z",
     "shell.execute_reply.started": "2025-01-03T20:42:28.593865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade54f8-ebdb-436d-afe1-3cfba6471002",
   "metadata": {},
   "source": [
    "Để có thể phân nhỏ dữ liệu text, ta cần làm sạch dữ liệu với `regular expression`, loại bỏ khoảng trắng, loại các ký tự đặc biệt, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca9e720-b8d6-4ea1-acc2-5dfad771f0cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:45:42.300062Z",
     "iopub.status.busy": "2025-01-03T20:45:42.299755Z",
     "iopub.status.idle": "2025-01-03T20:45:42.305951Z",
     "shell.execute_reply": "2025-01-03T20:45:42.305162Z",
     "shell.execute_reply.started": "2025-01-03T20:45:42.300039Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5dd8a2-cefc-4ddc-8203-92da32a82f80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:45:46.606071Z",
     "iopub.status.busy": "2025-01-03T20:45:46.605758Z",
     "iopub.status.idle": "2025-01-03T20:45:46.610782Z",
     "shell.execute_reply": "2025-01-03T20:45:46.610000Z",
     "shell.execute_reply.started": "2025-01-03T20:45:46.606050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '--', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '--', 'his', 'last', 'Chicago', 'sitter']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e63071-f67f-40bc-9320-61b17b78f30d",
   "metadata": {},
   "source": [
    "## Chuyển đổi text sang token ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ffe0a8-d7fa-436d-b048-15fc7da52230",
   "metadata": {},
   "source": [
    "Mỗi token sẽ được đưa vào *kho từ vựng* (`vocabulary`), và sẽ đưa các từ, ký tự đặc biệt hoặc cụm từ thành các số nguyên duy nhất như dưới đây."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bff3e7-f864-4ebe-8025-d3f0210ed7f5",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-03.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce814b-8099-42a3-8d2a-996b4ec10b44",
   "metadata": {},
   "source": [
    "Tạo kho từ điển dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee7374a3-34ef-44f5-86e0-f0d7ec13998e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:53:18.531161Z",
     "iopub.status.busy": "2025-01-03T20:53:18.530250Z",
     "iopub.status.idle": "2025-01-03T20:53:18.535499Z",
     "shell.execute_reply": "2025-01-03T20:53:18.534859Z",
     "shell.execute_reply.started": "2025-01-03T20:53:18.531122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53f5021d-71cd-4472-bbfb-a1a9d671b8ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:56:36.326504Z",
     "iopub.status.busy": "2025-01-03T20:56:36.326200Z",
     "iopub.status.idle": "2025-01-03T20:56:36.330194Z",
     "shell.execute_reply": "2025-01-03T20:56:36.329347Z",
     "shell.execute_reply.started": "2025-01-03T20:56:36.326483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tạo dictionary với token, integer\n",
    "vocab = {token:integer for integer,token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63fc4188-c40c-4a69-aaa9-0ad451e81e80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:57:39.949405Z",
     "iopub.status.busy": "2025-01-03T20:57:39.949095Z",
     "iopub.status.idle": "2025-01-03T20:57:39.953882Z",
     "shell.execute_reply": "2025-01-03T20:57:39.953151Z",
     "shell.execute_reply.started": "2025-01-03T20:57:39.949383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị kết quả mappting từ điển\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8340fe-de51-4dc9-80a0-3c24a74095f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Quá trình tạo token ID có thể được đơn giản hóa bằng 3 bước sau\n",
    "\n",
    "- Tạo word tokenization\n",
    "- Tạo bộ từ điển vocabulary\n",
    "- Mapping token về key của bộ từ điển"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35712638-00db-4171-8a0a-11230ea15c28",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-04.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a70807-819d-4d7f-8237-9c3b153f58ac",
   "metadata": {},
   "source": [
    "Ta có thể tạo một class cho phép encode & decode dữ liệu text đơn giản từ bộ từ điển có sẵn (vocab ở ví dụ trên) như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f7f7949-eced-470d-9809-31f45e75d110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:02:56.034273Z",
     "iopub.status.busy": "2025-01-03T21:02:56.033965Z",
     "iopub.status.idle": "2025-01-03T21:02:56.039660Z",
     "shell.execute_reply": "2025-01-03T21:02:56.038727Z",
     "shell.execute_reply.started": "2025-01-03T21:02:56.034252Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    # ecode để convert từ text sang embedding id\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "                                \n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    # decode để convert từ embedding id về dạng text\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670fe36-5b51-4593-aae1-8d6860894acf",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-05.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e85c82-8474-4dbf-b86a-6be34d41d01c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:04:10.766257Z",
     "iopub.status.busy": "2025-01-03T21:04:10.765940Z",
     "iopub.status.idle": "2025-01-03T21:04:10.770791Z",
     "shell.execute_reply": "2025-01-03T21:04:10.770030Z",
     "shell.execute_reply.started": "2025-01-03T21:04:10.766234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5b31422-6c50-4606-b14d-b21e0a49a471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:06:30.575746Z",
     "iopub.status.busy": "2025-01-03T21:06:30.575436Z",
     "iopub.status.idle": "2025-01-03T21:06:30.580544Z",
     "shell.execute_reply": "2025-01-03T21:06:30.579606Z",
     "shell.execute_reply.started": "2025-01-03T21:06:30.575724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode\n",
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e03c41-5893-4155-aef3-2498d765f93b",
   "metadata": {},
   "source": [
    "## Các context tokens đặc biệt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1baeeb4-c4d6-4e44-bc06-42c801b6d960",
   "metadata": {},
   "source": [
    "Trong một số trường hợp, ta cần phải thêm các tokens để có thể hỗ trợ LLM xử lý và hiểu ngữ cảnh tốt hơn - như ký tự kết thúc đầu câu, cuối câu,... Một số tokens đặc biệt thường gặp như sau:\n",
    "\n",
    "- `[BOS]` (beginning of sequence) \n",
    "- `[EOS]` (end of sequence) \n",
    "- `[UNK]` (unknown) - các từ không có trong vocabulary\n",
    "- `[PAD]` (padding) - bổ sung thêm token để độ dài văn bản trong quá trình huấn luyện là đồng nhất.\n",
    "\n",
    "Ví dụ: \n",
    "\n",
    "- text 1: `Tôi yêu Việt Nam`\n",
    "- text 2: `Học LLM thật là thú vị`\n",
    "\n",
    "Độ dài của text1 là 4 token, trong khi text 2 có 6 token. Khi huấn luyện LLM sẽ cần độ dài của text tương đương nhau. Khi đó, text1 sẽ được chuyển đổi như sau\n",
    "\n",
    "- text 1 (new): `Tôi yêu Việt Nam [PAD] [PAD]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d8927-a91a-41cd-8431-70037b120b7e",
   "metadata": {},
   "source": [
    "**Lưu ý**: Với GPT2, để đơn giản hóa quá trình, GPT2 sử dung `<|endoftext|>` để thay thế cho các token đặc biệt. Với trường hợp `tokens` không có trong bộ từ điển, GPT2 sẽ sử dụng kỹ thuật BPE (byte pair encoding) để xử lý. \n",
    "\n",
    "Xem minh họa dưới đây để hiểu rõ hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8bfdd-f813-4218-b223-e9413c87605a",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-06.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea5d82-3531-41d0-aa7f-3afca586d625",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-07.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d71f75-359b-4bf9-8f52-974abbfc9229",
   "metadata": {},
   "source": [
    "Xem ví dụ dưới đây"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90f14d20-75dd-4e2a-864f-446e61bda822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:27:52.951350Z",
     "iopub.status.busy": "2025-01-03T21:27:52.951041Z",
     "iopub.status.idle": "2025-01-03T21:27:52.977940Z",
     "shell.execute_reply": "2025-01-03T21:27:52.976862Z",
     "shell.execute_reply.started": "2025-01-03T21:27:52.951328Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m SimpleTokenizerV1(vocab)\n\u001b[1;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, do you like tea. Is this-- a test?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# error\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m, in \u001b[0;36mSimpleTokenizerV1.encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m      8\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([,.:;?_!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]|--|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m     10\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     item\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     12\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m ids \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpreprocessed\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([,.:;?_!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]|--|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m     10\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     item\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     12\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Hello'"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"Hello, do you like tea. Is this-- a test?\"\n",
    "tokenizer.encode(text) # error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b30c5a-8fbf-48ef-9f97-00e646c3f04b",
   "metadata": {},
   "source": [
    "Ở ví dụ trên, quá trình tokenization sẽ báo lỗi do từ `Hello` đang không có trong bộ từ điển ban đầu. Do đó, ta cần thực hiện 2 bước:\n",
    "\n",
    "- Mở rộng vocabulary với `<|unk|>` và `<|endoftext|>`\n",
    "- Điều chỉnh tokenization trong trường hợp không có dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae0a1543-0530-4208-8ea6-12ac2433cc60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:32:10.851073Z",
     "iopub.status.busy": "2025-01-03T21:32:10.850759Z",
     "iopub.status.idle": "2025-01-03T21:32:10.855365Z",
     "shell.execute_reply": "2025-01-03T21:32:10.854545Z",
     "shell.execute_reply.started": "2025-01-03T21:32:10.851051Z"
    }
   },
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bc0ea6e-efe9-4efa-809a-3796daa057d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:33:05.149391Z",
     "iopub.status.busy": "2025-01-03T21:33:05.149071Z",
     "iopub.status.idle": "2025-01-03T21:33:05.153160Z",
     "shell.execute_reply": "2025-01-03T21:33:05.152375Z",
     "shell.execute_reply.started": "2025-01-03T21:33:05.149370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38e74167-c449-44c9-9799-992734387e6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:33:34.079008Z",
     "iopub.status.busy": "2025-01-03T21:33:34.078702Z",
     "iopub.status.idle": "2025-01-03T21:33:34.084327Z",
     "shell.execute_reply": "2025-01-03T21:33:34.083756Z",
     "shell.execute_reply.started": "2025-01-03T21:33:34.078987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra các ký tự đặc biệt đã được thêm vào embedding\n",
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faf6ae67-083a-47ad-9c8f-eba2b27476d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:34:48.636867Z",
     "iopub.status.busy": "2025-01-03T21:34:48.636553Z",
     "iopub.status.idle": "2025-01-03T21:34:48.642744Z",
     "shell.execute_reply": "2025-01-03T21:34:48.641740Z",
     "shell.execute_reply.started": "2025-01-03T21:34:48.636846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Viết lại class mới\n",
    "\n",
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            # Nếu từ không có trong vocab thì chuyển |unk|\n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a524e0bf-2b51-4152-b0d6-9e2e7463d2da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:35:28.479793Z",
     "iopub.status.busy": "2025-01-03T21:35:28.479482Z",
     "iopub.status.idle": "2025-01-03T21:35:28.484058Z",
     "shell.execute_reply": "2025-01-03T21:35:28.483246Z",
     "shell.execute_reply.started": "2025-01-03T21:35:28.479771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ef99845-0b89-45a8-bf7c-c07c3b7669a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:35:52.618562Z",
     "iopub.status.busy": "2025-01-03T21:35:52.618238Z",
     "iopub.status.idle": "2025-01-03T21:35:52.623699Z",
     "shell.execute_reply": "2025-01-03T21:35:52.622936Z",
     "shell.execute_reply.started": "2025-01-03T21:35:52.618539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd790e71-39d0-40f3-8f06-e41ccbaec3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:36:50.061329Z",
     "iopub.status.busy": "2025-01-03T21:36:50.060835Z",
     "iopub.status.idle": "2025-01-03T21:36:50.065701Z",
     "shell.execute_reply": "2025-01-03T21:36:50.064932Z",
     "shell.execute_reply.started": "2025-01-03T21:36:50.061304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 697, 1116]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<|unk|> my word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f0fa2-9904-473b-b398-a714158c21d1",
   "metadata": {},
   "source": [
    "## Byte Pair Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f36ba7-5719-4bca-83f5-cfd21cd1ff31",
   "metadata": {},
   "source": [
    "Bên cạnh kỹ thuật thêm các từ và đặt từ đơn giản như `<|unk|>`, GPT2 sử dụng kỹ thuật Byte Pair Encoding. \n",
    "\n",
    "BPE sẽ chia nhỏ một từ mới thành các token nhỏ hơn và đã tồn tại trong kho từ vựng. BPE xây dựng vốn từ vựng bằng cách kết hợp lặp đi lặp lại các ký tự thường gặp thành từ phụ và từ phụ thường gặp thành từ. Ví dụ: BPE bắt đầu bằng việc thêm tất cả các ký tự đơn riêng lẻ vào từ vựng của nó (\"a\", \"b\", v.v.). \n",
    "\n",
    "Trong giai đoạn tiếp theo, nó hợp nhất các tổ hợp ký tự thường xuất hiện cùng nhau thành các từ phụ. Ví dụ: \"d\" và \"e\" có thể được hợp nhất thành từ phụ \"de\", từ này phổ biến trong nhiều tiếng Anh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44a27ce-41f5-4918-b2bb-fe874144913a",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-08.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417799b4-8c8e-48aa-b532-a4a6387252b7",
   "metadata": {},
   "source": [
    "Thư viện phổ biến để encode text embeding là `titoken` với core được viết bằng `Rust` để tăng tốc độ xử lý và tính toán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b26196bc-96f2-4fe4-96f5-a7c7ab63bfca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:45:07.099759Z",
     "iopub.status.busy": "2025-01-03T21:45:07.099452Z",
     "iopub.status.idle": "2025-01-03T21:45:07.119159Z",
     "shell.execute_reply": "2025-01-03T21:45:07.118326Z",
     "shell.execute_reply.started": "2025-01-03T21:45:07.099738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d647eb3c-6869-49c1-b74e-0c5fef8f5a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:45:08.504732Z",
     "iopub.status.busy": "2025-01-03T21:45:08.504273Z",
     "iopub.status.idle": "2025-01-03T21:45:09.483735Z",
     "shell.execute_reply": "2025-01-03T21:45:09.483127Z",
     "shell.execute_reply.started": "2025-01-03T21:45:08.504708Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32219dcb-6901-40dd-b2dd-f9c0326efdf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:45:48.300704Z",
     "iopub.status.busy": "2025-01-03T21:45:48.300401Z",
     "iopub.status.idle": "2025-01-03T21:45:48.305017Z",
     "shell.execute_reply": "2025-01-03T21:45:48.304222Z",
     "shell.execute_reply.started": "2025-01-03T21:45:48.300683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 300, 9997, 2419, 388, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace loretipsum.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3ecdd82-b265-41d5-b5af-36fe12d236f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:48:19.372677Z",
     "iopub.status.busy": "2025-01-03T21:48:19.372360Z",
     "iopub.status.idle": "2025-01-03T21:48:19.377593Z",
     "shell.execute_reply": "2025-01-03T21:48:19.376826Z",
     "shell.execute_reply.started": "2025-01-03T21:48:19.372654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace loretipsum.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da607d37-1846-470a-9906-0a97249dac24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:50:49.225890Z",
     "iopub.status.busy": "2025-01-03T21:50:49.225536Z",
     "iopub.status.idle": "2025-01-03T21:50:49.231583Z",
     "shell.execute_reply": "2025-01-03T21:50:49.230872Z",
     "shell.execute_reply.started": "2025-01-03T21:50:49.225860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34,\n",
       " 157,\n",
       " 119,\n",
       " 247,\n",
       " 782,\n",
       " 289,\n",
       " 127,\n",
       " 110,\n",
       " 64,\n",
       " 2124,\n",
       " 26102,\n",
       " 289,\n",
       " 157,\n",
       " 119,\n",
       " 247,\n",
       " 72,\n",
       " 442,\n",
       " 157,\n",
       " 119,\n",
       " 100,\n",
       " 299,\n",
       " 456,\n",
       " 128,\n",
       " 102,\n",
       " 64,\n",
       " 16049,\n",
       " 157,\n",
       " 119,\n",
       " 229,\n",
       " 83,\n",
       " 17871]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize với tiếng Việt\n",
    "tokenizer.encode(\"Cộng hòa xã hội chủ nghĩa Việt Nam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f323a-8376-4226-ba54-921e4a6330b3",
   "metadata": {},
   "source": [
    "## Data sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660869fb-fd91-42f5-a8e6-4fe3fe9e44a1",
   "metadata": {},
   "source": [
    "Như ta đã biết, LLM tập trung dự báo các từ tiếp theo trong một đoạn văn bản. Để xây dựng dữ liệu huấn luyện cho LLM, ta cần tạo các cặp vector đầu vào - kết quả tương ứng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a259a5-077a-4fd3-9efa-ecba6b8f2bf9",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-09.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34ce0edd-8153-478c-ab0e-c58b587c3bf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:54:00.887183Z",
     "iopub.status.busy": "2025-01-03T21:54:00.886869Z",
     "iopub.status.idle": "2025-01-03T21:54:00.894900Z",
     "shell.execute_reply": "2025-01-03T21:54:00.894293Z",
     "shell.execute_reply.started": "2025-01-03T21:54:00.887160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea1b941b-6c49-4240-b045-34ea1db89c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:54:42.127281Z",
     "iopub.status.busy": "2025-01-03T21:54:42.126940Z",
     "iopub.status.idle": "2025-01-03T21:54:42.130722Z",
     "shell.execute_reply": "2025-01-03T21:54:42.129972Z",
     "shell.execute_reply.started": "2025-01-03T21:54:42.127234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lấy dữ liệu sample\n",
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa4b2868-4e46-4f0a-8e34-512f7d167484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:56:14.500800Z",
     "iopub.status.busy": "2025-01-03T21:56:14.500497Z",
     "iopub.status.idle": "2025-01-03T21:56:14.505685Z",
     "shell.execute_reply": "2025-01-03T21:56:14.504595Z",
     "shell.execute_reply.started": "2025-01-03T21:56:14.500779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n",
      "z:            [2241, 287, 257, 4489]\n"
     ]
    }
   ],
   "source": [
    "# Tạo context 4 từ và dự đoán từ tiếp theo\n",
    "context_size = 4\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "z = enc_sample[2:context_size+2]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")\n",
    "print(f\"z:            {z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67921b-663e-4cb4-976a-b99df24bb0c0",
   "metadata": {},
   "source": [
    "Các cặp input, output cần dự báo sẽ như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "290ea07c-7c9b-42b5-9001-91d0329d581d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:56:55.450913Z",
     "iopub.status.busy": "2025-01-03T21:56:55.450594Z",
     "iopub.status.idle": "2025-01-03T21:56:55.457190Z",
     "shell.execute_reply": "2025-01-03T21:56:55.454676Z",
     "shell.execute_reply.started": "2025-01-03T21:56:55.450888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ef7c972-7cda-4224-8bc0-e2da2d8f94b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T21:57:28.913567Z",
     "iopub.status.busy": "2025-01-03T21:57:28.913265Z",
     "iopub.status.idle": "2025-01-03T21:57:28.918411Z",
     "shell.execute_reply": "2025-01-03T21:57:28.917761Z",
     "shell.execute_reply.started": "2025-01-03T21:57:28.913547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80635d-53fe-4f4a-a0f5-2e3940057123",
   "metadata": {},
   "source": [
    "### Xây dựng data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178fb15e-b758-4bcf-bb09-c8aa26e6a69c",
   "metadata": {},
   "source": [
    "Để thuận tiện cho việc chuẩn bị dữ liệu input/output cho LLM, ta cần xây dựng một `data loader` class, cho phép tạo ra các tensor chứa input & output cho LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6a0480-3564-485f-bedc-a8398b09b728",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-10.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "14eb3630-e1ea-4a94-b0e9-ec3a6d54b4da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:01:07.880080Z",
     "iopub.status.busy": "2025-01-03T22:01:07.879768Z",
     "iopub.status.idle": "2025-01-03T22:01:09.707895Z",
     "shell.execute_reply": "2025-01-03T22:01:09.707024Z",
     "shell.execute_reply.started": "2025-01-03T22:01:07.880059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "772b7b13-d73f-48dd-a5f0-52667c911018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:01:38.515953Z",
     "iopub.status.busy": "2025-01-03T22:01:38.515534Z",
     "iopub.status.idle": "2025-01-03T22:01:38.522574Z",
     "shell.execute_reply": "2025-01-03T22:01:38.521994Z",
     "shell.execute_reply.started": "2025-01-03T22:01:38.515930Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9c874de-02a0-44bc-8483-d9313f6fdee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:02:12.596766Z",
     "iopub.status.busy": "2025-01-03T22:02:12.596440Z",
     "iopub.status.idle": "2025-01-03T22:02:12.601438Z",
     "shell.execute_reply": "2025-01-03T22:02:12.600676Z",
     "shell.execute_reply.started": "2025-01-03T22:02:12.596743Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db5f8f4e-4261-47f0-aa98-5b822ad5a45b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:02:24.954916Z",
     "iopub.status.busy": "2025-01-03T22:02:24.954599Z",
     "iopub.status.idle": "2025-01-03T22:02:24.958538Z",
     "shell.execute_reply": "2025-01-03T22:02:24.957785Z",
     "shell.execute_reply.started": "2025-01-03T22:02:24.954894Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c3aae62c-0916-47b3-9bf1-104101ff717b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:04:17.364954Z",
     "iopub.status.busy": "2025-01-03T22:04:17.364614Z",
     "iopub.status.idle": "2025-01-03T22:04:17.436387Z",
     "shell.execute_reply": "2025-01-03T22:04:17.435709Z",
     "shell.execute_reply.started": "2025-01-03T22:04:17.364933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a3164-ea43-4300-b1c2-42a211aadd50",
   "metadata": {},
   "source": [
    "**Lưu ý**: `stride = 1` cho phép dịch chuyển context đi 1 token. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f66a8a-d039-4ee3-aa90-d27e0564bb6e",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-11.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18d91362-e296-42e8-8126-804e3214a18a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:06:29.140348Z",
     "iopub.status.busy": "2025-01-03T22:06:29.140035Z",
     "iopub.status.idle": "2025-01-03T22:06:29.169630Z",
     "shell.execute_reply": "2025-01-03T22:06:29.168931Z",
     "shell.execute_reply.started": "2025-01-03T22:06:29.140328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59d1ae-22b2-4d24-bb8d-15623a75e269",
   "metadata": {},
   "source": [
    "## Token embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e24a1-21de-4a56-951e-31f12e2b6fb1",
   "metadata": {},
   "source": [
    "Bước tiếp theo là triển chuyển đổi các token id thành các vector nhúng (vector embedding) như dưới đây"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22d3f3-5d57-4a5e-8f64-4d39f8e9388b",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-12.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1099b21d-d68e-4576-9ea5-f664b170d87b",
   "metadata": {},
   "source": [
    "**Ví dụ**: Ta có 4 word id và cần chuyển đổi thành vector embedding với kích thước là 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d654f2a-337c-4919-a258-7b37d01e0d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:20:39.444517Z",
     "iopub.status.busy": "2025-01-03T22:20:39.444202Z",
     "iopub.status.idle": "2025-01-03T22:20:39.448150Z",
     "shell.execute_reply": "2025-01-03T22:20:39.447372Z",
     "shell.execute_reply.started": "2025-01-03T22:20:39.444495Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b586c69-a640-46bb-9d5f-2b784d2aee1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:22:36.097352Z",
     "iopub.status.busy": "2025-01-03T22:22:36.097059Z",
     "iopub.status.idle": "2025-01-03T22:22:36.102580Z",
     "shell.execute_reply": "2025-01-03T22:22:36.101743Z",
     "shell.execute_reply.started": "2025-01-03T22:22:36.097332Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f8627283-8eac-48e2-9c74-3f383aa25e3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:22:46.856514Z",
     "iopub.status.busy": "2025-01-03T22:22:46.856208Z",
     "iopub.status.idle": "2025-01-03T22:22:46.862100Z",
     "shell.execute_reply": "2025-01-03T22:22:46.861401Z",
     "shell.execute_reply.started": "2025-01-03T22:22:46.856493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67c509a6-6dfb-4d5b-8c55-0ccc7aa78cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:23:13.324311Z",
     "iopub.status.busy": "2025-01-03T22:23:13.323996Z",
     "iopub.status.idle": "2025-01-03T22:23:13.329418Z",
     "shell.execute_reply": "2025-01-03T22:23:13.328573Z",
     "shell.execute_reply.started": "2025-01-03T22:23:13.324287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650d815-3d89-4440-a4d1-f9f8b04f349b",
   "metadata": {},
   "source": [
    "Convert một id ra vector embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a76a4ed0-b8f5-434b-8554-30f564f737d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:27:57.591707Z",
     "iopub.status.busy": "2025-01-03T22:27:57.591398Z",
     "iopub.status.idle": "2025-01-03T22:27:57.597501Z",
     "shell.execute_reply": "2025-01-03T22:27:57.596464Z",
     "shell.execute_reply.started": "2025-01-03T22:27:57.591686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[0.9178, 1.5810, 1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Tensor 3\n",
    "print(embedding_layer(torch.tensor([3])))\n",
    "# Tensor 1\n",
    "print(embedding_layer(torch.tensor([1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2e80a-8ac3-45ec-98b9-0a822952ac9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:28:10.718082Z",
     "iopub.status.busy": "2025-01-03T22:28:10.717761Z",
     "iopub.status.idle": "2025-01-03T22:28:10.723301Z",
     "shell.execute_reply": "2025-01-03T22:28:10.722396Z",
     "shell.execute_reply.started": "2025-01-03T22:28:10.718062Z"
    }
   },
   "source": [
    "Convert toàn bộ id ra vector embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2661e994-5caa-482b-8b84-41bb8a7c54e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:29:44.192323Z",
     "iopub.status.busy": "2025-01-03T22:29:44.192008Z",
     "iopub.status.idle": "2025-01-03T22:29:44.197354Z",
     "shell.execute_reply": "2025-01-03T22:29:44.196443Z",
     "shell.execute_reply.started": "2025-01-03T22:29:44.192301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd37652-013b-44bf-b49b-eaa125b027e6",
   "metadata": {},
   "source": [
    "## Mã hóa vị trí từ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe902eb-0777-467c-b41d-a1731143cbe1",
   "metadata": {},
   "source": [
    "Với cách thực hiện word embedding, mỗi từ sẽ có vector biểu diễn giống nhau với mọi câu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f720153-cc43-4f3f-8e24-0ab66a698ee1",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-14.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5efde70-1df0-42fa-acdc-86e72063ac0d",
   "metadata": {},
   "source": [
    "Tuy nhiên, trong văn bản, các từ ở các vị trí khác nhau sẽ có các biểu đạt và ý nghĩa khác nhau. Do đó, để khắc phục nhược điểm này, ta có thể bổ sung tham số về vị trí. Vị trí này có thể chia làm 2 nhóm - vị trí tương đối và vị trí tuyệt đối.\n",
    "\n",
    "Vị trí tuyệt đối mô tả vị trí của embeding trong đoạn văn. Trong khi đó, vị trí tương đối mô tả mối quan hệ theo khía cạnh - các vector cách nhau bao xa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5c413-0bf1-4ed2-9682-2af2ec7ae1b6",
   "metadata": {},
   "source": [
    "![](image/p02-02-03-text-embedding-15.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b82330-5337-4ae4-b166-daf67d5a8b70",
   "metadata": {},
   "source": [
    "Ví dụ với Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b28e37f-8678-4e1d-acca-f2cf1a1f8da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:35:06.017771Z",
     "iopub.status.busy": "2025-01-03T22:35:06.017451Z",
     "iopub.status.idle": "2025-01-03T22:35:06.131997Z",
     "shell.execute_reply": "2025-01-03T22:35:06.131375Z",
     "shell.execute_reply.started": "2025-01-03T22:35:06.017748Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64f9d867-6807-43df-b919-8fb18c90e3c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:35:13.855777Z",
     "iopub.status.busy": "2025-01-03T22:35:13.855460Z",
     "iopub.status.idle": "2025-01-03T22:35:13.882539Z",
     "shell.execute_reply": "2025-01-03T22:35:13.881957Z",
     "shell.execute_reply.started": "2025-01-03T22:35:13.855754Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a22d193b-001e-47e4-9046-8cedc9c37879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:35:23.168094Z",
     "iopub.status.busy": "2025-01-03T22:35:23.167745Z",
     "iopub.status.idle": "2025-01-03T22:35:23.172664Z",
     "shell.execute_reply": "2025-01-03T22:35:23.171924Z",
     "shell.execute_reply.started": "2025-01-03T22:35:23.168071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "672c4247-b3f2-4e27-90d1-942fe2777260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:35:47.460448Z",
     "iopub.status.busy": "2025-01-03T22:35:47.460140Z",
     "iopub.status.idle": "2025-01-03T22:35:47.464726Z",
     "shell.execute_reply": "2025-01-03T22:35:47.463906Z",
     "shell.execute_reply.started": "2025-01-03T22:35:47.460426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af9a40-a09f-4fff-8b6e-ecd4a15ae7d3",
   "metadata": {},
   "source": [
    "GPT2 sử dụng position embedding theo giá trị tuyệt đối"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5cbcc10-897b-4dab-aff2-c1cf0b44d91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:35:45.135590Z",
     "iopub.status.busy": "2025-01-03T22:35:45.135279Z",
     "iopub.status.idle": "2025-01-03T22:35:45.139790Z",
     "shell.execute_reply": "2025-01-03T22:35:45.138832Z",
     "shell.execute_reply.started": "2025-01-03T22:35:45.135568Z"
    }
   },
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a94bca66-80de-45ec-b59a-61e2cd68635f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:36:30.025642Z",
     "iopub.status.busy": "2025-01-03T22:36:30.025334Z",
     "iopub.status.idle": "2025-01-03T22:36:30.030295Z",
     "shell.execute_reply": "2025-01-03T22:36:30.029349Z",
     "shell.execute_reply.started": "2025-01-03T22:36:30.025622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bfd41026-8abb-4a97-9553-ce0e6e8bc861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:36:35.849873Z",
     "iopub.status.busy": "2025-01-03T22:36:35.849569Z",
     "iopub.status.idle": "2025-01-03T22:36:35.853776Z",
     "shell.execute_reply": "2025-01-03T22:36:35.853070Z",
     "shell.execute_reply.started": "2025-01-03T22:36:35.849852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
