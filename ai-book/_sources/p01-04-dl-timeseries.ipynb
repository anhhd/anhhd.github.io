{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuỗi thời gian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giới thiệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi dự báo với deep learning, ta có thể chia dữ liệu thành các minibatch khác nhau. Với mỗi `sequence_length` là `m`, sẽ lấy `m` điểm thời gian trước đó để làm input dự báo cho thời gian hiện tại "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T08:58:39.268256Z",
     "iopub.status.busy": "2025-01-09T08:58:39.267944Z",
     "iopub.status.idle": "2025-01-09T08:58:46.069054Z",
     "shell.execute_reply": "2025-01-09T08:58:46.068381Z",
     "shell.execute_reply.started": "2025-01-09T08:58:39.268233Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "int_sequence = np.arange(10)\n",
    "dummy_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    data=int_sequence[:-3],\n",
    "    targets=int_sequence[3:],\n",
    "    sequence_length=3,\n",
    "    batch_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2] 3\n",
      "[1, 2, 3] 4\n",
      "[2, 3, 4] 5\n",
      "[3, 4, 5] 6\n",
      "[4, 5, 6] 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for inputs, targets in dummy_dataset:\n",
    "    for i in range(inputs.shape[0]):\n",
    "        print([int(x) for x in inputs[i]], int(targets[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với mô hình `DL` cơ bản, ta có thể sử dụng các `dense layer` để sử dụng các feature tại n điểm thời gian gần nhất dự báo cho điểm thời gian tiếp theo. Xem ví dụ đơn giản dưới đây"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated a Polars DataFrame with 1000 data points and multiple features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>value</th><th>x1</th><th>x2</th><th>x3</th><th>x4</th><th>x5</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>-0.025092</td><td>-0.075519</td><td>0.952341</td><td>0.009449</td><td>0.014399</td><td>0.991273</td></tr><tr><td>1</td><td>0.189976</td><td>0.103368</td><td>0.938167</td><td>0.249313</td><td>-0.018828</td><td>0.879766</td></tr><tr><td>2</td><td>0.245068</td><td>0.197123</td><td>1.036587</td><td>0.195162</td><td>-0.107286</td><td>0.869436</td></tr><tr><td>3</td><td>0.315252</td><td>0.204071</td><td>0.850356</td><td>0.340227</td><td>-0.306923</td><td>0.635711</td></tr><tr><td>4</td><td>0.320622</td><td>0.221623</td><td>0.779726</td><td>0.334971</td><td>-0.384717</td><td>0.610326</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌──────┬───────────┬───────────┬──────────┬──────────┬───────────┬──────────┐\n",
       "│ time ┆ value     ┆ x1        ┆ x2       ┆ x3       ┆ x4        ┆ x5       │\n",
       "│ ---  ┆ ---       ┆ ---       ┆ ---      ┆ ---      ┆ ---       ┆ ---      │\n",
       "│ i64  ┆ f64       ┆ f64       ┆ f64      ┆ f64      ┆ f64       ┆ f64      │\n",
       "╞══════╪═══════════╪═══════════╪══════════╪══════════╪═══════════╪══════════╡\n",
       "│ 0    ┆ -0.025092 ┆ -0.075519 ┆ 0.952341 ┆ 0.009449 ┆ 0.014399  ┆ 0.991273 │\n",
       "│ 1    ┆ 0.189976  ┆ 0.103368  ┆ 0.938167 ┆ 0.249313 ┆ -0.018828 ┆ 0.879766 │\n",
       "│ 2    ┆ 0.245068  ┆ 0.197123  ┆ 1.036587 ┆ 0.195162 ┆ -0.107286 ┆ 0.869436 │\n",
       "│ 3    ┆ 0.315252  ┆ 0.204071  ┆ 0.850356 ┆ 0.340227 ┆ -0.306923 ┆ 0.635711 │\n",
       "│ 4    ┆ 0.320622  ┆ 0.221623  ┆ 0.779726 ┆ 0.334971 ┆ -0.384717 ┆ 0.610326 │\n",
       "└──────┴───────────┴───────────┴──────────┴──────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import polars as pl\n",
    "from lets_plot import *\n",
    "LetsPlot.setup_html()\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# --- 1. Generate Synthetic Data with Multiple Features ---\n",
    "# We'll create a primary time series and five additional features that are\n",
    "# correlated with the main series.\n",
    "def generate_time_series_with_features(num_points=1000, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Generates a synthetic time series as a Polars DataFrame with multiple features.\n",
    "    \"\"\"\n",
    "    time = np.arange(num_points)\n",
    "    \n",
    "    # Primary time series\n",
    "    series_values = np.sin(0.1 * time) + np.random.uniform(-noise_level, noise_level, num_points)\n",
    "    \n",
    "    # Generate five additional correlated features\n",
    "    df = pl.DataFrame({\n",
    "        \"time\": time,\n",
    "        \"value\": series_values,\n",
    "        \"x1\": series_values * 0.5 + np.random.uniform(-noise_level, noise_level, num_points),\n",
    "        \"x2\": np.cos(0.15 * time) + np.random.uniform(-noise_level, noise_level, num_points),\n",
    "        \"x3\": series_values + np.random.uniform(-noise_level, noise_level, num_points),\n",
    "        \"x4\": -np.sin(0.08 * time) + np.random.uniform(-noise_level, noise_level, num_points),\n",
    "        \"x5\": np.cos(0.2 * time) - series_values * 0.5 + np.random.uniform(-noise_level, noise_level, num_points)\n",
    "    })\n",
    "    return df\n",
    "\n",
    "data_df = generate_time_series_with_features()\n",
    "print(f\"Generated a Polars DataFrame with {data_df.shape[0]} data points and multiple features.\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "   <head>\n",
       "       <meta charset=\"UTF-8\">\n",
       "       <style> html, body { margin: 0; padding: 0; } </style>\n",
       "       <script type=\"text/javascript\" data-lets-plot-script=\"library\" src=\"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.7.0/js-package/distr/lets-plot.min.js\"></script>\n",
       "   </head>\n",
       "   <body>\n",
       "          <div id=\"6iPYd1\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "   \n",
       "   (function() {\n",
       "   // ----------\n",
       "   \n",
       "   const forceImmediateRender = false;\n",
       "   const responsive = false;\n",
       "   \n",
       "   let sizing = {\n",
       "       width_mode: \"MIN\",\n",
       "       height_mode: \"SCALED\",\n",
       "       width: null, \n",
       "       height: null \n",
       "   };\n",
       "   \n",
       "   const preferredWidth = document.body.dataset.letsPlotPreferredWidth;\n",
       "   if (preferredWidth !== undefined) {\n",
       "       sizing = {\n",
       "           width_mode: 'FIXED',\n",
       "           height_mode: 'SCALED',\n",
       "           width: parseFloat(preferredWidth)\n",
       "       };\n",
       "   }\n",
       "   \n",
       "   const containerDiv = document.getElementById(\"6iPYd1\");\n",
       "   let fig = null;\n",
       "   \n",
       "   function renderPlot() {\n",
       "       if (fig === null) {\n",
       "           const plotSpec = {\n",
       "\"data\":{\n",
       "\"time\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0,193.0,194.0,195.0,196.0,197.0,198.0,199.0,200.0,201.0,202.0,203.0,204.0,205.0,206.0,207.0,208.0,209.0,210.0,211.0,212.0,213.0,214.0,215.0,216.0,217.0,218.0,219.0,220.0,221.0,222.0,223.0,224.0,225.0,226.0,227.0,228.0,229.0,230.0,231.0,232.0,233.0,234.0,235.0,236.0,237.0,238.0,239.0,240.0,241.0,242.0,243.0,244.0,245.0,246.0,247.0,248.0,249.0,250.0,251.0,252.0,253.0,254.0,255.0,256.0,257.0,258.0,259.0,260.0,261.0,262.0,263.0,264.0,265.0,266.0,267.0,268.0,269.0,270.0,271.0,272.0,273.0,274.0,275.0,276.0,277.0,278.0,279.0,280.0,281.0,282.0,283.0,284.0,285.0,286.0,287.0,288.0,289.0,290.0,291.0,292.0,293.0,294.0,295.0,296.0,297.0,298.0,299.0,300.0,301.0,302.0,303.0,304.0,305.0,306.0,307.0,308.0,309.0,310.0,311.0,312.0,313.0,314.0,315.0,316.0,317.0,318.0,319.0,320.0,321.0,322.0,323.0,324.0,325.0,326.0,327.0,328.0,329.0,330.0,331.0,332.0,333.0,334.0,335.0,336.0,337.0,338.0,339.0,340.0,341.0,342.0,343.0,344.0,345.0,346.0,347.0,348.0,349.0,350.0,351.0,352.0,353.0,354.0,355.0,356.0,357.0,358.0,359.0,360.0,361.0,362.0,363.0,364.0,365.0,366.0,367.0,368.0,369.0,370.0,371.0,372.0,373.0,374.0,375.0,376.0,377.0,378.0,379.0,380.0,381.0,382.0,383.0,384.0,385.0,386.0,387.0,388.0,389.0,390.0,391.0,392.0,393.0,394.0,395.0,396.0,397.0,398.0,399.0,400.0,401.0,402.0,403.0,404.0,405.0,406.0,407.0,408.0,409.0,410.0,411.0,412.0,413.0,414.0,415.0,416.0,417.0,418.0,419.0,420.0,421.0,422.0,423.0,424.0,425.0,426.0,427.0,428.0,429.0,430.0,431.0,432.0,433.0,434.0,435.0,436.0,437.0,438.0,439.0,440.0,441.0,442.0,443.0,444.0,445.0,446.0,447.0,448.0,449.0,450.0,451.0,452.0,453.0,454.0,455.0,456.0,457.0,458.0,459.0,460.0,461.0,462.0,463.0,464.0,465.0,466.0,467.0,468.0,469.0,470.0,471.0,472.0,473.0,474.0,475.0,476.0,477.0,478.0,479.0,480.0,481.0,482.0,483.0,484.0,485.0,486.0,487.0,488.0,489.0,490.0,491.0,492.0,493.0,494.0,495.0,496.0,497.0,498.0,499.0,500.0,501.0,502.0,503.0,504.0,505.0,506.0,507.0,508.0,509.0,510.0,511.0,512.0,513.0,514.0,515.0,516.0,517.0,518.0,519.0,520.0,521.0,522.0,523.0,524.0,525.0,526.0,527.0,528.0,529.0,530.0,531.0,532.0,533.0,534.0,535.0,536.0,537.0,538.0,539.0,540.0,541.0,542.0,543.0,544.0,545.0,546.0,547.0,548.0,549.0,550.0,551.0,552.0,553.0,554.0,555.0,556.0,557.0,558.0,559.0,560.0,561.0,562.0,563.0,564.0,565.0,566.0,567.0,568.0,569.0,570.0,571.0,572.0,573.0,574.0,575.0,576.0,577.0,578.0,579.0,580.0,581.0,582.0,583.0,584.0,585.0,586.0,587.0,588.0,589.0,590.0,591.0,592.0,593.0,594.0,595.0,596.0,597.0,598.0,599.0,600.0,601.0,602.0,603.0,604.0,605.0,606.0,607.0,608.0,609.0,610.0,611.0,612.0,613.0,614.0,615.0,616.0,617.0,618.0,619.0,620.0,621.0,622.0,623.0,624.0,625.0,626.0,627.0,628.0,629.0,630.0,631.0,632.0,633.0,634.0,635.0,636.0,637.0,638.0,639.0,640.0,641.0,642.0,643.0,644.0,645.0,646.0,647.0,648.0,649.0,650.0,651.0,652.0,653.0,654.0,655.0,656.0,657.0,658.0,659.0,660.0,661.0,662.0,663.0,664.0,665.0,666.0,667.0,668.0,669.0,670.0,671.0,672.0,673.0,674.0,675.0,676.0,677.0,678.0,679.0,680.0,681.0,682.0,683.0,684.0,685.0,686.0,687.0,688.0,689.0,690.0,691.0,692.0,693.0,694.0,695.0,696.0,697.0,698.0,699.0,700.0,701.0,702.0,703.0,704.0,705.0,706.0,707.0,708.0,709.0,710.0,711.0,712.0,713.0,714.0,715.0,716.0,717.0,718.0,719.0,720.0,721.0,722.0,723.0,724.0,725.0,726.0,727.0,728.0,729.0,730.0,731.0,732.0,733.0,734.0,735.0,736.0,737.0,738.0,739.0,740.0,741.0,742.0,743.0,744.0,745.0,746.0,747.0,748.0,749.0,750.0,751.0,752.0,753.0,754.0,755.0,756.0,757.0,758.0,759.0,760.0,761.0,762.0,763.0,764.0,765.0,766.0,767.0,768.0,769.0,770.0,771.0,772.0,773.0,774.0,775.0,776.0,777.0,778.0,779.0,780.0,781.0,782.0,783.0,784.0,785.0,786.0,787.0,788.0,789.0,790.0,791.0,792.0,793.0,794.0,795.0,796.0,797.0,798.0,799.0,800.0,801.0,802.0,803.0,804.0,805.0,806.0,807.0,808.0,809.0,810.0,811.0,812.0,813.0,814.0,815.0,816.0,817.0,818.0,819.0,820.0,821.0,822.0,823.0,824.0,825.0,826.0,827.0,828.0,829.0,830.0,831.0,832.0,833.0,834.0,835.0,836.0,837.0,838.0,839.0,840.0,841.0,842.0,843.0,844.0,845.0,846.0,847.0,848.0,849.0,850.0,851.0,852.0,853.0,854.0,855.0,856.0,857.0,858.0,859.0,860.0,861.0,862.0,863.0,864.0,865.0,866.0,867.0,868.0,869.0,870.0,871.0,872.0,873.0,874.0,875.0,876.0,877.0,878.0,879.0,880.0,881.0,882.0,883.0,884.0,885.0,886.0,887.0,888.0,889.0,890.0,891.0,892.0,893.0,894.0,895.0,896.0,897.0,898.0,899.0,900.0,901.0,902.0,903.0,904.0,905.0,906.0,907.0,908.0,909.0,910.0,911.0,912.0,913.0,914.0,915.0,916.0,917.0,918.0,919.0,920.0,921.0,922.0,923.0,924.0,925.0,926.0,927.0,928.0,929.0,930.0,931.0,932.0,933.0,934.0,935.0,936.0,937.0,938.0,939.0,940.0,941.0,942.0,943.0,944.0,945.0,946.0,947.0,948.0,949.0,950.0,951.0,952.0,953.0,954.0,955.0,956.0,957.0,958.0,959.0,960.0,961.0,962.0,963.0,964.0,965.0,966.0,967.0,968.0,969.0,970.0,971.0,972.0,973.0,974.0,975.0,976.0,977.0,978.0,979.0,980.0,981.0,982.0,983.0,984.0,985.0,986.0,987.0,988.0,989.0,990.0,991.0,992.0,993.0,994.0,995.0,996.0,997.0,998.0,999.0],\n",
       "\"value\":[-0.025091976230527502,0.1899762779288114,0.24506811915734222,0.31525190350074694,0.3206220703971378,0.41062444267144355,0.4762591958286754,0.7174529163926782,0.7375790932481645,0.8249414251866924,0.745587883667057,0.9851893304938343,0.9985276141273107,0.9060260075528482,0.9218147234298804,0.9341758885747412,0.9604220516334127,0.9966160967789162,0.9602366346066183,0.9045459157270228,0.9316680057701576,0.7911081387792821,0.7669253335266337,0.7189775808354584,0.6666771773945578,0.6555073363825592,0.4554361282531361,0.4302267679165521,0.3534710639283132,0.14853941175798152,0.1626289784401549,-0.024314512829251206,-0.14536382483052418,-0.06796858669258199,-0.1624146954119198,-0.2891037580663276,-0.48159768946017834,-0.6103017181072167,-0.5750112856402878,-0.6997356604360538,-0.8323948483389725,-0.8192417290421568,-0.9646980681905445,-0.8343018563336985,-0.9998460775695127,-0.9450256607943006,-1.0313487884155823,-0.9959096533285386,-0.9868225529671847,-1.0454817215192271,-0.8650073491102267,-0.8707881176555092,-0.7955548674073153,-0.753301972138371,-0.7531844917937701,-0.6211654785657685,-0.7135681374619369,-0.6114889701138085,-0.555556721631649,-0.4088105986775832,-0.30168004026102946,-0.22789269791731584,-0.017341900987110512,-0.011835434176931552,0.0727361067879698,0.2236592047194652,0.2397262085083312,0.46528931676740626,0.4090234798745631,0.6758171517083036,0.7114355525781205,0.668712176432711,0.6947722872738735,0.9135289063195317,0.9400795645811504,0.9838014103829363,1.0221737413686758,0.9029771642238185,0.9702364910834596,0.9221151537447979,1.0619789317985004,0.9945494362105979,0.9069101616503024,0.8148835038134981,0.816795372431413,0.7635237770288397,0.7803183335417261,0.6904807243532246,0.662359741407027,0.4954638414902745,0.3360373344294169,0.36174731979395114,0.2750469238236254,0.13670986302096094,0.07896886144426996,-0.07639200118893115,-0.16978021534658258,-0.28625242273923424,-0.46139530390310934,-0.5359576083766604,-0.637735273752023,-0.5977885666401274,-0.7370034913782784,-0.7659716715306419,-0.7463131743004351,-0.9298373141418951,-0.9406988370056814,-0.9055247885615787,-1.035176596968167,-1.0800402713406188,-1.0420399159679499,-1.0623083307531882,-0.8932381986828023,-0.8923951739892055,-0.892647774362591,-0.801160056650885,-0.7620941795888849,-0.8246695721418249,-0.6150132850791268,-0.6102686638539031,-0.4750848869676224,-0.37042920454990125,-0.39462858724245425,-0.3412214064602656,-0.22001714293992108,-0.08090033962594942,0.0972260004056371,0.20537815807121265,0.1329002512077771,0.32962389965320615,0.4036492374563967,0.4530830264665213,0.516046588173961,0.637092796477328,0.8289578307349524,0.768425012955772,0.86291993920517,0.9465585340874982,0.9164215899199636,1.0663639179391682,1.0830968146832927,0.9496658479129906,0.9974763538948387,0.9469476262379672,0.9226258754247709,0.8422724449955895,0.9167040389364828,0.8462826357887057,0.6985478176253141,0.6786106423592984,0.7319410173504476,0.5191092477933816,0.41537766327204273,0.39463112518612464,0.4002484475678224,0.15487853624009668,0.142180761780618,0.06028710685167908,-0.1443793414292017,-0.14521531165181745,-0.31434669012121463,-0.3556102510652932,-0.4457160442462872,-0.5508973344718276,-0.7200487283370686,-0.6447248432512754,-0.8141960655399513,-0.8998380759397759,-0.9794120052705518,-0.9109454240967214,-0.9258846195111003,-1.080747439296072,-0.9944814543817398,-1.0544752760334235,-0.9636248223887427,-1.0407527196671593,-0.9106569502976307,-0.935235380531077,-0.7798561817382343,-0.8856529228322878,-0.7827739765616245,-0.7586190613073821,-0.5198940987505716,-0.44684071895053534,-0.4829772965288624,-0.31048380926277674,-0.18352922169637773,-0.13795886349430633,-0.04360552520716612,-0.0012068540130949004,0.06849776322413217,0.3272773595736252,0.42339854025256485,0.4619856518275468,0.49087172336743956,0.5753817846421332,0.7271547558421835,0.830995467342666,0.8910910223601288,0.9236192098131939,0.9413515799584853,0.8659525466469044,0.9081462605858991,1.072477243541323,1.0210787120745872,0.8986692046021252,0.9042010031918225,0.9938530783237267,0.8298075508464842,0.8193191389758492,0.8464023964093733,0.8161732013396314,0.7415534748065,0.5822764580423508,0.5997508977871656,0.4190888205935562,0.34633043128679364,0.3363509323513299,0.21991325560488068,0.16086709829867993,0.022671269169664797,-0.09497487475698543,-0.28860146704114376,-0.3304214481991603,-0.44451520958509105,-0.5383765837846928,-0.47732354415907474,-0.6723427607328974,-0.6450854450088223,-0.762570560775966,-0.787258143466841,-0.8946599491986433,-0.9198291382692684,-0.9673846154722977,-1.0478669605610405,-0.9535916049270952,-1.0431215196484565,-1.0856223276108652,-0.9427039865624298,-1.0079793458731445,-0.817486645136041,-0.767921287209412,-0.7202828486498629,-0.7657468450268046,-0.7658184970722481,-0.5056938173475792,-0.5222597607271592,-0.32602995226449416,-0.23391113068687167,-0.16004381483392022,-0.1734619716838559,-0.05571583361046027,0.13743540682884986,0.12986440456841478,0.19798707072169136,0.3704186065138383,0.5376715491075454,0.5765281403414694,0.6328472561379123,0.6135999670063983,0.7855598958194366,0.9213437707589343,0.8038978828581959,0.9233435751347672,1.029759708878289,1.027511366654758,1.0340479220768917,1.0404905596544425,0.9672493351555101,0.9394816165980507,1.0182481595002058,0.9844554958589219,0.9526875253667434,0.9099760111066729,0.7693848324077154,0.6995432905925376,0.6840361712097465,0.5732684553877979,0.4971393475957335,0.4248111541698383,0.3489068566713823,0.14105118661619925,0.04938203611234657,-0.10686691189238569,-0.10967959789719785,-0.316567185427448,-0.32682035825770606,-0.404398622299028,-0.5444810505949171,-0.5674706878604983,-0.7575338342251576,-0.8275299802989348,-0.7345013665276843,-0.8830216524948177,-0.97714250567981,-0.9365827563319926,-0.9161070230874632,-1.046322877755167,-0.9744037097831494,-1.081425537665061,-1.0776952798591404,-0.9614252058201757,-0.9295647159782586,-0.8708322622577134,-0.8047507791347939,-0.6979568235647782,-0.7251006981713544,-0.6917254615895385,-0.5186778054919909,-0.5391745447043603,-0.41624336118193783,-0.395006008825919,-0.3091823916127927,-0.023137372001651904,0.05127016150234291,0.12316929691048642,0.16482631786344198,0.2149270337831921,0.3059876721836792,0.41543705598787767,0.5612720141829147,0.6748743975468974,0.7382089325238806,0.7293146689554136,0.9237325414404186,0.9314498068849844,0.9370208311828087,0.9815199821999508,0.9665378898496988,0.9457881266550952,0.9711063958375195,1.0451602247732688,0.8802212101182099,0.8745432668881638,0.8250101312951695,0.7792857606329704,0.8888583713286433,0.7969532306620677,0.6819559120222042,0.5307219783927963,0.5274058611433903,0.4364181608253369,0.2845917429386652,0.2414526626916228,0.13656954192788467,0.08065749771536786,-0.015449304543422755,-0.23293841901959278,-0.26518907502848715,-0.3106528760742946,-0.4275554177801335,-0.4449642518422625,-0.5674447228904762,-0.7435309499714835,-0.8321829261648304,-0.7805349105706434,-0.9583551465846317,-0.8925115555788355,-0.8585407979999712,-0.9589542022931506,-1.0141448682018115,-0.9709414988643323,-1.0057811893553446,-0.9761750259780156,-0.8750272627184559,-0.9544963602945506,-0.7985660313120785,-0.7599206513608888,-0.8436162865927906,-0.8028647629856244,-0.7233825330815142,-0.6602648581199526,-0.5597573264372293,-0.35199878744406543,-0.3804338718082118,-0.23400367357771001,-0.02997459535639864,-0.09445745604711724,0.16361079351029478,0.1559106601934674,0.22000154423371657,0.4295836683807763,0.5059933497942357,0.6408696808424393,0.6919109417056499,0.7786707788486138,0.7402856023125542,0.7774384348482495,0.9417328233696156,0.9937274967196443,1.0618964146842225,0.9681238341729184,0.9719610360663617,1.054829867192291,0.9597106932647437,1.059796920815691,1.0176951329955104,0.8947262700184174,0.9129348572439746,0.8588819784839175,0.6657379342465354,0.7553185742297802,0.5988108413948262,0.5800316101453804,0.3905866740506891,0.4132558225476607,0.2162272074957247,0.04240821412313128,0.1217696526337105,-0.14100342734616672,-0.19475994128662602,-0.16638727622285704,-0.2614933803293051,-0.42862915322566997,-0.5042217353162498,-0.6228710485798059,-0.7297684752980576,-0.7916498257728475,-0.78428363091144,-0.8215359512517412,-0.858205739170464,-0.8939510297880539,-1.059475731230283,-0.9949061598000303,-1.0884221142554749,-0.9861807266548469,-0.9939804726289592,-0.8811311234003326,-0.9552956111609122,-0.9596247877198943,-0.9031764062180312,-0.7198983496281128,-0.6812670247509959,-0.7103530295557645,-0.6331226083373422,-0.42362168969200337,-0.4585001698157834,-0.214190594361479,-0.14004069043838857,-0.16593452827205638,-0.06533053207754805,0.21475917852733084,0.19084142533944815,0.2865136255948757,0.4682217900068429,0.5843350330293998,0.676364240808845,0.7083315600656578,0.7048286544990415,0.710908005517557,0.9063329077196058,0.910778090091743,0.9231518751829496,1.0494133254311384,0.9105435606328683,0.9971158932699423,0.9011708196985049,0.9829607579628424,0.8809337780482864,0.8641925462006179,0.8252935970042302,0.8839794216957134,0.8471610925757156,0.7504677514098012,0.7547385626811459,0.5591707003180264,0.45739443393495915,0.48502892179245916,0.262975678806372,0.3146685200811977,0.02600401768318726,0.11786329684426668,-0.16740475366823834,-0.0969726469475399,-0.26707502832582064,-0.26871238991033125,-0.5435661415446861,-0.5339952665300469,-0.5319031621756594,-0.6958892226209445,-0.7423749336966143,-0.789174646770722,-0.8892095514151073,-0.8976056823795469,-0.9400304871358697,-0.9008768365048992,-1.086431340410224,-1.0437932435109984,-0.9043773211892029,-0.9009442860229451,-0.9626213022023292,-0.8949521619198447,-0.9195463423932202,-0.8846993081887349,-0.7686684353005397,-0.7222145086284851,-0.6007074923832874,-0.620276304340518,-0.3539750185684649,-0.2601577789761841,-0.22274251089997973,-0.15750894345830813,-0.1035301466034414,0.09726969253019958,0.17105846215644005,0.1648971495244628,0.4104989307501719,0.48548027472740496,0.5993859197688202,0.6379329341859904,0.6929122150305327,0.7246212180598434,0.8908581890367168,0.9328287272768314,0.8153741419939046,0.8492625076245697,0.9475084636801488,1.0528390752354149,1.0967972229442995,0.9280538684079864,1.0054537351109123,0.9416048084559461,1.0285623379513353,0.9628180552569078,0.9129383319086506,0.781443858943112,0.705231273222046,0.604294276072337,0.4817427329675577,0.5585669568157833,0.4585053520078497,0.40221540023095304,0.30492574781738224,0.11795696529680694,0.06087253503602593,-0.0038380657808230884,-0.12180085826388354,-0.3392841345491039,-0.39278321426446505,-0.5473727140152721,-0.46797884339987184,-0.6175553383024678,-0.7666803392591615,-0.7445692444045703,-0.8140016090554523,-0.9163432947310952,-1.0067405400374903,-0.9273268617663046,-0.9801609991111301,-0.9425058730798967,-0.9957224731362212,-0.9221152720094307,-0.9650493558185339,-0.9363760994112286,-0.8368882084573473,-0.8860630010182798,-0.8858367986889798,-0.8446439505327709,-0.6296359224723989,-0.5800633877164285,-0.48073504846706716,-0.49117270867390184,-0.41437174284549755,-0.343203987538283,-0.17800321267030994,-0.030665017504160647,0.02975850398064596,0.13825025968991492,0.32952629763080754,0.3138000617602471,0.4389626530797871,0.580553130630761,0.5855549958335997,0.7070302766779842,0.8246317328238282,0.9040938462399629,0.797500033566229,0.9986248565444635,0.947827119302611,0.9276631379762434,0.9846997993321894,1.0958170956101208,0.9952823549926391,0.9494979300851875,0.9875873698089637,0.8764948465210173,0.8019199896149609,0.7619447834615609,0.7028447993177764,0.6409170811652031,0.5645034416690199,0.5847523450864365,0.40723166463021565,0.34956272205161415,0.36555944153794917,0.183906948403466,0.1236494580756709,-0.0752754535724346,-0.17106164909197413,-0.30003147247076384,-0.37102360848778376,-0.44265241170493097,-0.5525478549175749,-0.6549134826598089,-0.72750908346144,-0.7319518382609044,-0.8480771386723926,-0.8738393374799576,-0.8948994031838018,-0.8974450714237447,-1.0582553420401732,-0.9271762936835135,-0.9725565380345222,-1.0828900008840099,-0.9156471799606558,-0.8874141434097466,-1.0308909579175591,-0.9498257377346049,-0.7970112570372019,-0.753074455133228,-0.8022764927779473,-0.726379486240873,-0.6165466579885225,-0.5102267187303217,-0.3949035102123598,-0.35201282750060725,-0.23727446158805846,-0.08197716674678851,-0.12451104504002336,0.018581583553309376,0.2100256174797174,0.3439864106215694,0.3622226309972759,0.4576560657514909,0.459505422428554,0.6090149172166421,0.7013271574455439,0.7116268162437297,0.7776854032335979,0.8517661266394286,0.824040277752336,0.9189660194382304,0.9218263859163184,0.9602356453889261,0.9239489167094568,1.0733706275092068,0.9993079824863409,0.9919365499567044,0.9799237323189198,0.878538109525065,0.7442127371075882,0.7739675987524133,0.7159730477444397,0.6727710242539338,0.5288617082728934,0.3814717507806027,0.32158100403797407,0.2426671957878927,0.20176084071213837,0.08753537305842174,-0.05533180884439755,-0.0289136800596283,-0.20346622589845037,-0.37333595069594616,-0.49337979298863865,-0.5719855219236208,-0.6371654794159319,-0.7321617402023928,-0.7982881536288182,-0.8425361806707182,-0.9208452599163713,-0.8235835857832637,-1.0252847685669013,-0.9654186134138399,-1.0075357739579172,-0.9025457566529137,-1.0760381478839,-1.0083231151178336,-0.8735777422404077,-0.8642813389745254,-0.8345132664994352,-0.897920235246248,-0.858408471950658,-0.6940232770049449,-0.5697711980937352,-0.5656372901857567,-0.47824571172239894,-0.4472292325834194,-0.2559543749519232,-0.27597617378518796,-0.1500489665023385,-0.029950524429877574,0.08638151806193681,0.132390755789359,0.20408798520507554,0.39764757538495155,0.4239005168352358,0.5684150291924027,0.5635158326956881,0.7030260521187657,0.7804085680682062,0.7436155788565917,0.8516063497932685,0.8533675638529882,0.8721016287179372,1.0807744134706818,0.9607892318106167,1.06187456306822,0.944418348912974,1.0134546806142788,1.003100225232312,0.9345802947423738,0.8650187784598166,0.799622935745372,0.7254138790480109,0.7723814200583408,0.6765758010469773,0.621334196112439,0.36578626629895794,0.39529272921486114,0.3414914541262438,0.09223798544518888,-0.030099979091803925,0.004868756357153434,-0.12798369923994957,-0.17260792193644667,-0.4087068280468706,-0.3699316586263013,-0.5766971970894946,-0.6671630931019467,-0.743918797301109,-0.6839726063711095,-0.7765010462926434,-0.8594916845106709,-0.9382691024509839,-0.8714327500307258,-0.9957606550219732,-0.9285722262018075,-1.0117969118435952,-1.021978875621473,-0.9926103033343261,-1.0028059288086686,-0.8818720787475332,-0.8898561473872934,-0.8940673722743532,-0.7023065853486287,-0.7393391457687317,-0.6341474996160412,-0.48188110608820744,-0.45301832182307844,-0.46440202726775764,-0.2058563391728311,-0.17138650183540027,-0.1310846974686066,-0.07036927255648559,0.1604057357443087,0.22442447346678493,0.3039089353704454,0.4698323370902402,0.5387030857208055,0.49644261284473057,0.607919683502001,0.6682903562520275,0.8332191061423573,0.7491358901742097,0.9059896196736338,0.985173013446159,1.039384954239686,0.9541664398721323,1.0618705252500547,0.9216465059717727,1.0607248361656116,0.8989402449445516,0.9251817894423038,0.9680158584344698,0.7922947256270837,0.7533000452131665,0.7889710346984382,0.7181595802419506,0.6252776447566857,0.5527681448809552,0.43431817963141267,0.2836737517363015,0.2066634249396094,0.0756807923295309,0.12149593243339533,-0.043468976279747114,-0.17932923498828773,-0.26485687425651516,-0.2629894464599177,-0.5134423880842923,-0.5140958296477939,-0.612084196029996,-0.6667637099705347,-0.8543403401808962,-0.7448721055224505,-0.7860215975063124,-0.9038497993910001,-0.9128163271687307,-0.893403138534192,-0.9524409270606955,-1.0694358776001551,-0.9807499396343724,-0.9607767490564494,-0.9735927547581973,-0.8778529678514739,-0.795747626776335,-0.7461676843291676,-0.7814679809771563,-0.7816327840404642,-0.5329197544819869,-0.4814223454255926,-0.5380959504450493,-0.28806020655104364,-0.20373022209125105,-0.17664801303709438,-0.06306401398979018,-0.001609523463173619,0.029265555935670956,0.18389382224216144,0.3737994721526875,0.3073999170997211,0.46235672792812305,0.5595215735608242,0.6658038491226351,0.814154982435719,0.76401643289052,0.8207603976069316,0.9469859248712078,0.9290578179121277,0.9132854256881817,0.9789270180961661,0.9268090158137807,0.9341354489964806,0.9887717867265825,0.9532407599795245,1.0230958075961725,0.8738829300135605,0.8697928107494137,0.8238693489629605,0.6358092113909589,0.694345827853187,0.5190827084812492,0.5916968457830426,0.34023192816806197,0.3003392335530741,0.138227868764062,0.22206657487529197,0.023438620775333274,-0.05784528821138814,-0.2626603244709016,-0.22347756475029096,-0.4261501606585552,-0.37950379578256804,-0.6044827781109845,-0.6883186519567693,-0.7938324091695715,-0.7744095178450626,-0.8158534199960688,-0.967397346623141,-0.8683529236650577,-0.9664931610020211,-0.9764018193536119,-1.0074516449737807,-1.0198281553215902,-0.9824377970911093,-1.047767535009739,-1.017099677176088,-0.8462709881817069,-0.7853692006260937,-0.8471559733748719,-0.8066831134133498,-0.6634443684791057,-0.6349929960006103,-0.629995851665015,-0.5168296221293711,-0.3133758458127401,-0.22973292069279103,-0.2584329295638983,-0.12015495836648371,-0.018386737948725043,0.1693708568003632,0.13717962245861598,0.24997400598091105,0.4817615004606317,0.4458989404126298,0.6240533042743601,0.618524617007529,0.6614570257068746,0.7534743619201726,0.904522792183585,0.9778446523241576,1.0103257842795237,0.9518600182319422,1.0244657082683295,0.9403706761942479,0.9565430864886588,1.065749605236372,0.8677951208619361,0.8513648302055791,0.8355739146297633,0.7501041247944982,0.7234448522511389,0.7382611384501069,0.633222280904424,0.6482722898323581,0.5483346035534158,0.3634728852578953,0.2533098226491023,0.18066759832019635,0.1240465002541184,-0.04020035720247227,-0.06884571852130132,-0.2107196097450676,-0.27919452918451837,-0.3964870576079672,-0.515093682509777,-0.4698347242385569,-0.5867521853131527,-0.7850092612330056,-0.7057724744362222,-0.8406258358850444,-0.8094734972595363,-0.8698083198581514,-0.9768420504317119,-1.079885435461061,-1.043302778503283,-0.9914082840825128,-0.9657473367632357,-1.023657135150199,-1.0204109264553824,-0.8448686412480214,-0.7694358491756258,-0.8069838996074566,-0.8154772757166278,-0.725550979432179,-0.6997391617107394,-0.43793324182373694,-0.5094149011373457,-0.32550789285510084,-0.29044094133021314,-0.13640670570491975,-0.017477352826347915,0.11814502238178477,0.0929174763403282,0.15175387903693988,0.27235986243252974,0.5169675344357354,0.5993568933167939,0.6264351512322188,0.7033650868228516,0.7857513083859974,0.749779318983148,0.9514082785387801,0.8974227968375912,0.9263101244641239,0.9799907740203226,0.9023713004877282,0.9330841460413487,1.0442936151287203,0.9001474790193702,0.9812913372970198,0.877205300994972,0.8641955426161079,0.7934201273880123,0.7478110314432617,0.7537204825690271,0.5954772589792962,0.5691202277524332,0.46528200142478926,0.4123419721000513,0.3727165898882848,0.23475683517049264,0.032241409158400444,-0.10439091164017889,-0.15794941503193782,-0.1900582204643282,-0.3953712302550126,-0.39991171221730765,-0.4693564363959787,-0.6065330938270307,-0.5981272549222556,-0.8034002058714204,-0.8748612997321819,-0.8015277960723793,-0.8968793771925636,-0.8981569418565819,-0.9793811559643711,-1.0379200035481562,-0.9343699529983837,-0.9393236583925578,-0.9513002132752733,-1.0169490074312324,-0.9247647407048646,-0.9326286792901839,-0.9394789317081282,-0.7187337114247436,-0.8112184989542691,-0.5775408835440047,-0.6007230067258115]\n",
       "},\n",
       "\"mapping\":{\n",
       "\"x\":\"time\",\n",
       "\"y\":\"value\"\n",
       "},\n",
       "\"data_meta\":{\n",
       "\"series_annotations\":[{\n",
       "\"type\":\"int\",\n",
       "\"column\":\"time\"\n",
       "},{\n",
       "\"type\":\"float\",\n",
       "\"column\":\"value\"\n",
       "},{\n",
       "\"type\":\"float\",\n",
       "\"column\":\"x1\"\n",
       "},{\n",
       "\"type\":\"float\",\n",
       "\"column\":\"x2\"\n",
       "},{\n",
       "\"type\":\"float\",\n",
       "\"column\":\"x3\"\n",
       "},{\n",
       "\"type\":\"float\",\n",
       "\"column\":\"x4\"\n",
       "},{\n",
       "\"type\":\"float\",\n",
       "\"column\":\"x5\"\n",
       "}]\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[],\n",
       "\"layers\":[{\n",
       "\"geom\":\"line\",\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"data\":{\n",
       "}\n",
       "}],\n",
       "\"metainfo_list\":[],\n",
       "\"spec_id\":\"1\"\n",
       "};\n",
       "           fig = LetsPlot.buildPlotFromProcessedSpecs(plotSpec, containerDiv, sizing);\n",
       "       } else {\n",
       "           fig.updateView({});\n",
       "       }\n",
       "   }\n",
       "   \n",
       "   const renderImmediately = \n",
       "       forceImmediateRender || (\n",
       "           sizing.width_mode === 'FIXED' && \n",
       "           (sizing.height_mode === 'FIXED' || sizing.height_mode === 'SCALED')\n",
       "       );\n",
       "   \n",
       "   if (renderImmediately) {\n",
       "       renderPlot();\n",
       "   }\n",
       "   \n",
       "   if (!renderImmediately || responsive) {\n",
       "       // Set up observer for initial sizing or continuous monitoring\n",
       "       var observer = new ResizeObserver(function(entries) {\n",
       "           for (let entry of entries) {\n",
       "               if (entry.contentBoxSize && \n",
       "                   entry.contentBoxSize[0].inlineSize > 0) {\n",
       "                   if (!responsive && observer) {\n",
       "                       observer.disconnect();\n",
       "                       observer = null;\n",
       "                   }\n",
       "                   renderPlot();\n",
       "                   if (!responsive) {\n",
       "                       break;\n",
       "                   }\n",
       "               }\n",
       "           }\n",
       "       });\n",
       "       \n",
       "       observer.observe(containerDiv);\n",
       "   }\n",
       "   \n",
       "   // ----------\n",
       "   })();\n",
       "   \n",
       "   </script>\n",
       "   </body>\n",
       "</html>"
      ],
      "text/plain": [
       "<lets_plot.plot.core.PlotSpec at 0x1e84d47a510>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    ggplot(data_df, aes(\"time\", \"value\"))\n",
    "    + geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. Tao tập dữ liệu phục vụ cho dự báo với x steps\n",
    "def create_dataset_with_features(dataframe, feature_columns, target_column, n_steps_in, n_steps_out):\n",
    "    \"\"\"\n",
    "    Converts a time series stored in a Polars DataFrame into a\n",
    "    supervised learning dataset for multi-variate, multi-step forecasting.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pl.DataFrame): The input time series data.\n",
    "        feature_columns (list): The names of the columns to use as input features.\n",
    "        target_column (str): The name of the column containing the target values (Y).\n",
    "        n_steps_in (int): The number of past time steps to use as input (the window size).\n",
    "        n_steps_out (int): The number of future time steps to predict.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple of (X, y) where X are the input sequences\n",
    "               and y are the target sequences, both as NumPy arrays.\n",
    "    \"\"\"\n",
    "    # Extract features and target into a single NumPy array\n",
    "    features = dataframe.select(feature_columns).to_numpy()\n",
    "    target = dataframe.select(target_column).to_numpy().flatten()\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - n_steps_in - n_steps_out + 1):\n",
    "        # The input is the window of n_steps_in for all features\n",
    "        X_input = features[i:i + n_steps_in, :]\n",
    "        X.append(X_input.flatten()) # Flatten the 2D input window to a 1D vector\n",
    "        \n",
    "        # The output is the sequence of n_steps_out future target values\n",
    "        y.append(target[i + n_steps_in : i + n_steps_in + n_steps_out])\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define the features and target\n",
    "feature_cols = [\"x1\", \"x2\", \"x3\", \"x4\", \"x5\"]\n",
    "target_col = \"value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prepared with 788 training examples and 198 test examples.\n",
      "Dataset prepared with 788 training examples and 198 test examples.\n",
      "Each input example has 50 features (10 steps * 5 features).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We'll use the last 10 data points to predict the next 5.\n",
    "n_steps_in = 10\n",
    "n_steps_out = 5\n",
    "X, y = create_dataset_with_features(data_df, feature_cols, target_col, n_steps_in, n_steps_out)\n",
    "\n",
    "# Determine the number of features for the model input shape\n",
    "n_features = len(feature_cols)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]\n",
    "\n",
    "print(f\"Dataset prepared with {X_train.shape[0]} training examples and {X_test.shape[0]} test examples.\")\n",
    "print(f\"Dataset prepared with {y_train.shape[0]} training examples and {y_test.shape[0]} test examples.\")\n",
    "print(f\"Each input example has {X_train.shape[1]} features ({n_steps_in} steps * {n_features} features).\")\n",
    "\n",
    "# --- 3. Build the Keras Model ---\n",
    "# The input layer now expects a flattened vector of all features and all time steps.\n",
    "model = Sequential([\n",
    "    Dense(50, activation='relu', input_shape=(n_steps_in * n_features,)),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(n_steps_out) # The output layer has `n_steps_out` neurons\n",
    "])\n",
    "\n",
    "# --- 4. Compile the Model ---\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel: \"sequential\"\u001b[0m\n",
      "┌─────────────────────────────────┬────────────────────────┬───────────────┐\n",
      "│\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m│\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense (\u001b[94mDense\u001b[0m)                   │ (\u001b[96mNone\u001b[0m, \u001b[32m50\u001b[0m)             │         \u001b[32m2,550\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_1 (\u001b[94mDense\u001b[0m)                 │ (\u001b[96mNone\u001b[0m, \u001b[32m50\u001b[0m)             │         \u001b[32m2,550\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_2 (\u001b[94mDense\u001b[0m)                 │ (\u001b[96mNone\u001b[0m, \u001b[32m5\u001b[0m)              │           \u001b[32m255\u001b[0m │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m5,355\u001b[0m (20.92 KB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m5,355\u001b[0m (20.92 KB)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.4680 - val_loss: 0.2384\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2117 - val_loss: 0.1195\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1109 - val_loss: 0.0527\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0429 - val_loss: 0.0205\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0178 - val_loss: 0.0131\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0076\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5. Train the Model ---\n",
    "history = model.fit(X_train, y_train, epochs=20, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "Mean Absolute Error on the test set for all predictions: 0.0702\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Dự báo trên tập test & đánh giá chất lượng mô hình ---\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "mae = np.mean(np.abs(predictions.flatten() - y_test.flatten()))\n",
    "print(f\"\\nMean Absolute Error on the test set for all predictions: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Prediction for the next 5 values in the series:\n",
      "  Step 1: -0.5801\n",
      "  Step 2: -0.4782\n",
      "  Step 3: -0.3557\n",
      "  Step 4: -0.3337\n",
      "  Step 5: -0.1604\n"
     ]
    }
   ],
   "source": [
    "# Dự báo với các điểm dữ liệu\n",
    "last_window = data_df.select(feature_cols).tail(n_steps_in).to_numpy()\n",
    "input_for_prediction = last_window.flatten().reshape(1, -1) \n",
    "\n",
    "next_values_prediction = model.predict(input_for_prediction)\n",
    "print(\"\\nPrediction for the next 5 values in the series:\")\n",
    "for i, pred in enumerate(next_values_prediction[0]):\n",
    "    print(f\"  Step {i+1}: {pred:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với ví dụ đơn giản trên, để dự báo các biến tiếp theo, ta cần duỗi tất cả các biến đầu vào và xây dựng mô hình cho tất cả tập dữ liệu *cùng một lúc*. Nhóm mô hình trên còn gọi là `feedforward neural network`. Trong thực tế, với một số bài toán dự báo, 1 yếu tố mới đầu ra sẽ không chỉ phụ thuộc dữ liệu đầu vào mà toàn bộ các thông tin dữ liệu lịch sử (ký ức) như dự báo ECG, dịch thuật. Trong kiểu mô hình trên, ta không cho phép mô hình học tuần tự theo chu kỳ thời gian. \n",
    "\n",
    "Để khắc phục nhược điểm trên, người ta xây dựng thêm mô hình `Recurrent Neural Network`. Mô hình này dựa trên ý tưởng kết quả dự báo không chỉ dựa trên thông tin mới mà còn dựa vào các thông tin đã được dự báo và lưu trữ từ quá khứ. Như vậy, mô hình có trí nhớ với khả năng lưu trữ các thông tin cũ từ quá khứ.\n",
    "\n",
    "Thay vì chỉ nhận dữ liệu đầu vào $x_t$, RNN sẽ nhận cả các trạng thái ẩn (hidden state) $h_{t-1}$ từ thời điểm trước đó. Như vậy, ta có thể coi $h_{t-1}$ như một bộ nhớ lưu trữ các thông tin từ quá khứ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_t = f(W_{x} x_t + W_{h} h_{t-1} + b_h)$$\n",
    "$$y_t = g(W_yh_t + c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong đó:\n",
    "\n",
    "- $h_t$: Trạng thái ẩn tại thời điểm $t$\n",
    "- $x_t$: Đầu vào tại thời điểm $t$\n",
    "- $y_t$: Output\n",
    "- $f, g$: Hàm kích hoạt (activation function) như `tanh`, `relu`, `sigmoid`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Pseudo code\n",
    "state_t = 0\n",
    "for input_t in input_sequence:\n",
    "    output_t = f(input_t, state_t)\n",
    "    state_t = output_t\n",
    "\n",
    "# Detail implementation\n",
    "state_t = 0\n",
    "for input_t in input_sequence:\n",
    "    output_t = activation(dot(W, input_t) + dot(U, state_t) + b)\n",
    "    state_t = output_t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/p01-2025-09-01-15-56-15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trực quan hóa**: Giả sử ta đang dự đoán một câu tiếng Việt. Câu bắt đầu với cụm từ\n",
    "\n",
    "“Hôm nay trời rất…”\n",
    "\n",
    "- Đến đây ta có thể dự đoán từ tiếp theo → có thể là “đẹp”, “nắng”, “lạnh”…\n",
    "- Dự đoán phụ thuộc vào tất cả từ trước đó.\n",
    "- RNN giống như một “bộ nhớ tạm thời” để lưu lại ngữ cảnh trước khi sinh tiếp từ sau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giới thiệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Về mặt lý thuyết, RNN có khả năng lưu trữ trí nhớ tại các `state`. Tuy nhiên, khi chuỗi thời gian đủ lớn, mô hình sẽ không có khả năng ghi nhớ các trạng thái ẩn ở lâu trước đó. Do đó, RNN chỉ có thể có *trí nhớ ngắn hạn*. Để giải quyết nhược điểm đó, người ta phát triển thêm mô hình LSTM - Long Short Term Memory, cho phép mô hình Neural Network có thể ghi nhớ các trạng thái dài hạn.\n",
    "\n",
    "Ý tưởng chính của LSTM là để tạo ra và cho phép ghi nhớ ký ức được tốt hơn. Thay vì chỉ có 1 trạng thái ẩn, LSTM cho phép tạo ra các `cell state` (bộ nhớ dài hạn). Thông tin trong bộ nhơ dài hạn được quyết định và điều chỉnh từ các cổng (gates). Các cổng này cho phép mô hình quyết định giữ lại, quên đi hoặc bổ sung các thông tin mới."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/p01-2025-09-01-16-12-17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với mô hình LSTM, mạng neural sẽ mang theo thông tin `C` & được tính toán, điều chỉnh 1 chút theo thời gian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Pseudo code\n",
    "output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(c_t, Vo) + bo)\n",
    "i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)\n",
    "f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)\n",
    "k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)\n",
    "\n",
    "# Trong đó\n",
    "c_t+1 = i_t * k_t + c_t * f_t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trực quan hóa**: RNN có thể coi như người có trí nhớ ngắn hạn nhưng khi câu chuyện dài quá sẽ quên mất các nội dung chính. LSTM giống như người có trí nhớ dài hạn tốt để có thể tập trung vào trọng tâm.\n",
    " \n",
    "Quay trở lại ví dụ dự đoán câu tiếng Việt. Giả sử ta có câu:\"Hôm nay trời rất đẹp, tôi đi dạo công viên...\"\n",
    "\n",
    "Trong LSTM, mô hình sẽ cập nhật thông qua 3 cánh cửa:\n",
    "\n",
    "- Forget gate: Quên đi các thông tin không cần thiết như \"hôm nay\"\n",
    "- Input gate: Bổ sung các thông tin mới như \"đẹp\" hay \"công viên\"\n",
    "- Output gate: Quyết định thông tin nào sẽ được đưa vào trạng thái ẩn để dự đoán từ tiếp theo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ví dụ mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với mô hình đã xây dựng với Dense Layer, ta có thể xây dựng mô hình LSTM như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated a Polars DataFrame with 1000 data points and multiple features.\n",
      "Dataset prepared with 788 training examples and 198 test examples.\n",
      "Each input example has shape: (10, 6).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import polars as pl\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# --- 1. Generate Synthetic Data with Multiple Features ---\n",
    "# We'll create a primary time series and five additional features that are\n",
    "# correlated with the main series.\n",
    "def generate_time_series_with_features(num_points=1000, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Generates a synthetic time series as a Polars DataFrame with multiple features.\n",
    "    \"\"\"\n",
    "    time = np.arange(num_points)\n",
    "    \n",
    "    # Primary time series\n",
    "    series_values = np.sin(0.1 * time) + np.random.uniform(-noise_level, noise_level, num_points)\n",
    "    \n",
    "    # Generate five additional correlated features\n",
    "    df = pl.DataFrame({\n",
    "        \"time\": time,\n",
    "        \"value\": series_values,\n",
    "        \"x1\": series_values * 0.5 + np.random.uniform(-noise_level, noise_level, num_points),\n",
    "        \"x2\": np.cos(0.15 * time) + np.random.uniform(-noise_level, noise_level, num_points),\n",
    "        \"x3\": series_values + np.random.uniform(-noise_level, noise_level, num_points),\n",
    "        \"x4\": -np.sin(0.08 * time) + np.random.uniform(-noise_level, noise_level, num_points),\n",
    "        \"x5\": np.cos(0.2 * time) - series_values * 0.5 + np.random.uniform(-noise_level, noise_level, num_points)\n",
    "    })\n",
    "    return df\n",
    "\n",
    "data_df = generate_time_series_with_features()\n",
    "print(f\"Generated a Polars DataFrame with {data_df.shape[0]} data points and multiple features.\")\n",
    "\n",
    "# --- 2. Prepare Data for Supervised Learning with Multiple Features ---\n",
    "# We'll create a dataset where the model learns to predict the next `n_steps_out` values\n",
    "# of the primary time series based on a fixed window of all features.\n",
    "def create_dataset_with_features(dataframe, feature_columns, target_column, n_steps_in, n_steps_out):\n",
    "    \"\"\"\n",
    "    Converts a time series stored in a Polars DataFrame into a\n",
    "    supervised learning dataset for multi-variate, multi-step forecasting.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pl.DataFrame): The input time series data.\n",
    "        feature_columns (list): The names of the columns to use as input features.\n",
    "        target_column (str): The name of the column containing the target values (Y).\n",
    "        n_steps_in (int): The number of past time steps to use as input (the window size).\n",
    "        n_steps_out (int): The number of future time steps to predict.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple of (X, y) where X are the input sequences\n",
    "               and y are the target sequences, both as NumPy arrays.\n",
    "    \"\"\"\n",
    "    # Extract features and target into a single NumPy array\n",
    "    features = dataframe.select(feature_columns).to_numpy()\n",
    "    target = dataframe.select(target_column).to_numpy().flatten()\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - n_steps_in - n_steps_out + 1):\n",
    "        # The input is the window of n_steps_in for all features\n",
    "        X_input = features[i:i + n_steps_in, :]\n",
    "        X.append(X_input) # We now append the 2D window directly\n",
    "        \n",
    "        # The output is the sequence of n_steps_out future target values\n",
    "        y.append(target[i + n_steps_in : i + n_steps_in + n_steps_out])\n",
    "\n",
    "    # LSTM models expect a 3D input: [samples, timesteps, features]\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define the features and target\n",
    "feature_cols = [\"value\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\"]\n",
    "target_col = \"value\"\n",
    "\n",
    "# We'll use the last 10 data points to predict the next 5.\n",
    "n_steps_in = 10\n",
    "n_steps_out = 5\n",
    "X, y = create_dataset_with_features(data_df, feature_cols, target_col, n_steps_in, n_steps_out)\n",
    "\n",
    "# Determine the number of features for the model input shape\n",
    "n_features = len(feature_cols)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:] # Fixed the bug here\n",
    "\n",
    "print(f\"Dataset prepared with {X_train.shape[0]} training examples and {X_test.shape[0]} test examples.\")\n",
    "print(f\"Each input example has shape: {X_train.shape[1:]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel: \"sequential_1\"\u001b[0m\n",
      "┌─────────────────────────────────┬────────────────────────┬───────────────┐\n",
      "│\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m│\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ lstm (\u001b[94mLSTM\u001b[0m)                     │ (\u001b[96mNone\u001b[0m, \u001b[32m50\u001b[0m)             │        \u001b[32m11,400\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_3 (\u001b[94mDense\u001b[0m)                 │ (\u001b[96mNone\u001b[0m, \u001b[32m5\u001b[0m)              │           \u001b[32m255\u001b[0m │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m11,655\u001b[0m (45.53 KB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m11,655\u001b[0m (45.53 KB)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Build the Keras Model with LSTM ---\n",
    "# The LSTM layer expects a 3D input: [samples, timesteps, features]\n",
    "model = Sequential([\n",
    "    # The LSTM layer processes the sequence data\n",
    "    LSTM(50, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    # The final dense layer predicts the n_steps_out values\n",
    "    Dense(n_steps_out)\n",
    "])\n",
    "\n",
    "# --- 4. Compile the Model ---\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.5300 - val_loss: 0.3779\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3014 - val_loss: 0.2145\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1882 - val_loss: 0.1398\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1298 - val_loss: 0.0666\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0660 - val_loss: 0.0345\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0320 - val_loss: 0.0183\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0165 - val_loss: 0.0108\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0077 - val_loss: 0.0069\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0068 - val_loss: 0.0065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5. Train the Model ---\n",
    "history = model.fit(X_train, y_train, epochs=20, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "Mean Absolute Error on the test set for all predictions: 0.0667\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Make a Forecast and Evaluate ---\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mae = np.mean(np.abs(predictions.flatten() - y_test.flatten()))\n",
    "print(f\"\\nMean Absolute Error on the test set for all predictions: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\n",
      "Prediction for the next 5 values in the series:\n",
      "  Step 1: -0.5511\n",
      "  Step 2: -0.4145\n",
      "  Step 3: -0.3618\n",
      "  Step 4: -0.2764\n",
      "  Step 5: -0.1332\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You can also make a multi-step forecast on the very last data points\n",
    "# The input for prediction must have the shape [1, n_steps_in, n_features]\n",
    "last_window = data_df.select(feature_cols).tail(n_steps_in).to_numpy()\n",
    "input_for_prediction = last_window.reshape(1, n_steps_in, n_features) \n",
    "\n",
    "next_values_prediction = model.predict(input_for_prediction)\n",
    "print(\"\\nPrediction for the next 5 values in the series:\")\n",
    "for i, pred in enumerate(next_values_prediction[0]):\n",
    "    print(f\"  Step {i+1}: {pred:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tài liệu tham khảo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
