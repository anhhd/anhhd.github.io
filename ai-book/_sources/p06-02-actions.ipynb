{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e639c3",
   "metadata": {},
   "source": [
    "# Tools với AI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42903a74",
   "metadata": {},
   "source": [
    "## Giới thiệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea04997",
   "metadata": {},
   "source": [
    "Với LLM thông thường, ta chỉ có thể tương tác trực tiếp với mô hình đã được huấn luyện mà không có khả năng thực hiện nhiệm vụ. Để khắc phục nhược điểm này, agent cần được tương tác với các công cụ nằm ngoài LLM để có thể thực hiện tác vụ cụ thể. \n",
    "\n",
    "Xem ví dụ về quy trình tương tác giữa LLM và các công cụ bên ngoài với yêu cầu tìm kiếm thông tin một bộ phim của ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60169d8",
   "metadata": {},
   "source": [
    "![](image/p06-02-actions-2025-07-21-20-54-54.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebd7c7",
   "metadata": {},
   "source": [
    "![](image/p06-02-actions-2025-07-21-20-56-41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9675c1c4",
   "metadata": {},
   "source": [
    "## Ví dụ với OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2696bbfd",
   "metadata": {},
   "source": [
    "### Đơn tác vụ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1036cc7f",
   "metadata": {},
   "source": [
    "Khi sử dụng LLM với khả năng tương tác với các công cụ bên ngoài (tools/ actions), LLM sẽ thực hiện các tác vụ với sơ đồ và các bộ tham số bao gồm:\n",
    "\n",
    "- **Model**: Mô hình LLM cụ thể - ví dụ ChatGPT 3.5 turbo, Llama 7B,...\n",
    "- **Messages**: Prompt & hướng dẫn về system prompt\n",
    "- **Parameters**: Các bộ tham số của agent như temperature, max tokens\n",
    "- **Tools**: Công cụ cho phép thương tác với bên ngoài - ví dụ: hàm, api call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725f65c",
   "metadata": {},
   "source": [
    "![](image/p06-02-actions-2025-07-21-21-00-20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c33fef4",
   "metadata": {},
   "source": [
    "Ta có thể xây dựng một tool cho phép trả ra `tool` cần thiết để thực hiện nhiệm vụ mà người dùng yêu cầu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c23ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "# Ensure the API key is available\n",
    "if not api_key:\n",
    "    raise ValueError(\"No API key found. Please check your .env file.\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "# Example function to query ChatGPT\n",
    "def ask_chatgpt(user_message):    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # gpt-4 turbo or a model of your preference\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": user_message}],\n",
    "        temperature=0.7,\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"recommend\",\n",
    "                    \"description\": \"Provide a recommendation for any topic.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"topic\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The topic, a user wants a recommnedation for.\",\n",
    "                            },\n",
    "                            \"rating\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The rating this recommendation was given.\",\n",
    "                                \"enum\": [\"good\", \"bad\", \"terrible\"]\n",
    "                                },\n",
    "                        },\n",
    "                        \"required\": [\"topic\"],\n",
    "                    },\n",
    "                },\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    return response.choices[0].message.tool_calls[0].function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d7248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(arguments='{\"topic\":\"time travel movie\"}', name='recommend')\n",
      "Function(arguments='{\"topic\":\"fiction book\",\"rating\":\"good\"}', name='recommend')\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user = \"Can you please recommend me a time travel movie?\"\n",
    "response = ask_chatgpt(user)\n",
    "print(response)\n",
    "\n",
    "# Example usage with a different user input\n",
    "user = \"Can you please recommend me a good fiction book to read?\"\n",
    "response = ask_chatgpt(user)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d92e05",
   "metadata": {},
   "source": [
    "Trong bước trên, hàm **KHÔNG** thực sự chạy mà chỉ trả ra loại actions và các tham số cần thiết để thực hiện tác vụ mà thôi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ef316",
   "metadata": {},
   "source": [
    "### Đa tác vụ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa4fb89",
   "metadata": {},
   "source": [
    "Tương tự như hàm trên, ta có thể xây dựng cùng lúc nhiều hàm khác nhau để thực hiện các tác vụ khác nhau mà người dùng yêu cầu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b0cb0",
   "metadata": {},
   "source": [
    "![](image/p06-02-actions-2025-07-21-21-14-47.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c75aee",
   "metadata": {},
   "source": [
    "Ví dụ cho phép thực hiện đa tác vụ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9b4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def recommend(topic, rating=\"good\"):\n",
    "    \"\"\"Give a recommendation for any topic\"\"\"\n",
    "    if \"time travel\" in topic.lower():\n",
    "        return json.dumps({\"topic\": \"time travel\",\n",
    "                           \"recommendation\": \"Back to the Future\",\n",
    "                           \"rating\": rating})\n",
    "    elif \"recipe\" in topic.lower():\n",
    "        return json.dumps({\"topic\": \"recipe\",\n",
    "                           \"recommendation\": \"The best thing you ever ate.\",\n",
    "                           \"rating\": rating})\n",
    "    elif \"gift\" in topic.lower():\n",
    "        return json.dumps({\"topic\": \"gift\",\n",
    "                           \"recommendation\": \"A glorius new...\",\n",
    "                           \"rating\": rating})\n",
    "    else:\n",
    "        return json.dumps({\"topic\": topic,\n",
    "                           \"recommendation\": \"unknown\"})\n",
    "    \n",
    "\n",
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    user = \"\"\"Can you please make recommendations for the following:\n",
    "    1. Time travel movies\n",
    "    2. Recipes\n",
    "    3. Gifts\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"recommend\",\n",
    "                \"description\": \"Provide a recommendation for any topic.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"topic\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The topic, a user wants a recommnedation for.\",\n",
    "                            },\n",
    "                            \"rating\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The rating this recommendation was given.\",\n",
    "                                \"enum\": [\"good\", \"bad\", \"terrible\"]\n",
    "                                },\n",
    "                            },\n",
    "                    \"required\": [\"topic\"],\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"recommend\": recommend,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                topic=function_args.get(\"topic\"),\n",
    "                rating=function_args.get(\"rating\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd8f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your request, here are some recommendations:\n",
      "\n",
      "1. Time travel movies: \"Back to the Future\"\n",
      "2. Recipes: \"The best thing you ever ate.\"\n",
      "3. Gifts: \"A glorious new...\" (Unfortunately, the full recommendation is not provided)\n",
      "\n",
      "I hope you find these recommendations helpful!\n"
     ]
    }
   ],
   "source": [
    "# Thực hiện tác vụ\n",
    "print(run_conversation())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
